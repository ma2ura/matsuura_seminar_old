[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "実証会計・ファイナンスのノート",
    "section": "",
    "text": "この資料は、笠原・村宮 (2022)「実証会計・ファイナンス」をゼミで輪読した際に使用した講義ノートである。本資料の内容は、上記教科書の内容を補足するために作成したもので、基本的には笠原・村宮本の章立てに沿っています。\nただし、本資料の内容は、笠原・村宮本の内容を簡略化しつつ、内容を補足するために作成したものですので、本資料だけで笠原・村宮本の内容を理解することは不可能です。 従って、本資料を理解するためには、笠原・村宮本を読むことを強く推奨します。\n\n\nこの教科書では、紛らわしい表現を避けるため、様々な要素(利子率とか割引率とか投資収益率とか)を記号で表現します。ここでは、それらの記号の意味を説明しておくので、分からなくなったら随時ここに戻って確認するようにしてください。\n\nキャッシュ・フロー(Cash Flow)：CF\n無リスク利子率(Risk-Free rate)：r_F\nネット・リターン(net return) : r\nグロス・リターン(gross return) : R = 1 + r\n現在価値(Present Value)：PV\n銘柄(i) : i = 1, 2, \\dots , n, \\dots , N\n期間や時点(Time)：t = 1, 2, \\dots , T\n\n次に、定数(constant)と確率変数(random variable)について説明します。\n定数とはある特定の数を意味します。例えば、1や52や0.1などです。 定数は定まった数ですので、不確実性はありません。\n確率変数(random variable)は、ある値をとる確率が定義されている変数です。 例えばサイコロの出目は確率変数です。サイコロの出目は1から6までの値をとりますが、どの値が出るかは確定していません。しかし、1から6までの値が出る確率は等しく1/6です。このように、確率変数はある値をとる確率が定義されている変数です。 確率変数であることを明示するために、確率変数には~(チルダ)をつけて表記します。たとえば確率変数Xは\\tilde{X}で表記します。\n確率変数は、どの値がどの確率で出るのかは分かっていますが、実際どの値が観察されるのかは分かりません。そのため、確率変数は期待値(expectation)と分散(variance)を持ちます。 以下では、期待値を表す演算子として\\mathbb{E}[\\cdot]を、分散を表す演算子として\\mathbb{V}[\\cdot]を用います。 ファイナンスや会計学では、リスクを分散で表します。 「リスクがある」とは、結果として実現する値がばらつくことを意味します。 結果が確実に分かっている場合は、リスクがない、つまり分散が0の場合です。\n\n\nよく出てくるものをまとめておきます。\n足し算をまとめて書くときは、\\sumを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを足し合わせるときは以下のように書きます。\n\nx_1 + x_2 + x_3 + \\cdots + x_n\n\nこれを\\sumを使って書くと以下のようになります。\n\n\\sum _{i = 1}^n x_i\n\nこのほうがシンプルです。\n掛け算をまとめて書くときは、\\prodを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを掛け合わせるときは以下のように書きます。\n\nx_1 \\times x_2 \\times x_3 \\times \\cdots \\times x_n\n\nこれを\\prodを使って書くと以下のようになります。\n\n\\prod _{i = 1}^n x_i\n\n離散的な変数xの期待値は以下のように書きます。\n\n\\mathbb{E}[x] = \\sum _{i = 1}^n x_i p_i\n\nここで、p_iはx_iが観測される確率です。 たとえばサイコロの出目Xは\\{1,2,3,4,6\\}の値を、それぞれ1/6の確率で出す確率変数です。サイコロの出目の期待値は、\n\n\\begin{align*}\n\\mathbb{E}[X] &= \\frac 16 \\times 1 + \\frac 16 \\times 2 + \\frac 16 \\times 3 + \\frac 16 \\times 4 + \\frac 16 \\times 5 + \\frac 16 \\times 6\\\\\n& = 3.5\n\\end{align*}\n\nとなります。\n次に、確率変数の分散は、\n\n\\mathbb{V}[x] = \\sum _{i = 1}^n (x_i - \\mathbb{E}[x])^2 p_i\n\nと書きます。これもサイコロの例で考えてみましょう。 サイコロの出目の分散は、\n\n\\begin{align*}\n\\mathbb{V}[X] &= \\frac 16 \\times (1 - 3.5)^2 + \\frac 16 \\times (2 - 3.5)^2 + \\frac 16 \\times (3 - 3.5)^2 \\\\\n&+ \\frac 16 \\times (4 - 3.5)^2 + \\frac 16 \\times (5 - 3.5)^2 + \\frac 16 \\times (6 - 3.5)^2\\\\\n& = 2.916666666666666534\n\\end{align*}\n\nと計算できます。\n\n\n\n期待値について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{E}[a] = a \\\\\n&\\mathbb{E}[a \\tilde X] = a \\mathbb{E}[\\tilde X]\\\\\n&\\mathbb{E}[\\tilde X + a] = \\mathbb{E}[\\tilde X] + a\\\\\n&\\mathbb{E}[\\tilde X + \\tilde Y] = \\mathbb{E}[\\tilde X] + \\mathbb{E}[\\tilde Y]\n\\end{align}\n\n\n\n1つめの式は、定数aの期待値はaであることを意味します。 2つめの式は、定数aと確率変数\\tilde Xの積の期待値は、定数aと確率変数\\tilde Xの期待値の積に等しいことを意味します。 3つめの式は、確率変数\\tilde Xに定数aを足したものの期待値は、確率変数\\tilde Xの期待値に定数aを足したものに等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の期待値は、確率変数\\tilde Xの期待値と確率変数\\tilde Yの期待値の和に等しいことを意味します。\n特に4つめの公式は重要で、和の期待値は期待値の和となることを意味してます。よく使うので覚えておいてください。\n正6面体のサイコロの出目Xと正4面体のサイコロの出目Yの和の期待値は、\n\n\\begin{align*}\n\\mathbb{E}[X] &= 3.5\\\\\n\\mathbb{E}[Y] &= \\frac 14 \\times 1 + \\frac 14 \\times 2 + \\frac 14 \\times 3 + \\frac 14 \\times 4 = 2.5\\\\\n\\mathbb{E}[X + Y] &= \\mathbb{E}[X] + \\mathbb{E}[Y] = 3.5 + 2.5 = 6\n\\end{align*}\n\nとなります。\n\n\n\n分散について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{V}[a] = 0\\\\\n&\\mathbb{V}[a \\tilde X] = a^2 \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + a] = \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + \\tilde Y] = \\mathbb{V}[\\tilde X] + \\mathbb{V} [\\tilde Y] + \\mathbb{Cov}(X,Y)\\\\\n&\\mathbb{V}[\\tilde X] = \\mathbb{E}[\\tilde X^2] - \\mathbb{E}[\\tilde X]^2\\\\\n\\end{align}\n\n\n\n1つめの式は、定数aの分散は0であることを意味します。自明ですね。 2つめの式は、定数aと確率変数\\tilde Xの積の分散は、定数aの2乗と確率変数\\tilde Xの分散の積に等しいことを意味します。1つめの式から明らかですね。\n3つめの式は、確率変数\\tilde Xに定数aを足したものの分散は、確率変数\\tilde Xの分散に等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の分散は、確率変数\\tilde Xの分散と確率変数\\tilde Yの分散と共分散の和に等しいことを意味します。これもよく出てくるので覚えておいてください。\n5つめの式は、確率変数\\tilde Xの分散は、確率変数\\tilde Xの2乗の期待値から確率変数\\tilde Xの期待値の2乗を引いたものに等しいことを意味します。 つまり分散の計算は、確率変数の2乗の期待値から期待値の2乗を引くことで計算できるということです。これ重要です。 先のサイコロの例で確認してみます。\n\n\\begin{align*}\n\\mathbb{V}[X] &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n&= \\frac 16 \\times 1^2 + \\frac 16 \\times 2^2 + \\frac 16 \\times 3^2 + \\frac 16 \\times 4^2 + \\frac 16 \\times 5^2 + \\frac 16 \\times 6^2 - 3.5^2 \\\\\n&= 15.16667 - 12.25 \\\\\n&= 2.916667\n\\end{align*}\n\nとなり、上で計算した分散と一致します。"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "7  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Chap02.html",
    "href": "Chap02.html",
    "title": "2  ファイナンス入門",
    "section": "",
    "text": "第2章ファイナンスでは、\nの3つを学習します。 学習目標として、"
  },
  {
    "objectID": "Chap02.html#割引率",
    "href": "Chap02.html#割引率",
    "title": "2  ファイナンス入門",
    "section": "2.1 割引率",
    "text": "2.1 割引率\nファイナンスでは，ある財の今の価値と将来の価値は異なる，という考えが基礎にあります。 今の100万円と1年後の100万円の価値は異なるのです。 この現在の価値と未来の価値をつなぐ概念を割引率(discount rate)といい，将来キャッシュ・フローを現在価値(present value)に変換する際に用いる値です。 ファイナンス(finance)という学問は、この割引率がどのように決まるのかを明らかにする研究分野であるといえます。\n\n2.1.1 確実なキャッシュ・フローに対する割引率\nまず、確実に得られるキャッシュ・フローに対する割引率を考えてみましょう。 確実に得られる、とは特定の結果が確率1で実現することを意味します。\n用語の意味は以下の通りです。\n\n現在価値 ：一般に将来発生するキャッシュフローの現時点における価値\n時間価値 ：将来と現在の価値の違い\n無リスク金利 (risk-free rate) ：安全資産(無リスク資産)へと投資したときのリターンであり，安全資産への投資時点でリターンとして獲得できる額が確定します。 無リスク金利は確率変数ではなく定数(parameter)として扱います。\n\nT年後の確実なキャッシュフローをCF_Tで表し，無リスク割引率を無リスク金利r_Fとすると，その現在価値は以下のように計算されます。\n\nPV = \\frac{CF_T}{(1 + r_F)^T}\n\n\n\n\n\n\n\nノート\n\n\n\n現時点でCF_0を1年間貯金します。預金金利rは10％(つまりr = 0.1)とします。 1年後に受け取れるキャッシュ・フローCF_1は、貯金した元本CF_0と利息CF_0 \\times 0.1となります。 つまり、CF_0 + CF_0 \\times 0.1 = ( 1 + 0.1 ) CF_0です。\n逆に、来年CF_1受け取るためには、今いくら貯金するかを考えてみましょう。 来年CF_1受け取るために今必要な貯金額をXとすると、 X \\times (1 + 0.1) = CF_1となる。 つまりX = CF_1 / (1.1)となります。 このXが表している金額が，1年後に受け取るCF_1の現在価値(present value)となります。\n\n\n将来の確実なキャッシュ・フローCF_Tの現在価値は、無リスク割引率r_Fと将来受け取る時点であるTに依存して決まります。 CF_T = 100の場合、r_FとTの変化に応じて現在価値がどのように変化するのか確認してみましょう。\nT=1として(時点を固定して)、横軸を無リスク割引率r_F、縦軸を現在価値PVとしたグラフが以下のものです。 割引率が大きくなるにつれて現在価値が小さくなることが分かります。\n\nT = 1 # 時点を1とする\nr_F <- c(0.01, seq(0.1,1, by = 0.01)) #0.1から1の間を0.01刻みで変化\nPV <- 100/(1+r_F)^T # 現在価値\ndf <- data.frame(r_F, PV) # データフレームの作成\n# 作図\nggplot(df) + aes(x = r_F, y = PV) + geom_line(color = \"blue\") +\n  xlab(\"割引率\") + ylab(\"現在価値\") + mystyle\n\n\n\n\n次に、無リスク利子率r_F = 0.1として、横軸を時点T、縦軸を現在価値PVとしてグラフが以下のものです。 キャッシュ・フローCFを受け取る時点が遠くなるほど(T\\rightarrow \\infty)、現在価値が小さくなる(PV \\rightarrow 0)ことがわかります。\n\nr_F <- 0.1\nT <- c(seq(0,10, by = 0.1))\nPV <- 100/(1 + r_F)^T\ndf <- data.frame(T, PV)\nggplot(df) + aes(x = T, y = PV) + geom_line(color = \"red\") +\n  xlab(\"T年後\") + ylab(\"現在価値\") + mystyle\n\n\n\n\n\n\n2.1.2 不確実なキャッシュ・フローに対する割引率\nリスクプレミアム(risk premium)の反映が割引率の2つ目の役割です。 普通、将来に得られるキャッシュ・フローCFがいくらになるのか分かりませんし、将来CFは様々な要因に影響を受けて変化する確率変数(random variable)ですので、現時点における期待値(expected value)で評価することにします。\n\n\n\n\n\n\n期待値\n\n\n\nここで、期待値をとる演算子(operator)を\\mathbb{E}で表し、期待値をとる時点を添え字で表す。ここでは現時点t=0における期待値を\\mathbb{E}_0と表現している。 たとえば，現時点をt=0として，1期先に起こりうる結果Xが100か200であることが分かっていて，それぞれの発生確率が50%であったとする。この将来に起こりうる結果を現時点での情報を基に期待値をとる，ということは，\n\n\\mathbb{E}[X] = 0.5 \\times 100 + 0.5 \\times 200 = 150\n\nとなる。このように起こりうる結果と発生確率を掛けて足したものを期待値という。\n\n\nリスクプレミアム(risk premium)は割引率の調整で定量化されます。 つまり、リスクの高い投資に対しては無リスク利子率r_Fにリスクプレミアムを加えたリスク調整済みの割引率を用いることになります。\n\nPV_0 = \\frac{\\mathbb{E_0}[\\widetilde {CF}_1]}{1+r_F+\\underbrace{(\\widetilde{r}-r_F)}_{\\text{リスクプレミアム}}}=\\frac{\\mathbb{E_0}[\\widetilde {CF}_1]}{\\underbrace{1+\\widetilde{r}}_{\\text{リスク調整済み割引率}}}\n\n割引率は時間価値やリスクプレミアムに関する定量的な情報を含むので、タイミングやリスクの異なるキャッシュフローを現在価値という同一の尺度で評価できるようになります。\n\n\n2.1.3 NPV法\nNPV法とは、割引現在価値(net present value: 以下NPV)を基準に投資の意思決定を行う考え方をいう。\n投資を目論む現時点を時点0とする。 0時点におけるキャッシュ・フローCF_0は初期投資を意味します。 つまり企業の財布から現金が減るためマイナスとなります。\n向こうT年間にわたり毎年\\mathbb{E}[\\widetilde{CF}_t],\\quad t = 1,\\dots ,Tの期待キャッシュフローが生み出されるならば、それらを割引率1 + \\widetilde{r}で現在価値に直して足し合わせた値(つまりNPV)が、現時点で評価したプロジェクトの成果となります。\nNPVはそのプロジェクトから発生するすべてのキャッシュフローの現在価値として解釈できます。 コーポレートファイナンスでは，\n\nNPVがゼロ以上のプロジェクトは投資を実行\nNPVが負のプロジェクトは投資を見送る\n\nことで企業価値を最大化する投資を行うことになります。\n\n\n\n\n\n\n例: プロジェクトA\n\n\n\n\n現時点(t=0)で280万円の初期投資が必要\n1年後に 115万円の期待キャッシュフロー\n2年後に 264.5万円の期待キャッシュフロー\n無リスク金利 0.1，リスクプレミアム0.05とするときの割引率0.15\n\nプロジェクトの成果を将来キャッシュフローの現在価値によって評価する。 2年分の将来キャッシュフローの現在価値を足し合わせて300万円\n\n\\text{プロジェクトAの成果} = \\frac{115}{1.15}+\\frac{264.5}{1.15^2}=300\n\nよって、NPV = -280 + 300 = 20 >0\n\n\n一般的なNPV法は以下のようにかかれる。\n\n\\begin{aligned}\nNPV_0 &= \\frac{CF_0}{(1+\\widetilde{r})^0}+\\frac{\\mathbb{E}[CF_1]}{(1+\\widetilde{r})^1}+\\frac{\\mathbb{E}[CF_2]}{(1+\\widetilde{r})^2}+ \\cdots +\\frac{\\mathbb{E}[CF_T]}{(1+\\widetilde{r})^T}\\\\\n&= \\underbrace{CF_0}_{\\tiny 初期投資額}+\n\\underbrace{\\sum_{t=1}^T\\frac{\\mathbb{E}[CF_t]}{(1+\\widetilde{r})^t}}_{\\tiny 現時点で評価した成果}\n\\end{aligned}\n\n\n\n2.1.4 配当割引モデル\nNPVの考え方を株式に適用する。株式から生み出される将来得られるキャッシュ・フローは、一株当たり配当(Dividend Per Share: DPS)であり、t時点の一株当たり配当をD_tで表す。 将来DPSは確率変数であるため期待値で考え、それを割引率\\widetilde{r}で割り引くことで、一株当たりの株式価値を求める。\n\n\\begin{aligned}\nP_0^* &= \\frac{\\mathbb{E_0}[\\tilde D_1]}{1 + \\widetilde r} + \\frac{\\mathbb{E_0}[\\tilde D_2]}{(1 + \\widetilde r)^2} + \\cdots + \\frac{\\mathbb{E_0}[\\tilde D_{\\infty}]}{(1 + \\widetilde r)^{\\infty}} \\\\\n&= \\sum^{\\infty}_{t=1}\\frac{\\mathbb{E_0}[\\tilde D_t]}{(1+\\widetilde{r})^t}\n\\end{aligned}\n\n\n\n2.1.5 ゴードン成長モデル\n期待DPSが一定の割合で成長していくと仮定した割引配当モデルをゴードン成長モデルという。 直近の実現したDPSをD_0と置き、将来にわたってこの配当の期待値が一定割合G%で成長していくと仮定する。つまり1時点先の配当額が(1 + G)D_0となる、と仮定する。 すると、t時点先の配当額\\mathbb{E}[D_t]は、\n\n\\begin{aligned}\n\\mathbb{E}[D_t] &= D_0 \\times \\underbrace{(1+G) \\times \\cdots \\times (1+G)}_{複利でt回}\\\\\n&= (1+G)^tD_0\n\\end{aligned}\n\nで表すことができる。 一定割合で配当額が成長する株式の理論価値P_0を配当割引モデルで計算すると，\n\n\\begin{aligned}\nP_0 &= \\frac{(1+G) D_0}{(1+\\widetilde{r})} + \\frac{(1+G)^2 D_0}{(1+\\widetilde{r})^3} + \\frac{(1+G)^3 D_0}{(1+\\widetilde{r})^3} + \\cdots \\\\\n    &= \\sum^{\\infty}_{t=1}\\frac{(1+G)^tD_0}{(1+\\widetilde{r})^t} \\\\\n    &=\\frac{(1+G)D_0}{\\widetilde{r}-G}\n\\end{aligned}\n\n2本目の式から3本目の式への計算で、等比級数の和の公式を利用している。\n\n\n\n\n\n\nノート\n\n\n\n初項a，公比rの等比数列\n\na, ar, ar^2, ar^3, \\dots , ar^{n-1},ar^n , \\dots\n\nがある。この等比数列の和をS_nで表す。\n\nS_n = a + ar + ar^2 + \\cdots + ar^{n-1} + \\cdots\n\n両辺にrを乗じると，\n\nrS_n =  ar + ar^2 + \\cdots + ar^{n-1} + ar^{n} + \\cdots\n\nとなる。そして，S_n - rS_nを計算すると，\n\n\\begin{aligned}\nS_n - r S_n &= a\\\\\n(1-r)S_n &= a\\\\\nS_n &= \\frac{a}{1-r}\n\\end{aligned}\n\n上のゴードン成長モデルの初項は(1+G)D_0/(1+\\widetilde r)，公比は(1 +G)/(1+\\widetilde r)なので，\n\n\\begin{aligned}\nS_n\n%P_0^* &= \\frac{(1+G)D_0}{1+ \\widetilde r} + \\frac{(1+G)^2 D_0}{(1+ \\widetilde r)^2} + \\frac{(1+G)^3 D_0}{(1+ \\widetilde r)^3} + \\cdots \\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)D_0}{(1 + \\widetilde r)}}{1 - \\frac{1+G}{1+\\widetilde r}}\\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\widetilde r)}D_0}{\\frac{(1+ \\widetilde r) - (1+G)}{1+\\widetilde r}}\\\\\n%&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\widetilde r)}D_0}{\\frac{\\widetilde r - G}{1+\\widetilde r}}\\\\\n&= \\displaystyle  \\frac{1+G}{\\widetilde r - G}D_0\\\\\n\\end{aligned}\n\nただし，\\widetilde{r} \\not = Gの場合のみである。\n\n\n\n\n2.1.6 割引率と期待リターンの関係\n割引率Rは投資家が将来キャッシュフローを購入するにあたって最低限要求する期待リターン(要求収益率)とも解釈できる。\n\n\n\n\n\n\n例\n\n\n\n1年後の期待DPSが100万円で配当支払後に即解散する予定(=DPSがゼロ)の企業の理論株価を考える。 たとえば，確率50%で配当が200となるが，確率50％で配当が0となる株式を考えてみる。期待配当は，0.5 \\times 200 + 0.5 \\times 0 = 100となる。\nリスク調整済みの割引率r = 0.25であるときの現在価値は100/(1 + 0.25)で理論株価は80万円となる。 この株式を購入するか検討している投資家にとって、「現時点でこの株式を購入し、1年後に配当を受け取ることは一種の投資プロジェクト」とみなせる。 この投資プロジェクトに対して必要な投資額は現時点の株価P_0であり、現時点で評価した成果は配当として受け取り予定の将来キャッシュフローの現在価値P^*_0である。 よって、\n\nNPV = -P_0 + P_0^*\n\nしたがって、市場価値が理論株価以下である限り、NPVが非負となるためこの株式を購入することが経済合理的である。\n\nNPV  \\geq 0 \\Leftrightarrow P_0 \\leq P^*_0 =80\n\nつまり株式を80未満の価格で購入できれば、NPVがプラスとなる。"
  },
  {
    "objectID": "Chap02.html#平均分散アプローチ入門",
    "href": "Chap02.html#平均分散アプローチ入門",
    "title": "2  ファイナンス入門",
    "section": "2.2 平均分散アプローチ入門",
    "text": "2.2 平均分散アプローチ入門\n個々の投資家にとって最適となる証券の組み合わせの比率を決めることを最適ポートフォリオ選択という。 分散投資によりリスクを逓減できる、という現象がなぜ生じるのかを、数理的に明らかにする。 このアプローチを平均・分散アプローチといい、ポートフォリオの望ましさを、ポートフォリオのリターンの期待値と分散で評価する。\n\n2.2.1 ポートフォリオのリスクとリターン\nいま、銘柄Aと銘柄Bの2銘柄のみが投資対象である場合を考える。 それぞれの銘柄への投資割合をw_Aとw_Bとし、w_A + w_B = 1とする。\n\n元本 X\n投資銘柄Aのリターン 1 + r_A\n投資銘柄Bのリターン 1 + r_B\n\n元本Xのうちw_A分だけ銘柄Aに投資すると、1年後に期待値で\\mathbb{E}[X \\times w_A \\times (1+r_A)]になる。銘柄Bについても同様に考えると、手元にある元本を全額銘柄AとBに振り分けると、\n\n\\begin{aligned}\n(1 + r_A) w_A X + ( 1 + r_B) w_B X\n& = w_A X + w_A r_A X + w_B X + w_B r_B X\\\\\n& = \\left [\\underbrace{(w_A + w_B)}_{\\text{定義より} = 1}+(w_A r_A + w_B r_B) \\right ]X\\\\\n& = (1 + w_A r_A + w_B r_B) X\n\\end{aligned}\n\nとなる。元本を2銘柄に投資すると、1年後に(1+w_Ar_A+w_Br_B)Xとなる。 1年後の価値と初期投資額の比としてこのポートフォリオのリターンr_Pを計算する。\n\n\\begin{aligned}\n\\frac{\\overbrace{(1 + r_A) w_A X + (1 + r_B)w_B X}^{将来時点の評価額}}{\\underbrace{X}_{初期投資}} & = 1 + w_A r_A + w_B r_B\n\\end{aligned}\n\nここで、w_A r_A + w_B r_B = r_Pとおくと、\n\n\\text{ポートフォリオのリターン} = 1 + r_P\n\nとなる。 元本を除いたポートフォリオのリターンr_Pは、構成銘柄のリターンを保有比率で加重平均した値となる。\n\n\n\n\n\n\nノート\n\n\n\nリターンの定義(P_t - P_{t-1})/P_{t-1} = P_t/P_{t-1} -1はネット・リターン(net return)と呼ばれるものである。ここでは小文字のrで表す。 これにたいして，元本も含めたリターン1 + R_t = P_t/P_{t-1}はグロス・リターン(gross return)という。ここでは大文字のRで表す。\n\n\nポートフォリオ構築時には、各銘柄の実現リターンはわからないので(つまり確率変数)、かわりに期待値や分散を評価する。\n銘柄Aと銘柄Bのネット・リターンの\n\n期待値\\mathbb{E}[r_A]と\\mathbb{E}[r_B]をそれぞれ(\\mu_A,\\mu_B)\n分散\\mathbb{V}[r_A]と\\mathbb{V}[r_B]をそれぞれ(\\sigma^2_A,\\sigma^2_B)\n共分散\\mathbb{Cov}[r_A, r_B]を\\sigma_{AB}\n\nで表す。\nリターンr_Aとr_Bの相関係数を\\rhoと表記する。相関係数の定義から、\n\n\\begin{aligned}\n\\rho\n%&= \\frac{\\mathbb{E}[(r_A - \\bar r_A)(r_B - \\bar r_B)]}{\\mathbb{E}[(r_A - \\bar r_A)^2]}\n&= \\frac{\\sigma _{AB}}{\\sigma _A \\sigma _B} \\\\\n\\Leftrightarrow \\sigma_{AB} & = \\rho\\sigma_A\\sigma_B\n\\end{aligned}\n\nが成立する。\n上の式より、r_P = w_A r_A + w_B r_Bであるから、その期待値\\mathbb{E}[r_P] = \\mu_Pも各銘柄の期待リターンの加重平均となる。ここで投資割合w_Aとw_Bはパラメータであり，r_A, r_Bは確率変数である。\n\n\\begin{aligned}\n\\mathbb{E}[R_p] = \\mu_P &= \\mathbb{E}[w_A r_A + w_B r_B]\\\\\n&= w_A \\mathbb{E}[r_A] + w_B \\mathbb{E}[r_B]\\\\\n&=w_A\\mu_A+w_B\\mu_B\n\\end{aligned}\n\nポートフォリオPの分散\\mathbb{V}[r_P] = \\sigma^2_Pは各銘柄の分散及び相関係数を用いて計算できる。\n\n\\begin{aligned}\n\\mathbb{V}[r_P] = \\sigma_P^2 &= \\mathbb{V}[w_A r_A + w_B r_B]\\\\\n&= w_A^2 \\mathbb{V}[r_A] + w_b^2 \\mathbb{V}[r_B] + 2 w_A w_B \\mathbb{Cov}[r_A,r_B]\\\\\n&= w_A^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2w_A w_B \\sigma _{AB}\\\\\n&= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B +\n\\underbrace{2 w_A w_B \\rho \\sigma_A \\sigma_B}_{ここの\\rho の符号が重要}\n\\end{aligned}\n\nポートフォリオPの分散は，各銘柄の分散に投資割合の二乗を乗じたものに，各銘柄のリターンの相関関係部分を加えたものとなっている。 つまり，この2銘柄のリターンの相関係数\\rhoに応じて，ポートフォリオPの分散が大きくなるかどうかが決まる，ということである。\n\n\n2.2.2 分散投資のメリット\n保有比率(w_A,w_B)を変化させたときのポートフォリオの\\mu_Pと\\sigma_Pがそのように変化するかを確認する。\n\n\\begin{aligned}\n\\mathbb{V}[r_P] = \\sigma_P^2 &= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n&= (w_A \\sigma_A + w_B \\sigma_B)^2 - 2w_A  w_B \\sigma _A \\sigma_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n&= (w_A \\sigma_A + w_B \\sigma_B)^2 - (2 + 2\\rho ) w_A w_B\\sigma_A\\sigma_B\\\\\n&=(w_{A} \\sigma_{A} + w_{B}\\sigma_{B})^{2} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{ここ重要}\n\\end{aligned}\n\n0 \\leq w_{A} \\leq 1かつ 0 \\leq w_{B} \\leq 1のとき、\n\n2 ( 1- \\rho ) w_A w_b \\sigma _A \\sigma _B \\geq 0\n\nとなる(\\rho = 1のときのみ0となる)。 したがって、\n\n\\begin{aligned}\n\\sigma_P^2 = (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{\\geq 0}\n\\end{aligned}\n\nから、\n\n\\begin{aligned}\n& \\sigma _P^2 \\leq (w_A \\sigma _A + w_B \\sigma _B)^2 \\\\\n\\Longleftrightarrow & \\sigma_{P}  \\leq\n\\underbrace{w_{A}\\sigma_{A}+w_{B}\\sigma_{B}}_{リスクの加重平均}\n\\end{aligned}\n\nとなり，ポートフォリオのリスクを表す標準偏差\\sigma_Pが銘柄AとBの標準偏差の加重平均w_{A}\\sigma_{A} + w_{B} \\sigma_{B}より少なくとも低くなることがわかる。 これを分散投資効果という。\n\n# text p.65\n# 設定\nrho = 0.2\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(0,1,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb * mu_B,\n  sigma_p = sqrt(wa^2 * sigma_A^2 + wb^2 * sigma_B^2 + 2 * rho * wa * wb * sigma_A * sigma_B),\n  label= c(\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\")\n  )\n\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n完全な負の相関(\\rho=-1)であるの場合、\\sigma^{2}_{P}=0のポートフォリオを構築できる。 確認のため、2銘柄の価格が完全な負の相関\\rho = -1をもつとき、ポートフォリオPのリスク\\sigma_Pは\n\n\\begin{aligned}\n\\mathbb{V}[r_P] = \\sigma ^2_P &=(w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2}-2(1- (-1))w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 + w_B^2\\sigma _B^2 + 2w_A w_B \\sigma_A \\sigma_B -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 - 2w_{A}w_{B} \\sigma_{A}\\sigma_{B} + w_B^2\\sigma _B^2 \\\\\n&= (w_{A}\\sigma_{A} - w_{B}\\sigma_{B})^{2}\\\\\n\\sigma _P &= | w_{A}\\sigma_{A} - w_{B}\\sigma_{B}|\n\\end{aligned}\n\n以下のように，w_A \\sigma _A = w_B \\sigma_Bとなるようにw_Aとw_Bを選べば、\\sigma _P = 0となるポートフォリオを作れる。\n\n# text p.65\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n\nwa <- seq(0,1,by = 0.01)\nwb <- 1 - wa\n\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb*mu_B,\n  sigma_p = abs(wa*sigma_A - wb*sigma_B),\n  label= c(\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\")\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\nこのケースでは、\\sigma_A = 0.2、\\sigma_B = 0.3となっているため、0.2w_A = 0.3w_Bとなる保有割合を考える。\n\n\\begin{aligned}\n0.2 w_A &= 0.3w_B\\\\\n0.2 w_A &= 0.3(1-w_A)\\\\\n0.2 w_A &= 0.3 - 0.3w_A\\\\\n0.5 w_A &= 0.3\\\\\nw_A &= 0.6\n\\end{aligned}\n\nとなるため、銘柄Aに60％、銘柄Bに40%を投資することで、リスクゼロで期待リターン0.6\\times0.1 + 0.4 \\times 0.2 = 0.14を獲得することができる。\n\n\n2.2.3 空売りの効果\n空売り(short sale)とは、 1. 保有していない証券を誰か(普通は証券会社)から借りてきて売却し、 2. 一定期間後に買い戻して元の持ち主に返却する 取引をいい、値下がりから利益を得る。 空売りを行う投資家をショートセラー(short seller)という。\nいままでは、0 \\leq w_A,w_B \\geq 1＄という制約を置いていたが、この制約をはずして、 w_A + w_B = 1のみを課す。つまりw_A<0やw_B<0が空売りを表す。\n\nrho = 0.2\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb*mu_B,\n  sigma_p = sqrt(wa^2 * sigma_A^2 + wb^2 * sigma_B^2 + 2 * rho * wa * wb * sigma_A * sigma_B),\n  label= c(\n  rep(\"\",100),\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\" , rep(\"\",100)\n  )\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n\n\n2.2.4 安全資産の導入\n安全資産の購入についても考える。\n安全資産Fのリターンをr_F、 ポートフォリオPの保有比率をw_Fとおく（安全資産のリターンは確実に実現する成果なので，確率変数を表すチルダをつけてない）。 以降は，確率変数にはなるべくチルダをつける。銘柄Aと銘柄Bと安全資産の投資割合をそれぞれw_A, w_B, w_Fで表す。\nまず銘柄Aと安全資産の2資産からなるポートフォリオを考える。 つまり各資産への投資割合をw_A + w_F = 1,\\quad w_B = 0 とする場合を考える。 この安全資産と銘柄AからなるポートフォリオPの(ネット)リターン\\widetilde r_Pは，\n\n\\widetilde r_{P} = w_{F} R_{F} + w_{A} \\widetilde r_{A}\n\nとなり，このポートフォリオの期待値は，\n\n\\begin{aligned}\n\\mu_{P} =\\mathbb{E}[r_P] &=\\mathbb{E}[ w_F R_{F} + w_{A} \\widetilde{r_A} ]\\\\\n&=w_F R_{F}+w_{A} \\mathbb{E}[\\widetilde{r_A}]\\\\\n&=w_F R_{F}+w_{A} \\mu_{A}\\\\\n&=(1-w_A) R_{F}+w_{A} \\mu_{A}\\\\\n&=R_{F} - w_{A}r_F + w_A\\mu_A\\\\\n&=R_{F} + w_A(\\underbrace{\\mu_A - r_F}_{\\tiny リスクプレミアム})\n\\end{aligned}\n\nとなる。もちろん安全資産のリターンは確率変数でないので，期待値をとってもそのままである。 \\mu_{A}-R_{F} はリスク資産である銘柄Aのリスクプレミアムを表している。通常，リスクのある資産の期待リターンは安全資産のリターンより大きいため，リスクプレミアムは正の値となる。したがって，リスク資産への投資割合w_Aを1単位増加させれば，\\mathbb{E}[r_P]はリスクプレミアム分増加する\nつぎに，ポートフォリオのリスクを表す標準偏差\\sigma _Pとリターンの関係は次式で表せる。まず安全資産のリスクはゼロであるため，リスク資産の銘柄Ａを保有する分だけリスクが生じる。\nつぎに，ポートフォリオのリスクを表す標準偏差\\sigma _Pとリターンの関係は次式で表せる。まず安全資産のリスクはゼロであるため，リスク資産の銘柄Ａを保有する分だけリスクが生じる。\n\n\\begin{aligned}\n\\sigma_P^2 = \\mathbb{V}[r_P]  &= \\mathbb{V}[w_Fr_F + w_A r_A]\\\\\n&= \\mathbb{V}[w_A r_A]\\\\\n&= w_A^2 \\mathbb{V}[r_A]\\\\\n&= w_A^2 \\sigma _A^2 \\\\\n\\sigma _P & = |w_A| \\sigma_A\n\\end{aligned}\n\n空売りを想定する場合w_A < 0となるため，標準偏差を求める際に絶対値をとっている。空売りはない状況（つまり，w_A>0）を想定すると，\n\n\\begin{aligned}\n\\sigma _P = w_A \\sigma _A\\\\\nw_A = \\frac{\\sigma_P}{\\sigma _A}\n\\end{aligned}\n\nのように，リスク資産である銘柄Aへの投資割合w_Aが，ポートフォリオPとリスク資産Aのリスクの割合で決定されることがわかる。これを，ポートフォリオの期待リターン\\mu_Pに代入すると，\n\n\\begin{aligned}\n\\mu_{P} &= r_F + w_A(\\mu_A - r_F)\\\\\n& = r_F + \\frac{\\sigma_P}{\\sigma _A}(\\mu_A - r_F) \\\\\n&= R_{F}+\\frac{\\mu_{A}-R_{F}}{\\sigma_{A}}\\sigma_{P}\n\\end{aligned}\n\nとなり，期待リターン\\mu_Pは，切片がr_F，傾きが(\\mu_A - r_F)/\\sigma_Aとする\\sigma_Pの線形関数となる。\n\nr_F = 0.01\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = r_F + wa*(mu_A - r_F),\n  sigma_p = abs(wa)*sigma_A,\n  label= c(\n  rep(\"\",100),\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\" , rep(\"\",100)\n  )\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n\n\n2.2.5 3資産のポートフォリオ\nリスク資産AとB，安全資産Fの3資産に投資するポートフォリオを考える。 ここで，w_A + w_B > 0を仮定し，少なくとも少しはリスク資産を保有するケースを考える。 当然だけれど，w_A = w_B =0のケースでは，安全資産のみを保有するケースとなり，リスクも無く，リターンも確定している。\n3資産A,B,Fへの投資割合をそれぞれw_A，w_B,w_Fとすると， 3資産からなるポートフォリオの期待リターンは次のように計算できる。\n\n\\begin{aligned}\n\\mathbb{E}[R_{P}] &= w_Fr_F + w_A \\mathbb{E} [\\widetilde r_A] + w_B \\mathbb{E}[ \\widetilde r_B] \\\\\n& =\nw_{F} R_{F} + (w_{A} + w_{B}) \\left(\\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E} [\\widetilde r_{A}] + \\frac{w_{B}}{w_{A}+w_{B}} \\mathbb{E}[ \\widetilde r_{B} ]\\right)\n\\end{aligned}\n\n安全資産への投資割合w_Fとリスク資産への投資割合w_C = w_A + w_Bとまとめて，式を変形させる。 安全資産への投資以外の資金で構築したリスク資産AとBからなるポートフォリオをP_Cを考えると，P_Cの期待リターンR_Cは次のように計算できる。\n\n\\begin{aligned}\nR_{C} &= \\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E}[\\widetilde r_{A}] + \\frac{w_{B}}{w_{A}+w_{B}}\\mathbb{E}[ \\widetilde r_{B}]\\\\\n\\end{aligned}\n\n安全資産FとポートフォリオCを保有した場合の期待リターンは次式となる。\n\n\\begin{aligned}\n\\mu_{P} & = \\mathbb{E}[w_F r_F + w_A r_A + w_B r_B]\\\\\n&= w_Fr_F + w_A \\mathbb{E}[r_A] + w_B \\mathbb{E}[r_B]\\\\\n&= w_Fr_F + (w_A + w_B) \\underbrace{ \\left( \\frac{w_A}{w_A + w_B} \\mathbb{E}[r_A] + \\frac{w_B}{w_A + w_B} \\mathbb{E}[r_B] \\right )}_{=w_C\\text{とおく}}\\\\\n&= w_F r_F + w_{C}\\mu_C\n\\end{aligned}\n\n安全資産と2つのリスク資産からなるポートフォリオの期待リターンは，安全資産の期待リターンとリスク資産の期待リターンの和となる。\n安全資産と2つのリスク資産に投資可能な場合，(\\mu_P, \\sigma _P)の取りうる値を図示できる。テキストの数値例を用いてRで図示してみる。\n\nリスク資産Aの期待リターン 0.1，標準偏差 0.2\nリスク資産Bの期待リターン 0.2，標準偏差 0.3\n安全資産の期待リターンを 0.01\nリスク資産AとBの間の相関係数は0.2\n安全資産，銘柄A，銘柄Bへの投資割合を0.2，0.3，0.5とするポートフォリオを考える。このポートフォリオの期待リターン\\mu_Pと標準偏差\\sigma_Pは次のようになる。"
  },
  {
    "objectID": "Chap02.html#最適ポートフォリオ問題",
    "href": "Chap02.html#最適ポートフォリオ問題",
    "title": "2  ファイナンス入門",
    "section": "2.3 最適ポートフォリオ問題",
    "text": "2.3 最適ポートフォリオ問題\n「どのようなポートフォリオが投資家にとって望ましいか」\n一般に、投資家はリスクが小さい一方でリターンが大きいポートフォリオを好む。 ここでは，リターンをポートフォリオの期待リターン\\mu_P，リスクをポートフォリオの標準偏差\\sigma _Pで表し，この2つの変数から更正される平面(\\mu_P, \\sigma_P)上で最適ポートフォリオ問題を分析する。\n\n2.3.1 効率的フロンティア\nリスク資産Aと資産Bにのみ投資可能であり，それぞれに異なる割合で投資したポートフォリオDとＥを比較する(以下の図）\n\n標準偏差はともに0.25 \\sigma _D = \\sigma _E = 0.25\nDの方がEよりも期待リターンが大きい，\\mu _D > \\mu _E\n\nつまり，同じリスク（標準偏差）ならリターン（期待リターン）が高いポートフォリオに投資したほうがよい。よってリスク・リターンのトレードオフの意味でDの方がEよりも望ましい。 以下のグラフでいうと、同じリスク(緑のライン上)なら、リターンの高いポートフォリオが望ましい。そのため赤い実線が効率的フロンティアとなり、青い点線は選択されないポートフォリオになる。\n\n#w<- seq(0, 1, by = 0.01) # 所有ウェイト\nw <- seq(-1,2,by = 0.01)\n\nmu_a    <- 0.1 # 株式Aの期待収益率\nsigma_a <- 0.2 # 株式Aの分散\nmu_b    <- 0.2 # 株式Bの期待収益率\nsigma_b <- 0.3 # 株式Bの分散\nrho     <- 0.2 # 相関係数\nmu_p    <-  w * mu_a + (1 - w) * mu_b # ポートフォリオの期待リターン\nsigma_p <- sqrt((w * sigma_a + (1 - w) * sigma_b)^2 - 2*(1 - rho)*w*(1 - w)*sigma_a*sigma_b) # ポートフォリオの分散\ndf_plot <- data.frame(mu_p, sigma_p)\ndf_plot <- df_plot %>% dplyr::mutate(plus_dummy = as.factor(ifelse(mu_p >= 0.126, 1, 0)))\nggplot(df_plot) + aes(y = sigma_p, x = mu_p, color = plus_dummy, linetype = plus_dummy) +\nscale_linetype_manual(values = c(\"dashed\", \"solid\")) + geom_path() +\ngeom_hline(yintercept = 0.25, color = \"green\") + coord_flip() + mystyle\n\n\n\n\nリスク資産AとBに加え、安全資産Fにも投資可能な場合、効率的フロンティアは直線になる。 この場合、効率的フロンティアは資本市場線(Capital Market Line; CML)とも呼ばれる。 傾きは、この金融市場におけるリスクとリターンのトレードオフを表す。\n\n#w<- seq(0, 1, by = 0.01) # 所有ウェイト\nw <- seq(-1,2,by = 0.01)\n\nmu_a    <- 0.1 # 株式Aの期待収益率\nsigma_a <- 0.2 # 株式Aの分散\nmu_b    <- 0.2 # 株式Bの期待収益率\nsigma_b <- 0.3 # 株式Bの分散\nrho     <- 0.2 # 相関係数\nr_F     <- 0.01 # 無リスク利子率\n\nmu_p    <-  w * mu_a + (1 - w) * mu_b # ポートフォリオの期待リターン\nsigma_p <- sqrt((w * sigma_a + (1 - w) * sigma_b)^2 - 2*(1 - rho)*w*(1 - w)*sigma_a*sigma_b) # ポートフォリオの分散\ndf_plot <- data.frame(mu_p, sigma_p)\ndf_plot <- df_plot %>% dplyr::mutate(plus_dummy = as.factor(ifelse(mu_p >= 0.126, 1, 0)))\n\nggplot(df_plot) + aes(y = sigma_p, x = mu_p, color = plus_dummy, linetype = plus_dummy) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) + geom_path() + ylim(0,0.6) +\n  geom_hline(yintercept = 0.25, color = \"green\") + coord_flip() + mystyle\n\n\n\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = r_F + wa*(mu_A - r_F),\n  sigma_p = abs(wa) * sigma_A\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line()  + coord_flip()\n\n\n\n\n\n\n2.3.2 投資家のリスク回避度と最適ポートフォリオ\n効率的フロンティアのうち、どの点が投資家の最適ポートフォリオになるのか，について考える。 そのためには投資家のリスク・リターンのトレードオフに関する選好(preference)の特徴，つまりリスクの回避度の情報が必要となる。 (\\mu_P,\\rho_p)平面上でそれを描く方法の一つが無差別曲線(indifference curve)である。 無差別曲線とは，投資家の効用(utility)が一定となるリスクとリターンの組み合わせを描いた曲線をいう。つまり同じ効用水準を達成できるリスクとリターンの組み合わせを表現した曲線である。\n\n2.3.2.1 効用関数の例\n以下では，財xとyを消費したときの効用Uを図示している。この消費者の効用関数はU(x,y) = x^{\\frac 25} \\times y^{\\frac 35}としている。\n\nlibrary(Rsolnp)\nx <- 1:50\ny <- 1:50\nu <- function(x, y) {x^(2/5) * y^(3/5)} #効用関数を定義\nU <- outer(x, y, u) #outer()はx_1,x_2に対応したf(x_1,x_2)の値を行列で返す\npersp(x, y, U,\n      theta = 30, # 横回転の角度\n      phi = 30, # 縦回転の角度\n      ticktype = \"simple\", # 線の種類\n      lwd = 0.5, # 線の太さ\n      col = F,\n      border = 8)\n\n\n\n\nこの立体図を等高線を使って表現したものが以下の図である。 青いラインは予算制約であり、予算の範囲内で購入可能な財の組み合わせを意味している。つまり、この予算制約と無差別曲線が接する点が、予算内で達成可能な最も高い効用水準を表している。\n無リスク利子率が10%で，リスクプレミアムが5％，βが1.2の場合の期待リターンは，r_F + \\beta \\times (R_M - r_F) = 0.1 + 1.2 \\times 0.05 = 0.16となる。このときの無差別曲線は，U = 0.16となるような点を結んだ曲線となる。\n\ncontour(x, y, U, method = \"edge\", labcex = 1,lwd = 2)\nabline(a = 100/6, b = -4/6, lwd = 2, col = \"blue\") #予算制約線\npoints(x = 10, y = 10, lwd = 3, col = \"darkblue\", pch = 16) #最適消費点\n\n\n\n\n無差別曲線と消費可能集合\n\n\n\n\nリスクとリターンの無差別曲線\n\n\n\n無差別曲線と効率的フロンティアに基づく最適ポート フォリオの決定\n\n\n複数ポートフォリオを比べるとき，この図の左上のものほど高リターン低リスクに対応するので、より高い効用水準が実現する。 また無差別曲線の局所的な傾きは、その投資家が追加的なリスクを引き受けるうえで要求するリスクプレミアムを表す。 リスク回避的な投資家ほど，リスクを1単位負担する際に，より大きなリスクプレミアムを要求するので、傾きは大きくなる。 つまり，1単位リスクを負担する代わりに欲しいリターンの額が大きくなるほど，傾きが大きくなる。\n無差別曲線と効率的フロンティアが接する点が、この投資家にとっての最適ポートフォリオとなる。 投資可能なポートフォリオの範囲で、最も左上の無差別曲線を実現するのが接点となる。 どの点が最適ポートフォリオとして選ばれるかは個々の投資家の無差別曲線の形状(リスク回避度)に依存する。最適ポートフォリオにおいて、無差別曲線と効率的フロンティアの局所的な傾きは一致(接線だから当然)するため、その投資家が要求するリスクプレミアムがちょうど実現されている。\n上図の場合，この投資家の最適ポートフォリオは(w_F,w_{tan})\\approx(0.29,0.71)の比率で構成される。\n接点ポートフォリオは銘柄Aに47％、銘柄Bに53％投資するポートフォリオだったので、最適保有比率は、(w_F,w_A,w_B)\\approx(0.29,0.33,0.38)と書き換えられる。\n\n\n\n2.3.3 トービンの分離定理\n安全資産が投資可能な場合の最適ポートフォリオ問題を考える。\n\n接点ポートフォリオを求め、リスク資産同士の相対的な保有比率を求める。\n投資家ごとのリスク回避度に応じて安全資産と接点ポートフォリオの最適保有比率の決定\n\n1は各投資家で共通している。 いったん接点ポートフォリオを求めてしまえば、他の投資家はその情報を用いて2を考えればよい。\n最適ポートフォリオ問題を2段階に分離できるという命題は、トービンの分離定理(又は二基金文理定理)と呼ばれている。"
  },
  {
    "objectID": "Chap02.html#capm",
    "href": "Chap02.html#capm",
    "title": "2  ファイナンス入門",
    "section": "2.4 CAPM",
    "text": "2.4 CAPM\nここでは，資産価格モデルの1つである資本資産価格モデル(Capital Asset Pricing Model)について議論する。まずは各投資家の最適ポートフォリオ問題を所与として、金融市場全体の均衡に関して議論する。\n\n2.4.1 仮定の確認\n\n選好 : 全ての投資家はポートフォリオを期待値と標準偏差の基準で評価する\n取引コスト : 取引に際して手数料や税金が存在せず、空売りが自由に可能\n流動性 : どれだけ売買しても証券の価格は変化しない\n情報集合 : 全ての投資家は同じ情報を共有している\n\n上記の仮定を満たす金融市場のことを、一般に完全資本市場(完全市場: perfect market)と呼ぶ。 これは「取引を行う上で完全に摩擦のない市場」というものであり，理論上の設定である。\n厳密にいうと、上記の仮定のうちいずれも現実には成立しない。 しかし、単純で分析が容易なモデルから出発し、その含意が仮定にどう依存するか議論を深めていくというのが経済理論の標準的なアプローチである。 実際、以降で導出するCAPMに関してこれらの仮定を緩めた理論が数多く提唱されている。\n\n\n2.4.2 CAPMの第一命題\n以上の仮定を受け入れると安全資産が投資可能なとき，全ての投資家の最適ポートフォリオ問題に対してトービンの分離定理を応用することができる。 全ての投資家は安全資産と接点ポートフォリオに投資し、危険資産に限定すれば同質的なポートフォリオを保有する。 金融市場全体の均衡を議論するうえで、市場にその資産が供給されている以上、誰かがその最適ポートフォリオの一部として保有しているという、需要と供給の一致がポイントである。\n\n\n\n\n\n\n例\n\n\n\n\n市場に参加している投資家3名\n市場に供給されている危険資産が銘柄XとYだけ\n時価総額はXが800億円、Yが200億円　\n\nこの市場には合計1000億円の危険資産が存在するとする。 全ての投資家が保有するリスク資産の合計額も1000億円に一致するはず。 リスク資産に限定すれば，全ての(合理的な)投資家は接点ポートフォリオと同じ比率でリスク資産を保有しているので，銘柄XとYの保有比率は時価総額と同じ比率8:2になっていなければならない。\n\n\n\n\n銘柄X\n銘柄Y\n合計\n\n\n\n\n\nw_X=0.8\nw_Y=0.2\nw_X+w_Y=1\n\n\n投資家A\n480\n120\n600\n\n\n投資家B\n240\n60\n300\n\n\n投資家C\n80\n20\n100\n\n\n合計\n800\n200\n1000\n\n\n\n\n\n以上の議論をよりフォーマルに述べるために、市場ポートフォリオを導入する。\n\n\n\n\n\n\n市場ポートフォリオ\n\n\n\n市場ポートフォリオ (market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいう。厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれるが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多い。\n\n\n\n\n\n\n\n\nCAPMの第一命題\n\n\n\n市場ポートフォリオは接点ポートフォリオと一致し、効率的フロンティア(資本市場線)上に位置する。\n\n\n投資家は市場ポートフォリオに投資するとき、\\sigma_Mのリスクを背負う見返りとしてr_Fに加えて\\mu_M-r_Fだけ追加的な報酬を期待する。 この追加的な報酬を市場リスクプレミアム(market risk premium)という。したがってこの命題の下では、資本市場線を市場リスクプレミアム(\\mu_M-r_F)を利用して、以下のように表せる。\n\n\\mu_P = r_F + \\frac{\\mu_M - r_F}{\\sigma_M} \\sigma_P\n\n\n\n\nCAPM\n\n\n今までのパラメータをそのまま用いる。 接点ポートフォリオの保有比率は概ね47%を銘柄Aに、 53%を銘柄Bに投資するポートフォリオになった。CAPMの第一命題によると、この市場における銘柄AとBの時価総額比率は約0.47対0.53になっていなければならない。 この命題によると、各銘柄の期待リターンや分散から接点ポートフォリオを計算する必要はなく、単に時価総額加重で市場ポートフォリオを保有すればよい。\n\nパッシブ運用：幅広い銘柄に分散投資し、市場平均と同じようなパフォーマンスを目指す運用手法\nアクティブ運用：市場平均を上回るパフォーマンスを目指し、投資銘柄を絞ったり、投資比率を工夫したりする運用方法\n\n任意のポートフォリオの収益性を測る指標として、シャープ・レシオが提唱されている。シャープ・レシオは追加的なリスク・テイクによってどれだけリスクプレミアムを改善できるのかを表す指標。CAPMの第一命題によると、市場ポートフォリオはシャープ・レシオを最大化するという意味で最も効率的なポートフォリオであり、資本市場線の傾き\\frac{\\mu_M - r_P}{\\sigma_M}は市場ポートフォリオのシャープ・レシオと一致する。\n\n\\frac{\\mu_P-r_F}{\\sigma_P}\n\n\n\n2.4.3 CAPMの第二命題\n第二命題は個々の資産のリスクとリターンのトレードオフを数式で表現したもの。 ある証券に投資するときのリスクと、その証券に投資するときの期待リターンとの関係を知ることができるようになる。各投資家が証券iを追加的に保有する際、重要となるのは市場ポートフォリオとの相関。分散が大きい資産であっても、市場ポートフォリオと負に相関していれば、その資産を追加的に保有することでポートフォリオ全体のリスクは低減される。CAPMの第二命題は、この相関を以下のマーケット・ベータとして定量化する。 ※R_iは証券iのリターン、R_Mは市場ポートフォリオのリターン\nこの\\beta_iは市場ポートフォリオのリスクを1としてベンチマーク化し、その証券のリスクがベンチマークの1を上回るか下回るかを測るもの。\\beta_iが大きいほど証券iは投資家にとってリスクが大きいことを意味する。証券iのリスクはその証券のリターンの標準偏差ではなく、この\\beta_iによって測られる。\n\n\\beta_i = \\frac{\\mathbb{Cov}[R_i, R_M]}{\\mathbb{Var}[R_M]}\n\n金融市場全体が均衡しているには，リスクの高い証券はその分だけ期待リターンも高くなければならない。 \\beta_iが低いにもかかわらず期待リターンが高い証券があるなら、投資家は市場ポートフォリオから離れてその証券をさらに買い増しするインセンティブを持つ。 その結果、市場価格が上がり、期待リターンが下がるため、\\beta_iに応じた期待リターンが均衡で実現される。 CAPMの第二命題はこの均衡におけるリスクとリターンのトレードオフの関係を記述した式である。\nこれまでは市場リスクプレミアムを\\mu_M - r_Fと表記していたが、以後ではより一般的な\\mathbb{E}[R_M] - r_Fと表記する。\n\n\n\n\n\n\nCAPMの第二命題\n\n\n\n各証券のリスクプレミアムは、その証券のマーケット・ベータに比例する。 この式は、証券iのリスクプレミアム\\mathbb{E}[R_i]-r_Fを、\\beta_iと市場リスクプレミアム\\mathbb{E}[R_M]-r_Fに分解している。\n\n\n第二項の\\mathbb{E}[R_M]-r_Fは個々の証券には依存しない定数である。\n\n\\begin{aligned}\n\\mathbb{E}[R_i]-r_F = \\beta_i (\\mathbb{E}[R_M] - r_F)\\\\\n\\text{ただし、 } \\beta = \\frac{Cov[R_i,R_M]}{Var[R_M]}\n\\end{aligned}\n\n通常、市場リスクプレミアムは正の値をとるので、CAPMの第二命題によると、個々の証券のリスクプレミアムは\\beta_iに関して線形に増加する。 \\beta_iはあくまで市場ポートフォリオとの相関でリスクを定量化しているのがポイント。 いくら個々の証券のリスクが大きくても、それが市場ポートフォリオと相関しない固有リスクであれば、リスクプレミアムには反映されない。 期待値をとる前のR_iを分解して確認する。\n\nR_i = r_F + \\beta_i (R_M - r_F) + \\varepsilon_i\n\nここで\\varepsilon_iは期待値ゼロでR_Mと相関しない誤差項である。\n\n\\mathbb{E}[\\varepsilon_i] = 0, \\qquad \\mathbb{Cov}[\\varepsilon_i, R_M] = 0\n\n\n\\begin{aligned}\nVar[R_i] &= \\mathbb{Var}[\\beta_i R_M + \\varepsilon_i]\\\\\n& = \\beta_i^2 \\mathbb{Var}[R_M] + \\mathbb{Var}[\\varepsilon_i] + \\underbrace{\\mathbb{Cov}[\\beta_i R_M, \\varepsilon_i]}_{\\tiny =0}\\\\\n& = \\underbrace{\\beta_i^2 \\mathbb{Var}[R_M]}_{\\tiny 市場ポートフォリオとの相関による寄与分} + \\underbrace{\\mathbb{Var}[\\varepsilon_i]}_{\\tiny 誤差項による寄与分}\n\\end{aligned}\n\nR_iの分散を計算すると、市場ポートフォリオとの相関による寄与分と誤差項による寄与分に分解できる。 誤差項の分散が大きければその分だけR_iの分散も大きくなるが、証券iのリスクプレミアムは\\mathbb{E}[R_M]-r_Fのままで変化はない。\n\n\n2.4.4 証券市場線\n安全資産と複数の危険資産が投資可能な場合、投資家の最適ポートフォリオは各人のリスク回避度に応じて図2.14の左図の資本市場線の1点となる。CAPMの第二命題が示唆するように、各証券のリスクとリターンとの関係は図2.14の右図になる。縦軸に各証券の期待リターン、横軸に各証券のリスクを表すマーケット・ベータをとると、CAPMが完全に成立する世界では全ての資産が一直線上に並ぶ。この直線を証券市場線(Securities Market Line; SML)と呼ぶ。 現実は、必ずしもCAPMの第二命題は成立しておらず、CAPMが予測するリターン(証券市場線)からの縦方向からの乖離(これをアルファと呼ぶ)が見られる。\n図2.14挿入\n定義通り\\betaを計算すると銘柄Aは約0.63，銘柄Bは約1.33となる。 両者の期待リターン、および\\betaを図示すると証券市場線に乗っており、この仮想的な市場ではCAPMが成立していることがわかる。 CAPMはアクティブ運用の賛同者から激しい批判を浴びてきたが、歴史的にみるとパッシブ運用を採用する機関投資家は増え続けており、ファイナンス理論及び投資実務の双方に多大な影響を与えてきたと言って過言ではない。\n\n\n2.4.5 N資産が投資可能な場合への拡張\n今までは，リスク資産が銘柄AとBの二つしかない場合を分析してきたが，現実は多くのリスク資産が存在し、海外株式や債券、REIT(不動産投資信託)といったその他の投資可能な金融資産を含めればその数は飛躍的に増加する。 本節での平均分散アプローチやCAPMは危険資産の数が任意のN個であっても成立する。 ただしその場合は行列での表記が必須となる(第7章やサポートサイト4.5節参照)。\n一般に，平均分散の意味で効率的なポートフォリオ(平均分散ポートフォリオ)を計算するには、目標期待リターンを所与として、それを実現するポートフォリオの中でリスクを最小化するものを求める。 得られた期待リターンとリスクのペアを一点として、目標期待リターンを動かすとリスク・リターン平面上に双曲線が描ける。 この双曲線を平均分散フロンティアと呼び、効率的フロンティアはその上半分の領域である(確認済み)。\n一般に投資可能な資産の数が増えると、平均分散フロンティアは左上に移動し、投資家はより望ましいポートフォリオが実現できるようになる。 リスク資産AとBに加えてCが投資可能な状況を考えると投資可能な資産が増えたからと言って必ずしもその資産に投資する必要はない。w_C=0とすれば、投資家は危険資産AとBのみに投資可能だった場合と同じ投資機会集合を実現できる。 新しい危険資産が既存資産の組み合わせによって完全に再現できるような極端な例を除けば分散投資のメリットが生じるため、投資家はより望ましいリスク・リターンのトレードオフを実現できる。\n統計学における分散の定義は，N個の確率変数R_1,R_2,\\cdots,R_Nの共分散行列\\Sigmaの対角成分の和である。\n\n\\begin{align*}\n\\sigma^2=\\sum_{i=1}^N\\sum_{j=1}^N\\sigma_{ij}=\\sum_{i=1}^N\\sigma_{ii}\n\\end{align*}\n\nここで，\\sigma_{ij}はR_iとR_jの共分散であり，\\sigma_{ii}はR_iの分散である。 共分散行列\\Sigmaは対称行列であり，対角成分は分散を表す。 また，R_iとR_jの共分散は\\sigma_{ij}=\\sigma_{ji}である。 共分散行列の対角成分以外の成分は共分散を表す。\n\n\\begin{align*}\n\\Sigma=\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1N} \\\\\n\\sigma_{21} & \\sigma_{22} & \\cdots & \\sigma_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{N1} & \\sigma_{N2} & \\cdots & \\sigma_{NN} \\\\\n\\end{bmatrix}\n\\end{align*}\n\n上のは，N個の確率変数の共分散行列の定義である。Copilotで作成しました。"
  },
  {
    "objectID": "Chap02.html#数学の準備",
    "href": "Chap02.html#数学の準備",
    "title": "2  第2章 ファイナンス入門",
    "section": "2.1 数学の準備",
    "text": "2.1 数学の準備\n以下では、様々な要素(利子率とか割引率とか投資収益率とか)を記号で表現します。ここでは、それらの記号の意味を説明しておくので、分からなくなったら随時ここに戻って確認するようにしてください。\n\nキャッシュ・フロー(Cash Flow)：CF\n無リスク利子率(Risk-Free rate)：R_F\n現在価値(Present Value)：PV\n期間や時点(Time)：T\n\n次に、定数(constant)と確率変数(random variable)について説明します。\n定数とはある特定の数を意味します。例えば、1や52や0.1などです。 定数は定まった数ですので、不確実性はありません。\n確率変数(random variable)は、ある値をとる確率が定義されている変数です。 例えばサイコロの出目は確率変数です。サイコロの出目は1から6までの値をとりますが、どの値が出るかは確定していません。しかし、1から6までの値が出る確率は等しく1/6です。このように、確率変数はある値をとる確率が定義されている変数です。 確率変数であることを明示するために、確率変数には~(チルダ)をつけて表記します。\n確率変数はどの値がどの確率で出るのかは分かっていますが、実際どの値が観察されるのかは分かりません。そのため、確率変数は期待値(expectation)と分散(variance)を持ちます。 以下では、期待値を表す演算子として\\mathbb{E}[\\cdot]を、分散を表す演算子として\\mathbb{V}[\\cdot]を用います。 ファイナンスや会計学では、リスクを分散で表します。 「リスクがある」とは、結果として実現する値がばらつくことを意味します。 結果が確実に分かっている場合は、リスクがない、つまり分散が0の場合です。\n\n2.1.1 数式\nよく出てくるものをまとめておきます。\n足し算をまとめて書くときは、\\sumを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを足し合わせるときは以下のように書きます。 \nx_1 + x_2 + x_3 + \\cdots + x_n\n これを\\sumを使って書くと以下のようになります。 \n\\sum _{i = 1}^n x_i\n このほうがシンプルです。\n掛け算をまとめて書くときは、\\prodを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを掛け合わせるときは以下のように書きます。 \nx_1 \\times x_2 \\times x_3 \\times \\cdots \\times x_n\n これを\\prodを使って書くと以下のようになります。 \n\\prod _{i = 1}^n x_i\n 次に、$x = 1,2,3,4, $ といった離散的な変数xの期待値は以下のように書きます。 \n\\mathbb{E}[x] = \\sum _{i = 1}^n x_i p_i\n ここで、p_iはx_iが観測される確率です。 同様に、分散は、 \n\\mathbb{V}[x] = \\sum _{i = 1}^n (x_i - \\mathbb{E}[x])^2 p_i\n と書きます。\n\n\n2.1.2 期待値の特徴\n期待値について以下のような特徴があります。\n\n\n\n\n\n\nImportant\n\n\n\n\n\\begin{align}\n&\\mathbb{E}[a] = a \\\\\n&\\mathbb{E}[a \\tilde X] = a \\mathbb{E}[\\tilde X]\\\\\n&\\mathbb{E}[\\tilde X + a] = \\mathbb{E}[\\tilde X] + a\\\\\n&\\mathbb{E}[\\tilde X + \\tilde Y] = \\mathbb{E}[\\tilde X] + \\mathbb{E}[\\tilde Y]\n\\end{align}\n\n\n\n1つめの式は、定数aの期待値はaであることを意味します。 2つめの式は、定数aと確率変数\\tilde Xの積の期待値は、定数aと確率変数\\tilde Xの期待値の積に等しいことを意味します。 3つめの式は、確率変数\\tilde Xに定数aを足したものの期待値は、確率変数\\tilde Xの期待値に定数aを足したものに等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の期待値は、確率変数\\tilde Xの期待値と確率変数\\tilde Yの期待値の和に等しいことを意味します。\n特に4つめの公式は重要で、和の期待値は期待値の和となることを意味してます。よく使うので覚えておいてください。\n\n\n2.1.3 分散の特徴\n分散について以下のような特徴があります。\n\n\n\n\n\n\nImportant\n\n\n\n\n\\begin{align}\n&\\mathbb{V}[a] = 0\\\\\n&\\mathbb{V}[a \\tilde X] = a^2 \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + a] = \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + \\tilde Y] = \\mathbb{V}[\\tilde X] + \\mathbb{V} [\\tilde Y] + \\mathbb{Cov}(X,Y)\\\\\n&\\mathbb{V}[\\tilde X] = \\mathbb{E}[\\tilde X^2] - \\mathbb{E}[\\tilde X]^2\\\\\n\\end{align}\n\n\n\n1つめの式は、定数aの分散は0であることを意味します。自明ですね。 2つめの式は、定数aと確率変数\\tilde Xの積の分散は、定数aの2乗と確率変数\\tilde Xの分散の積に等しいことを意味します。1つめの式から明らかですね。\n3つめの式は、確率変数\\tilde Xに定数aを足したものの分散は、確率変数\\tilde Xの分散に等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の分散は、確率変数\\tilde Xの分散と確率変数\\tilde Yの分散と共分散の和に等しいことを意味します。これもよく出てくるので覚えておいてください。\n5つめの式は、確率変数\\tilde Xの分散は、確率変数\\tilde Xの2乗の期待値から確率変数\\tilde Xの期待値の2乗を引いたものに等しいことを意味します。 つまり分散の計算は、確率変数の2乗の期待値から期待値の2乗を引くことで計算できるということです。これ重要です。"
  },
  {
    "objectID": "index.html#数学算数の準備",
    "href": "index.html#数学算数の準備",
    "title": "実証会計・ファイナンスのノート",
    "section": "数学・算数の準備",
    "text": "数学・算数の準備\nこの教科書では、紛らわしい表現を避けるため、様々な要素(利子率とか割引率とか投資収益率とか)を記号で表現します。ここでは、それらの記号の意味を説明しておくので、分からなくなったら随時ここに戻って確認するようにしてください。\n\nキャッシュ・フロー(Cash Flow)：CF\n無リスク利子率(Risk-Free rate)：R_F\n現在価値(Present Value)：PV\n期間や時点(Time)：T\n\n次に、定数(constant)と確率変数(random variable)について説明します。\n定数とはある特定の数を意味します。例えば、1や52や0.1などです。 定数は定まった数ですので、不確実性はありません。\n確率変数(random variable)は、ある値をとる確率が定義されている変数です。 例えばサイコロの出目は確率変数です。サイコロの出目は1から6までの値をとりますが、どの値が出るかは確定していません。しかし、1から6までの値が出る確率は等しく1/6です。このように、確率変数はある値をとる確率が定義されている変数です。 確率変数であることを明示するために、確率変数には~(チルダ)をつけて表記します。たとえば確率変数Xは\\tilde{X}で表記します。\n確率変数は、どの値がどの確率で出るのかは分かっていますが、実際どの値が観察されるのかは分かりません。そのため、確率変数は期待値(expectation)と分散(variance)を持ちます。 以下では、期待値を表す演算子として\\mathbb{E}[\\cdot]を、分散を表す演算子として\\mathbb{V}[\\cdot]を用います。 ファイナンスや会計学では、リスクを分散で表します。 「リスクがある」とは、結果として実現する値がばらつくことを意味します。 結果が確実に分かっている場合は、リスクがない、つまり分散が0の場合です。\n\n数式\nよく出てくるものをまとめておきます。\n足し算をまとめて書くときは、\\sumを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを足し合わせるときは以下のように書きます。 \nx_1 + x_2 + x_3 + \\cdots + x_n\n これを\\sumを使って書くと以下のようになります。 \n\\sum _{i = 1}^n x_i\n このほうがシンプルです。\n掛け算をまとめて書くときは、\\prodを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを掛け合わせるときは以下のように書きます。 \nx_1 \\times x_2 \\times x_3 \\times \\cdots \\times x_n\n これを\\prodを使って書くと以下のようになります。 \n\\prod _{i = 1}^n x_i\n\n離散的な変数xの期待値は以下のように書きます。\n\n\\mathbb{E}[x] = \\sum _{i = 1}^n x_i p_i\n ここで、p_iはx_iが観測される確率です。 たとえばサイコロの出目Xは\\{1,2,3,4,6\\}の値を、それぞれ1/6の確率で出す確率変数です。サイコロの出目の期待値は、 \n\\begin{align*}\n\\mathbb{E}[X] &= \\frac 16 \\times 1 + \\frac 16 \\times 2 + \\frac 16 \\times 3 + \\frac 16 \\times 4 + \\frac 16 \\times 5 + \\frac 16 \\times 6\\\\\n& = 3.5\n\\end{align*}\n となります。\n次に、確率変数の分散は、 \n\\mathbb{V}[x] = \\sum _{i = 1}^n (x_i - \\mathbb{E}[x])^2 p_i\n と書きます。これもサイコロの例で考えてみましょう。 サイコロの出目の分散は、\n\n\\begin{align*}\n\\mathbb{V}[X] &= \\frac 16 \\times (1 - 3.5)^2 + \\frac 16 \\times (2 - 3.5)^2 + \\frac 16 \\times (3 - 3.5)^2 \\\\\n&+ \\frac 16 \\times (4 - 3.5)^2 + \\frac 16 \\times (5 - 3.5)^2 + \\frac 16 \\times (6 - 3.5)^2\\\\\n& = 2.916666666666666534\n\\end{align*}\n\nと計算できます。\n\n\n期待値の特徴\n期待値について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{E}[a] = a \\\\\n&\\mathbb{E}[a \\tilde X] = a \\mathbb{E}[\\tilde X]\\\\\n&\\mathbb{E}[\\tilde X + a] = \\mathbb{E}[\\tilde X] + a\\\\\n&\\mathbb{E}[\\tilde X + \\tilde Y] = \\mathbb{E}[\\tilde X] + \\mathbb{E}[\\tilde Y]\n\\end{align}\n\n\n\n1つめの式は、定数aの期待値はaであることを意味します。 2つめの式は、定数aと確率変数\\tilde Xの積の期待値は、定数aと確率変数\\tilde Xの期待値の積に等しいことを意味します。 3つめの式は、確率変数\\tilde Xに定数aを足したものの期待値は、確率変数\\tilde Xの期待値に定数aを足したものに等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の期待値は、確率変数\\tilde Xの期待値と確率変数\\tilde Yの期待値の和に等しいことを意味します。\n特に4つめの公式は重要で、和の期待値は期待値の和となることを意味してます。よく使うので覚えておいてください。\n正6面体のサイコロの出目Xと正4面体のサイコロの出目Yの和の期待値は、 \n\\begin{align*}\n\\mathbb{E}[X] &= 3.5\\\\\n\\mathbb{E}[Y] &= \\frac 14 \\times 1 + \\frac 14 \\times 2 + \\frac 14 \\times 3 + \\frac 14 \\times 4 = 2.5\\\\\n\\mathbb{E}[X + Y] &= \\mathbb{E}[X] + \\mathbb{E}[Y] = 3.5 + 2.5 = 6\n\\end{align*}\n となります。\n\n\n分散の特徴\n分散について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{V}[a] = 0\\\\\n&\\mathbb{V}[a \\tilde X] = a^2 \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + a] = \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + \\tilde Y] = \\mathbb{V}[\\tilde X] + \\mathbb{V} [\\tilde Y] + \\mathbb{Cov}(X,Y)\\\\\n&\\mathbb{V}[\\tilde X] = \\mathbb{E}[\\tilde X^2] - \\mathbb{E}[\\tilde X]^2\\\\\n\\end{align}\n\n\n\n1つめの式は、定数aの分散は0であることを意味します。自明ですね。 2つめの式は、定数aと確率変数\\tilde Xの積の分散は、定数aの2乗と確率変数\\tilde Xの分散の積に等しいことを意味します。1つめの式から明らかですね。\n3つめの式は、確率変数\\tilde Xに定数aを足したものの分散は、確率変数\\tilde Xの分散に等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の分散は、確率変数\\tilde Xの分散と確率変数\\tilde Yの分散と共分散の和に等しいことを意味します。これもよく出てくるので覚えておいてください。\n5つめの式は、確率変数\\tilde Xの分散は、確率変数\\tilde Xの2乗の期待値から確率変数\\tilde Xの期待値の2乗を引いたものに等しいことを意味します。 つまり分散の計算は、確率変数の2乗の期待値から期待値の2乗を引くことで計算できるということです。これ重要です。 先のサイコロの例で確認してみます。 \n\\begin{align*}\n\\mathbb{V}[X] &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n&= \\frac 16 \\times 1^2 + \\frac 16 \\times 2^2 + \\frac 16 \\times 3^2 + \\frac 16 \\times 4^2 + \\frac 16 \\times 5^2 + \\frac 16 \\times 6^2 - 3.5^2 \\\\\n&= 15.16667 - 12.25 \\\\\n&= 2.916667\n\\end{align*}\n となり、上で計算した分散と一致します。"
  },
  {
    "objectID": "Chap03.html",
    "href": "Chap03.html",
    "title": "3  R言語入門",
    "section": "",
    "text": "プログラミング言語にはいろんな種類があるけれど、今回学習するR言語は、インタプリタ型とよばれるもので、コンパイルという作業の必要が無く、書いたらすぐ実行できる仕様となっています。たとえば、教科書にあるように\nを実行すれば、結果がすぐ表示されます。 RstudioとかVS Codeを使って、上のようなRソースコードを一気に書いて、まとめて実行するためのスクリプト・ファイルを作成します。\nソースコードを書くにあたり注意する点として、以下の4つについて説明します。"
  },
  {
    "objectID": "Chap03.html#rの基本的な機能",
    "href": "Chap03.html#rの基本的な機能",
    "title": "3  R言語入門",
    "section": "3.1 Rの基本的な機能",
    "text": "3.1 Rの基本的な機能\n\n3.1.1 スカラー変数の定義\nこの学習を通じて変数(variable)とは、数値や文字といったデータを格納するための箱を表し、中に何が入っているのかにより、スカラー変数、ベクトル、行列、データフレームなどに分類されます。まずは、スカラー変数の定義を学びます。\nスカラー(scalar)とは、大きさだけで決まる量のことで、つまり、1つの数値を指します。 R言語ではスカラー変数を定義するには、<-を使います。たとえば、x <- 100と書けば、xというスカラー変数に100という数値を格納できます。このとき、<-は代入演算子と呼ばれ、右辺の値を左辺の変数に代入するという意味です。また、xという変数を左辺値(left-hand side)、100という数値を右辺値(right-hand side)と呼びます。\n\nx <- 100 # 代入演算子<- の前後に半角スペースを入れるのがお作法\n\nこの中身を表示されるには、print()関数を使います。\n\nprint(x) # xの中身を表示\n\n[1] 100\n\n\nあるいは\n\nx\n\n[1] 100\n\n\nでも表示されます。\n\nRでは#の後ろの文章はコメントとして扱われ、実行されません。コメントはプログラムの内容を説明するためにたくさん書いて残しておきましょう。\n\n\n\n3.1.2 ベクトル変数の定義\nベクトル(vector)とは、大きさと向きで決まる量のことで、つまり、複数の数値を指します。R言語ではベクトル変数を定義するには、c()を使います。たとえば、x <- c(1, 2, 3)と書けば、xというベクトル変数に1, 2, 3という数値を格納できます。このとき、c()はベクトルを作る関数と呼ばれ、1, 2, 3という数値を引数として与えています。\n\nx <- c(1, 5, 9) # xに1と5と9を要素とするベクトルを代入\nprint(x)\n\n[1] 1 5 9\n\n\n等差数列を作る関数にseq()関数があります。seq()は3つの引数をとり、\n\nfrom : 始点\nto : 終点\nby : 差分\n\nを指定します。たとえば、2000年から2020年を表す年度の変数をyearとして定義するには、\n\nyear <- seq(from = 2000, to = 2020, by = 1)\nprint(year)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nと書けば、2000から2020までの公差1の等差数列を作ります。 seq()変数の引数には、fromとtoとbyの3つの引数を指定することができますが、fromとtoのみを指定することもできます。このとき、byの値は1となります。次のように書いても、上と同じ結果を得ることができます。\n\nseq(2000,2020)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nベクトルの要素数を知るには、length()関数を使います。\n\nlength(year) # yearの要素数を表示\n\n[1] 21\n\n\nベクトル変数yearの中には21個の要素があることがわかります。\n\n\n3.1.3 ベクトルの要素の取り出し\n複数の要素をもつベクトルから、一部の要素を取り出すには、[]を使います。たとえば、xの2番目の要素を取り出すには、x[2]と書きます。このとき、[]は添字演算子と呼ばれ、2という添字を引数として与えています。添字は1から始まります。\n上のyearから2000を取り出すには、year[1]、2020を取り出すにはyear[21]と書きます。 次のような書き方で、好きな要素を指定して取り出すことができます。\n\nyear[1] # 1番目のデータを取り出す\n\n[1] 2000\n\nyear[20] # 20番目のデータを取り出す\n\n[1] 2019\n\nyear[2:5] # 2番目から5番目のデータを取り出す\n\n[1] 2001 2002 2003 2004\n\nyear[c(5,10)] # 1番目と20番目のデータを取り出す\n\n[1] 2004 2009\n\nyear[6:length(year)] # 6番目から最後のデータを取り出す\n\n [1] 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n[16] 2020\n\n\n\n\n3.1.4 現在価値の計算\n今の時点をt=0として、T年後に確実に得られるキャッシュ・フローCF_Tの現在価値PV_0は、\n\nPV_0 = \\frac{CF_T}{(1+r)^T}\n\nと書けます。たとえば1年後に確実に受け取れる100万円の現在価値PV_0を計算してみます。いま、無リスク利子率rは10%とします。\n\nt = 1\n100 / (1 + 0.1)^t\n\n[1] 90.90909\n\n\n10年後に確実に受け取れる100万円の現在価値PV_0を計算するには、次のように書きます。\n\nt = 10\n100 / (1 + 0.1)^t\n\n[1] 38.55433\n\n\n次に、この無リスク利子率rが変化した場合の現在価値の計算を考えます。まず、無リスク利子率のベクトルを定義します。\n\n# 下の２つは同じ結果\nR <- seq(from = 0.1, to = 0.2, by = 0.01)　# 省略せずに書いた場合\nR <- seq(0.1, 0.2, 0.01) # 略した場合\n\n次に、無リスク利子率が変化した場合の現在価値を計算します。\n\nPV <- 100 / (1 + R)\nprint(PV)\n\n [1] 90.90909 90.09009 89.28571 88.49558 87.71930 86.95652 86.20690 85.47009\n [9] 84.74576 84.03361 83.33333\n\n\nこのように100という定数をRというベクトル変数で割ると、Rの要素数と同じ要素数のベクトル変数PVが作成されます。 無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値が計算されました。 次にこの結果をグラフにしてみます。\n\n\n3.1.5 基本パッケージplotによる作図\nとりあえずサクッと作図してデータをチェックしたいとき、もとからR言語に組み込まれている基本関数plot()が便利です。 先ほど作成したベクトル変数PVをグラフにしてみます。\n\nplot(PV) # 基本関数plot()\n\n\n\n\nいま、PVは11個の要素をもつベクトル変数なので、データを左から順番に並べた散布図(scatter diagram)が作成されています。 これだと何のグラフか分かりづらいので、いろいろとオプションを指定してみます。\n\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\",\n    ylab = \"現在価値\",\n    main = \"無リスク利子率と現在価値の関係\",\n    type = \"l\" # 線グラフ\n)\n\n\n\n\nMacだと文字化けしてしまいました。そこで文字コードを指定します。Windowsだとこの作業は不要です。\n\npar(family = \"HiraKakuProN-W3\") # Macの場合のみ\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"無リスク利子率と現在価値の関係\", # グラフのタイトル\n    type = \"l\" # 折れ線グラフ\n)"
  },
  {
    "objectID": "Chap03.html#npvと割引率の関係の可視化",
    "href": "Chap03.html#npvと割引率の関係の可視化",
    "title": "3  R言語入門",
    "section": "3.3 NPVと割引率の関係の可視化",
    "text": "3.3 NPVと割引率の関係の可視化\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値NPVの値を計算してみます。\n\nR <- seq(0.1, 0.2, 0.01) # 無リスク利子率\nN <- length(R) # 無リスク利子率の要素数 11個\nNPV <- rep(NA, N) # ベクトル変数にN個のNAを代入\n\nfor (i in 1:N) { # iは1からNまで\n    NPV[i] <- -100 # 初期投資\n    for (j in 1:3) { # jは1から3まで\n        NPV[i] <- NPV[i] + 50 / (1 + R[i])^j # 現在価値\n    }\n}\nprint(NPV) # 11個の現在価値を表示\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n少し複雑な構造しているので、順番に説明します。\n\n1行目は、無リスク利子率のベクトル変数Rを定義しています。ここでは、0.1から0.2まで0.01刻みのデータを作成しています。\n2行目は、ベクトル変数Rの要素数をNとして定義しています。ここでは、Nは11となります。\n3行目は、ベクトル変数NPVにN個のNAを代入しています。NAはNot Availableの略で、欠損値を表します。NAを代入することで、空っぽの箱が11個入ったベクトル変数NPVを用意します。\n4行目から9行目は、for文を使って、NPVの中身を計算しています。 forが2回出てきているので、二重に繰り返しの処理を行っています。これをネストと呼びます。 1つのめforはiが1からN(ここでは11)まで変化し、2つめのforはjが1から3まで変化します。1つめのfor文のiが1のとき、次のfor文のjが1から3までの処理を繰り返し、次に1つめのfor文のiが2のとき、次のfor文のjが1から3までの処理を繰り返し・・・という順番で処理が行われます。\n10行目は、NPVの中身を表示しています。\n\n\nTABキーを使って、インデントを行い、ソースコードのまとまりをわかりやすくしています。インデントは、プログラムの構造をわかりやすくするために行います。インデントを行うときは、半角スペース2つか4つを使います。どちらを使っても構いませんが、どちらかに統一することが大切です。\n\nこの結果をグラフにしてみます。\n\npar(family = \"HiraKakuProN-W3\") # 日本語フォントの設定\nplot(\n    x = R, # x軸のデータ\n    y = NPV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"図：無リスク利子率と現在価値\", # グラフのタイトル\n    type = \"l\" # 線グラフ\n)\n\n\n\n\n\nベクトル化\n上のコードは、for文を使って、NPVの中身を計算しています。しかし、R言語では、for文を使わずに、ベクトルを使って、同じことを行うことができます。このように、for文を使わずに、ベクトルを使って処理を行うことをベクトル化と呼びます。ベクトル化を行うと、処理が高速化されることがあります。\n\nR <- 0.1 # 無リスク利子率 10%\nCF <- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nyear <- 0:3 # 年度のベクトル\nPV_CF <- CF / (1 + R)^year # 各期の現在価値を計算\nNPV <- sum(PV_CF) # 現在価値の合計\nprint(NPV)\n\n[1] 24.3426"
  },
  {
    "objectID": "Chap04.html#ディスクロージャー制度の概要とデータの入手先",
    "href": "Chap04.html#ディスクロージャー制度の概要とデータの入手先",
    "title": "4  財務データの取得と可視化",
    "section": "4.1 ディスクロージャー制度の概要とデータの入手先",
    "text": "4.1 ディスクロージャー制度の概要とデータの入手先\n\n4.1.1 法定開示と適時開示\n\n\n\n\n年次開示\n四半期開示\n重要事実\n\n\n\n\n法定開示\n有価証券報告書\n四半期報告書\n臨時報告書\n\n\n適時開示\n決算短信\n四半期決算短信\n適時開示\n\n\n\n\n\n4.1.2 財務データの入手先\n\nEDINET：金融庁が運営する電子開示システムで，全上場企業の法定開示資料をデータベースとして提供\nTDnet：東京証券取引所が運営する電子開示システムで，上場企業の決算短信をデータベースとして提供\n\nXBRL(eXtensible Business Reporting Language)形式で財務諸表などの主要情報を公開しています。XBRLからデータを読み込むスキルは本書の枠を超えるため，ここでは練習用データで分析しますが、立命館大学では日経NEEDSを利用して財務データを収集します。"
  },
  {
    "objectID": "Chap04.html#rを利用した財務データの分析",
    "href": "Chap04.html#rを利用した財務データの分析",
    "title": "4  財務データの取得と可視化",
    "section": "4.2 Rを利用した財務データの分析",
    "text": "4.2 Rを利用した財務データの分析\n\n4.2.1 tidyverseパッケージの概要\ntidyverseとは，R神Wickham氏が基本コンセプトを設定し，整然データ(tidy data)に対して一貫した記法でデータを扱えるパッケージ群です。 インストールと読み込みは以下の通りです。\n\n#install.packages(\"tidyverse\") # 初回だけ\nlibrary(tidyverse) # 毎回読み込み。\n\ntidyverseパッケージを読み込むことで，次の代表的なパッケージが利用できるようになります。 よく使うものは以下のものになります。\n\nggplot2 データの可視化　めっちゃ使う\ndplyr データハンドリング　めっちゃ使う\nreadr データを読み込む めっちゃ使う\ntidyr tidyデータにもっていく　そこそこ使う\npurrr 関数型プログラミングで使う　慣れてくると使う\ntibble data.frameではなくtibbleにする　あまり使わない\nstringr 文字列の加工・操作　ちょいちょい使う\nforcats ファクター型変数の操作　そんなに使わない\n\n\n\n4.2.2 財務データの読み込み\n「実証会計・ファイナンス」のサポートサイトにある練習用のデータセットch04_financial_data.csvをダウンロードして，自分のPCの作業ディレクトリに置きます。 いまRが作業ディレクトリとしてどこの場所を読み込んでいるのかを確認するにはgetwd()を使います。 作業ディレクトリを変更するときはsetwd()で作業ディレクトリを絶対パスで指定するとよいでしょう。\nいままではcsvデータを読み込むために，基本関数のread.csv()を使ってきましたが、ここからはより高速かつオプション指定が柔軟なtidyverse関数群の1つであるreadrパッケージのread_csv()関数を使います。readとcsvの間がピリオド.からアンダースコア_に変わっているので注意してください。 readrパッケージのread_csv()関数は，\n\nデータの読み込みが高速かつ型の推論が柔軟\n基本のdata.frameではなく，その拡張版であるtibbleで返す\n列名を勝手に変換しない。\n文字列を勝手にファクター型にしない（ read.csv()だと勝手にファクターになる )。\n\nという利点があります。 松浦は、作業ディレクトリであるフォルダの中にdataフォルダを作成し、そこにcsvファイルを入れています。 そのため、以下のコードではdata/ch04_financial_data.csvのように相対パスでファイルを指定しています。\n\nfinancial_data <- read_csv(\"data/ch04_financial_data.csv\") # readrを使用\nnrow(financial_data) # 行数\n\n[1] 7920\n\nncol(financial_data) # 列数\n\n[1] 11\n\nhead(financial_data,5) # 最初の5行\n\n# A tibble: 5 × 11\n   year firm_ID industry_ID sales    OX   NFE     X     OA    FA    OL     FO\n  <dbl>   <dbl>       <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl>\n1  2015       1           1 5261.  437.  NA    287. 13006. 3543. 4373.  2481.\n2  2016       1           1 5949.  564.  50.7  513. 13866. 4642. 4534.  3960.\n3  2017       1           1 6505.  691.  29.5  662. 13953. 7744. 5111.  6159.\n4  2018       1           1 6846.  751.  86.5  665. 18818. 7285. 5137. 10124.\n5  2019       1           1 7572.  959. 298.   660. 18190  9735. 5488. 11362.\n\n\nこのfinancial_dataには、11個の変数に観測値が7920個あることがわかります。\n\nyear : 年度\nfirm_ID : 企業ID\nindustry_ID : 産業ID\nsales : 売上高\nOX : 事業利益(operating income)\nNFE : 純金融費用(net financial expenses)\nX : 当期純利益(net income)\nOA : 事業資産(operating assets)\nOL : 事業負債(operating liabilities)\nFE : 金融資産(financial assets)\nFO : 金融負債(financial obligations)\n\nこのデータフレームの構造を確認します。\n\nglimpse(financial_data)\n\nRows: 7,920\nColumns: 11\n$ year        <dbl> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ industry_ID <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sales       <dbl> 5261.40, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505…\n$ OX          <dbl> 437.49, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.…\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> 286.64, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.…\n$ OA          <dbl> 13005.55, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86…\n$ FA          <dbl> 3543.43, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 225…\n$ OL          <dbl> 4372.96, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840…\n$ FO          <dbl> 2480.72, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2…\n\n\n変数はすべて数値型doubleになっていますが、firm_IDとindustry_IDはカテゴリーを表す変数ですので、数値型ではなくファクター型に変換します。ついでにyearは年度という時間を尺度なので、数値型ではなくfactor型に変換します。ここで重要なのは、yearはただのファクター型ではなく、順序のあるファクター型とすることです。\nここではas.factor()を使います。\n\n# firm_IDとindustry_IDをfactor型に変換\nfinancial_data$year <- factor(financial_data$year, \n                            ordered = TRUE, \n                            levels = c(2015:2020)\n                            )\nfinancial_data$firm_ID <- as.factor(financial_data$firm_ID)\nfinancial_data$industry_ID <- as.factor(financial_data$industry_ID)\n\n# 確認\nglimpse(financial_data)\n\nRows: 7,920\nColumns: 11\n$ year        <ord> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     <fct> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ industry_ID <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sales       <dbl> 5261.40, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505…\n$ OX          <dbl> 437.49, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.…\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> 286.64, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.…\n$ OA          <dbl> 13005.55, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86…\n$ FA          <dbl> 3543.43, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 225…\n$ OL          <dbl> 4372.96, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840…\n$ FO          <dbl> 2480.72, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2…"
  },
  {
    "objectID": "Chap04.html#探索的データ分析",
    "href": "Chap04.html#探索的データ分析",
    "title": "4  財務データの取得と可視化",
    "section": "4.3 探索的データ分析",
    "text": "4.3 探索的データ分析\n\n4.3.1 データセットの概要確認\nデータセットを操作するまえに，データの概要を大まかにつかむ必要があり，この作業を探索的データ分析(exploratory data analysis)といいます。 仮説などを持たず，とりあえず特徴や構造を理解するための方法です。\n\n\n\n\n\n\nノート\n\n\n\n引数の型に応じて自動的に最適な結果を返す機能を多態性 (polymorphism)といい，多態性をもつ関数を総称関数(generic function)という。\n\n\n\nsummary(financial_data)\n\n   year         firm_ID      industry_ID       sales        \n 2015:1266   1      :   6   3      :1760   Min.   :    205  \n 2016:1293   2      :   6   10     :1702   1st Qu.:  16103  \n 2017:1319   3      :   6   7      :1334   Median :  40431  \n 2018:1323   4      :   6   1      :1143   Mean   : 166007  \n 2019:1356   5      :   6   9      : 667   3rd Qu.: 118314  \n 2020:1363   7      :   6   8      : 429   Max.   :3496433  \n             (Other):7884   (Other): 885                    \n       OX                 NFE                  X                   OA         \n Min.   :-353606.7   Min.   :-285383.9   Min.   :-357624.8   Min.   :    217  \n 1st Qu.:    399.3   1st Qu.:    -66.4   1st Qu.:    383.3   1st Qu.:  12560  \n Median :   1602.9   Median :     -1.2   Median :   1586.1   Median :  30799  \n Mean   :   7968.9   Mean   :     64.0   Mean   :   7904.9   Mean   : 152273  \n 3rd Qu.:   5260.5   3rd Qu.:     41.4   3rd Qu.:   5204.6   3rd Qu.:  93469  \n Max.   : 398034.5   Max.   : 331035.3   Max.   : 572588.7   Max.   :7987936  \n                     NA's   :1                                                \n       FA                 OL                FO         \n Min.   :     288   Min.   :     35   Min.   :     44  \n 1st Qu.:    6835   1st Qu.:   3965   1st Qu.:   3757  \n Median :   19095   Median :  10868   Median :  11125  \n Mean   :   80185   Mean   :  50261   Mean   :  70681  \n 3rd Qu.:   52118   3rd Qu.:  33111   3rd Qu.:  35446  \n Max.   :29250611   Max.   :2817975   Max.   :7026924  \n                                                       \n\n\nさらに，データセットのある変数に含まれる固有な要素を抽出するには，unique()関数を用います。\n\nunique(financial_data$year) # financial_dataのyear変数に含まれる固有要素\n\n[1] 2015 2016 2017 2018 2019 2020\nLevels: 2015 < 2016 < 2017 < 2018 < 2019 < 2020\n\n# 2015, 2016, 2017, 2018, 2019, 2020\n\n固有要素の数を確認するには，unique()関数で取り出した要素の数をlength()関数で返します。 企業-年の企業数と年度数を確認するには次のようにします。\n\nlength(unique(financial_data$firm_ID)) # 1515を返す\n\n[1] 1515\n\nlength(unique(financial_data$industry_ID)) # 10\n\n[1] 10\n\n\nよってこのデータには10の産業、1515の企業があることが分かります。\n\n\n4.3.2 欠損データの処理\nほとんどのデータセットには，欠損値(NA)が含まれているため，この欠損値の処理は非常に重要になります。 欠損値の有無を確認するためには，complete.cases()関数を用いるのが便利です。 欠損値が含まれているとFALSEを返し，欠損値がないとTRUEを返します。\n\nhead(complete.cases(financial_data)) # 最初の６行の結果を表示\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nsum()関数で，TRUEの個数を数え上げることもできます。\n\nsum(complete.cases(financial_data)) # TRUE/FALSEを1/0に置き換えて合計\n\n[1] 7919\n\n\n欠損値の出現に何らかの傾向がある場合，欠損値の削除が生存者バイアス(survivorship bias)をもたらす可能性があります。 たとえば，過去20年間にわたって連結財務諸表データに欠損値が含まれていない上場企業ばかりを分析すると，途中で倒産したり上場したりした企業は削除され，20年間経営し続けている優良企業しかデータに残らない生存者バイアスが発生します。\nこのようなバイアスを考慮しなくても良いなら，欠損値をもつ個体(unit)のデータ(行)を削除するのが単純な処理となります。 このとき，tidyrパッケージに含まれるdrop_na()関数を用いると簡単に欠損値を含む行を削除できます。 基本関数のna.omit()でもよいですが，tidyr::drop_na()の方がオプションが豊富なのでおすすめです。\n\nnrow(financial_data) # 欠損行を削除する前の行数\n\n[1] 7920\n\nnrow(drop_na(financial_data)) # 欠損行を削除した場合の行数\n\n[1] 7919\n\nfinancial_data <- drop_na(financial_data) # 欠損行を削除した上でデータを上書き\n# この作業には注意が必要である。オリジナルデータはそのまま残しておいたほうが良い\n\n欠損値を含む行を削除するのではなく，欠損値に適切な推定値を代入することでサンプルサイズを減らさない方法も開発されていますが，欠損値の出現を説明する確率モデルを仮定し，その推定値を求める必要があります。\n\n\n\n\n\n\nノート\n\n\n\n詳しくは髙橋・渡辺 (2019) 欠損データ処理：Rによる単一代入法と多重代入法 を参照してください。\nさらに欠損値についての議論では，星野・岡田 (2016)「欠測データの統計科学―医学と社会科学への応用」岩波書店がめちゃめちゃ有用です。"
  },
  {
    "objectID": "Chap04.html#データの抽出とヒストグラムによる可視化",
    "href": "Chap04.html#データの抽出とヒストグラムによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.4 データの抽出とヒストグラムによる可視化",
    "text": "4.4 データの抽出とヒストグラムによる可視化\n\n4.4.1 条件にあうデータの抽出方法\n教科書では複数の方法が紹介されているが，このメモではtidyverseパッケージを用いた方法だけ取り上げます。具体的には，データベース操作のパッケージであるdplyrの中のfilter()関数について説明します。 さらにmagrittrを用いたパイプ演算子%>%を用いたデータの受け渡しの記法を活用して，可読性の高いソースコードを書くことも紹介します。 ここではdplyrパッケージのfilter()関数であることを明示的に示すため、dplyr::filter()と書いていますが、dplyrパッケージを読み込んでいる場合はfilter()と書いても同じです。\n\nfinancial_data_2015 <- financial_data %>%\n    dplyr::filter(year == 2015) # year変数が2015のデータを抽出\n\nfilter()で条件を満たすデータのみを取り出し，それをfinancial_data_2015に代入している。\nパイプ演算子%>%は左のオブジェクトを右の関数の第1引数に代入する，という処理を行います。 つまり，x %>% filter(year == 2015)は，filter(x, year == 2015)と同じ意味になります。 パイプ演算子を使うことで，データが次の処理に受け渡されていくプロセスが読みやすくなります。たとえば、\n\n欠損値を除去して，\n2015年のデータを抽出し，\nROEを計算して，\n産業ごとに平均値を出す\n\nというよく使いそうな処理を行いたい場合，tidyverseなら次のように書きます。\n\nfinancial_data %>%\n    drop_na() %>% # 欠損値を除去し，\n    filter(year == 2015) %>% # 2015年のデータを抽出し，\n    mutate(ROE = earnings / equity) %>% # ROEを変数を作り，\n    group_by(industry) %>% # 業種コードごとに\n    summarise(mean_ROE = mean(ROE)) # mean()でROE平均を計算\n\n基本関数の場合は、\n\nfinancial_data <- na.omit(financial_data)\nfinancial_data_2015 <- financial_data[financial_data$year == 2015, ]\nfinancial_data_2015$ROE <- financial_data_2015$earnings / financial_data_2015$equity\nmean_ROE_by_industry <- aggregate(financial_data_2015$ROE, \n        by = list(financial_data_2015$industry), \n        FUN = mean)\n\nとなりますので、上の方が読みやすいことがわかります。\n\n\n4.4.2 ヒストグラムによる売上高の可視化\n\n4.4.2.1 ヒストグラム\nヒストグラム(histogram)は，データの分布を可視化するためのグラフです。 ヒストグラムは，連続データを区間に分けて，区間ごとのデータの個数を棒グラフで表現したものです。したがってヒストグラムの棒の高さは、その区間に含まれるデータの個数を表します。\nたとえば、例として生徒100人の身長データがあるとします。 この身長データをRで生成するには，rnorm()関数を使います。\n\n# 平均170cm，標準偏差5cmの正規分布から100個のデータを生成\nheight <- rnorm(100, mean = 170, sd = 5)\nprint(height)\n\n  [1] 169.6924 174.5469 176.3546 171.0446 175.6103 170.4743 164.5788 166.0442\n  [9] 161.9346 163.7407 157.3900 179.8433 168.5600 172.7645 172.0916 162.9906\n [17] 164.9894 176.5034 174.0555 176.4578 164.5827 165.0025 168.9452 172.8089\n [25] 174.2949 171.0870 175.8524 180.7838 164.3101 178.1985 164.9176 176.0124\n [33] 170.4831 171.7323 170.9961 177.1232 169.7548 168.2287 169.0044 175.0003\n [41] 169.3694 172.1525 167.8356 171.3804 170.3527 168.2850 170.3796 162.3475\n [49] 164.0759 162.8132 168.2428 172.1306 173.8485 172.2481 167.0463 177.1396\n [57] 175.6116 170.5064 162.7817 162.8524 169.9775 171.3020 169.9325 171.4664\n [65] 180.8614 161.3915 168.1194 176.5041 177.4252 162.1188 171.4196 175.6819\n [73] 167.0647 169.8203 169.9235 167.6972 164.7486 168.0285 172.3546 173.3254\n [81] 169.8629 164.4961 174.7364 166.4179 177.7701 175.6074 179.5678 167.9054\n [89] 161.5347 166.5031 171.4887 173.6740 173.6661 168.2252 164.6050 168.9659\n [97] 166.2311 165.0904 170.7562 177.4817\n\n\n100個のデータを眺めていても、なかなか特徴をつかめませんよね。そこでこの身長という連続データを5センチごとの区間に分けます。 たとえば、165cm以上、170cm未満の区間には何人の生徒がいるのか、170cm以上、175cm未満の区間には何人の生徒がいるのか、というように区間ごとのデータの個数を数えます。 このとき、区間の幅を5cmにするか、10cmにするか、20cmにするか、ということは、データの特徴をつかむ上で重要なことです。 区間の幅を大きくすると、データの特徴がざっくりとしかつかめません。 一方、区間の幅を小さくすると、データの特徴が細かくつかめますが、データの個数が少ない区間が多くなり、データの特徴をつかむのに時間がかかります。 やってみましょう。\n\nhist(height, breaks = seq(150, 190,by = 1)) # 区間の幅を1cmにする\n\n\n\nhist(height, breaks = seq(150, 190,by = 5)) # 区間の幅を5cmにする\n\n\n\nhist(height, breaks = seq(150, 190,by = 10)) # 区間の幅を10cmにする\n\n\n\n\nどのヒストグラムがデータの特徴を最も良く表しているのか、を考えて区間幅を設定しましょう。\n\n\n4.4.2.2 ggplotでヒストグラム\nヒストグラムを書くためには，基本関数のhist()が最も簡単ですが，より高性能なggplot2を用いたヒストグラムの書き方を説明します。 ここでは、上で作成した2015年のデータfinancial_data_2015を使って、売上高のヒストグラムを書きます。\nggplot2の書き方は少し特殊ですが、慣れてくると非常に便利です。 ggplot2ではレイヤー(階層)を上から重ねていくようにグラフを作っていきます。 まずggplot()関数でグラフの土台を作ります。ggplot()に入れるデータの型はdata.frameでなければならないので注意しましょう。\nggplot()の中で読み込むデータを指定して、gというオブジェクトに代入し、それを表示させます。\n\ng <- ggplot(data = financial_data_2015) # グラフにしたいデータを指定\nprint(g) # 出力\n\n\n\n\n真っ白で何も出力されていませんが、financial_data_2015というデータフレームを指定して、グラフの土台を作りました。\n次に軸の設定をします。ヒストグラムは1変数のグラフなのでx軸のみを設定します。aes()関数で変数を指定します。先ほど作成したgにaes()関数を+で追加していきます。\n\ng <- g + aes(x = sales) # x軸を売上高にする\nprint(g) # 出力\n\n\n\n\n横軸が表示されました。 この上に、ヒストグラムを書くためにgeom_histogram()関数を追加します。 ggplot2パッケージでは、geom_***の形でグラフを指定します。例えば、\n\ngeom_bar 棒グラフ\ngeom_point 散布図\ngeom_line 折れ線グラフ\ngeom_boxplot 箱ひげ図\ngeom_histogram ヒストグラム\n\nあたりがよく使われるグラフです。\n\ng <- g + geom_histogram() # グラフはヒストグラム\nprint(g)\n\n\n\n\nここでコンソールに，\n\nstat_bin() using bins = 30. Pick better value with binwidth.\n\nというメッセージが出ますが、これは「何も指定されなかったので，ヒストグラムのビンの数を30にして作図したけど，オプションのstat_bin()で適切な区間幅をbinwidthで設定してね」ということです。無視しても大丈夫です。\nx軸が指数表記となっていて見づらいので，scales()関数を使って表記を変更します。\n\ng <- g + scale_x_continuous(label = scales::label_comma()) # 3桁ごとにコンマで区切った数値で表示\nprint(g)\n\n\n\n\n横軸の数値が変化したことが分かります。\nまた、小数ながら非常に大きな売上高をもつ企業があるため，ヒストグラムの形が左側に集まるように歪んでいます。 そこで売上高を自然対数に変換して，分布の歪みを修整したヒストグラムを書いてみます。 データを変更するので、最初から全部書きます。\n\ng <- ggplot(financial_data_2015) + # データの読み込み\n  aes(x = log(sales)) + # x軸を売上の自然対数に\n  geom_histogram() # ヒストグラム\nprint(g) # 出力\n\n\n\n\nうまくいきました。 ついでにいろいろなオプションをつけてみます。\n\nlibrary(ggthemes)\nmystyle <- list (#  ggplotのテーマ\n  theme_calc(), # ggthemesパッケージ\n  scale_colour_calc(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n\ng <- g + xlab(\"売上高の自然対数\") + ylab(\"度数\") + mystyle # 先ほどのスタイルを適用\nprint(g)"
  },
  {
    "objectID": "Chap04.html#データの集計と折れ線グラフによる可視化",
    "href": "Chap04.html#データの集計と折れ線グラフによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.5 データの集計と折れ線グラフによる可視化",
    "text": "4.5 データの集計と折れ線グラフによる可視化\n\n4.5.1 dplyrを用いた集計\nもっとデータを加工して、データの特徴をつかむグラフを作成してみます。 データを加工するために、非常に便利なパッケージであるtidyverseのdplyrを用いたデータ加工を説明します。dplyrでよく使う関数に、\n\ngroup_by() ：グループ化\nsummarise() ： 集計\nmutate() ： 変数の追加\nfilter()： データの抽出\n\nがあります。これらの関数を組み合わせることで、データの加工が非常に簡単にできます。たとえば、financial_dataに含まれる売上高を年度ごとに集計してみましょう。dplyrのgroup_by()関数を使うと、変数を指定してデータをグループ化することができます。たとえば、yearを指定すると、年度ごとにデータをグループ化します。 group_by()でグループ化したあとに、summarise()関数を使って平均や分散などの統計量を計算します。\n\nN_firms_by_year <- financial_data %>%\n    group_by(year) %>% # 年度ごとにグループ化\n    summarize( # 以下の統計量を計算\n        N_firms = n(), # データ個数 n()\n        mean_sales = mean(sales) # 売上高の年度平均 mean()\n)\n\nこれでN_firms_by_yearというオブジェクトに、financial_dataを年度ごとにグループ化して、年度ごとの企業数N_firmsと平均売上高mean_saleを計算したデータが入っています。 2015年から2020年の6年間のデータがあるので、6行のデータが入っているはずです。 中身を確認しておきましょう。\n\nglimpse(N_firms_by_year)\n\nRows: 6\nColumns: 3\n$ year       <ord> 2015, 2016, 2017, 2018, 2019, 2020\n$ N_firms    <int> 1265, 1293, 1319, 1323, 1356, 1363\n$ mean_sales <dbl> 173614.9, 173359.5, 170010.9, 157995.4, 160928.2, 161043.7\n\n\n以下の変数について6個のデータが入っていることがわかります。\n\nyear : 年度 (ord)\nN_firms : 企業数 (int)\nmean_sales : 平均売上高 (dbl)\n\n\n\n\n\n\n\nノート\n\n\n\n関数型プログラミング(functional programming)は，現代的なプログラミング・パラダイムの1種であり，定義された関数を用いて各データに対して行いたい処理を切り分ける。Rではapply系関数として，様々な関数が用意されている。tidyverse群では，purrrがある。ちょっと難しいですがpurrr超便利\n\n\n\n\n4.5.2 折れ線グラフによる上場企業数の可視化\nデータの成形が終わったので，折れ線グラフを作っていきます。 ここではx軸(横軸)を年度year，y軸(縦軸)を上場企業数N_firmsとする折れ線グラフを作ってみます。 折れ線グラフを作るにはgeom_line()関数を使います。\n\ng <- ggplot(N_firms_by_year) +\n    aes(x = year, y = N_firms, group=1) +\n    geom_line()\ng <- g + labs(x = \"Year\", y = \"Number of Firms\") + mystyle# 軸ラベル\nprint(g)\n\n\n\n\nここで突然現れたgroup = 1というaes()のオプションですが、これはすべてのデータが同じグループに属していることを指定しています。 x軸にファクター型を指定する場合、group = 1を指定しないと、x軸の値ごとに別のグループとして認識されてしまい、折れ線グラフがうまく描けません。"
  },
  {
    "objectID": "Chap04.html#変数の作成とヒストグラムによる可視化",
    "href": "Chap04.html#変数の作成とヒストグラムによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.6 変数の作成とヒストグラムによる可視化",
    "text": "4.6 変数の作成とヒストグラムによる可視化\ntidyverseのdplyrパッケージのmutate()関数を用いれば，パイプ演算子%>%を用いて可読性の高いシンプルな書き方で、新しい変数を作成することができます。\n\n\n\n\n\n\nキーボードショートカット\n\n\n\nMacならcommand + shift + mでパイプ演算子が入力できます。 Windowsならctrl + shift + mです。\n\n\nここでは，ROE(Return on Equity)を計算してみます。 ROEの定義は，\n\nROE_t = \\frac{X_t}{BE_{t-1}}\n\nとなります。 分子のX_tはt期の当期純利益，分母のBE_{t-1}はt期首の株主資本です。 練習用データであるfinancial_date.csvには，当期純利益はXという列名で収録されていますが、株主資本の列はありません。 よってデータから株主資本は次のように計算します。\n\nBE_t = \\underbrace{(OA_t - OL_t)}_{NOA_t} - \\underbrace{(FO_t - FA_t)}_{NFO_t}\n\nこの計算を行い，新しい変数BEをデータフレームに加えるには，dplyr::mutate()を使います。\n\nfinancial_data <- financial_data %>%\n    mutate(\n        BE = (OA - OL) - (FO - FA) # 新たなBE変数が加わる\n    )\n\n分母の株主資本は期首，つまり前期末の数値を用いる必要があります。 1期前の値を参照するには，lab()関数を用います。 ただ，クロスセクションのデータで普通にlag()関数を用いると，次のように別の企業のデータを参照してしまいます。\n\nfinancial_data <- financial_data %>%\n    mutate(\n        lag_BE = lag(BE),\n        ROE = X / lag_BE # これはダメ\n    )\n\nhead(financial_data, 10)[,c(\"firm_ID\", \"year\", \"BE\",\"lag_BE\",\"ROE\")]\n\n# A tibble: 10 × 5\n   firm_ID year      BE lag_BE      ROE\n   <fct>   <ord>  <dbl>  <dbl>    <dbl>\n 1 1       2016  10014.    NA  NA      \n 2 1       2017  10426. 10014.  0.0661 \n 3 1       2018  10842. 10426.  0.0638 \n 4 1       2019  11075. 10842.  0.0609 \n 5 1       2020  11594. 11075.  0.0762 \n 6 2       2015   1055. 11594.  0.00346\n 7 2       2016   1082.  1055.  0.0468 \n 8 2       2017   1135.  1082.  0.0702 \n 9 2       2018   1184.  1135.  0.0763 \n10 2       2019   1237.  1184.  0.0770 \n\n\n結果のfirm_IDが2の企業の2015年のROEを計算するには，1期前の企業1の2014年の株主資本を参照する必要があるけれど，2014年のデータは存在しないため、企業2の2015年度のROEは欠損値NAになっている必要があるのに、lag()関数が1つ前の企業1の2020年の株主資本を参照してしまっています。 ROEを企業ごとに計算するために，dplyr::group_by()を使って，計算を企業群ごとに行うことで、この問題を解決できます。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # firm_IDごとに以下の処理を繰り返す\n    mutate(\n        lagged_BE = lag(BE), # lag関数で前期の値を取り出す\n        ROE = X / lagged_BE # これはOK\n    ) %>%\n    ungroup() # group化を解除\nhead(financial_data, 10)[,c(\"firm_ID\", \"year\", \"BE\",\"lagged_BE\",\"ROE\")]\n\n# A tibble: 10 × 5\n   firm_ID year      BE lagged_BE     ROE\n   <fct>   <ord>  <dbl>     <dbl>   <dbl>\n 1 1       2016  10014.       NA  NA     \n 2 1       2017  10426.    10014.  0.0661\n 3 1       2018  10842.    10426.  0.0638\n 4 1       2019  11075.    10842.  0.0609\n 5 1       2020  11594.    11075.  0.0762\n 6 2       2015   1055.       NA  NA     \n 7 2       2016   1082.     1055.  0.0468\n 8 2       2017   1135.     1082.  0.0702\n 9 2       2018   1184.     1135.  0.0763\n10 2       2019   1237.     1184.  0.0770\n\n\n2015年のROEが欠損値になっており、正しい計算ができています。 クロスセクション分析におけるlag()関数の問題点を分かりやすくするために、上のようにlagged_BE変数とROE変数を別々に作成しましたが、通常は次のように書きます。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # firm_IDごとに以下の処理を繰り返す\n    mutate(\n        ROE = X / lag(BE) # これで一気に計算する方がOK\n    ) %>%\n    ungroup() # group化を解除\n\nこれでROEの計算ができので、次にROEのヒストグラムを作ってみます。\n\ng <- ggplot(financial_data) + # データの選択\n    aes(x = ROE) + geom_histogram()\ng <- g + scale_x_continuous(limits = c(-0.3, 0.5)) # x軸の範囲を調整\nprint(g)\n\n\n\n\nROEの分布が分かりました。赤字企業が分かりやすいように、ROEがゼロのところに縦線を引いてみます。 縦線を引くにはgeom_vline()を使い、横線を引くにはgeom_hline()を使います。\n\ng <- g + geom_vline(xintercept = 0, color = \"red\") # x軸に縦線を引く\nprint(g)"
  },
  {
    "objectID": "Chap04.html#グループごとの集計とランク付け",
    "href": "Chap04.html#グループごとの集計とランク付け",
    "title": "4  財務データの取得と可視化",
    "section": "4.7 グループごとの集計とランク付け",
    "text": "4.7 グループごとの集計とランク付け\n\n4.7.1 産業ごとのROE平均値と棒グラフによる可視化\nグループごとに平均値を出すといった処理は，dplyrのgroup_by()とsummarise()を用いることで簡単にできます。\nここでは、産業ごとにROEの平均値と標準偏差を求めてみます。ROEには欠損値が含まれているため、mean()関数を使うとNAが返ってきます。NAを無視して平均値を計算するには、mean()関数のオプションna.rm = TRUEを指定します。\n\ndf_ind <- financial_data %>%\n    group_by(industry_ID) %>% # 集計したいグループを指定\n    summarize(\n        mean_ROE = mean(ROE, na.rm = TRUE), # 産業平均\n        sd_ROE = sd(ROE, na.rm = TRUE)　# 産業標準偏差\n    )\nglimpse(df_ind)\n\nRows: 10\nColumns: 3\n$ industry_ID <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ mean_ROE    <dbl> 0.07731106, 0.10761577, 0.07548896, 0.07371925, 0.08570296…\n$ sd_ROE      <dbl> 0.09264764, 0.09530125, 0.05569899, 0.04676826, 0.04859797…\n\n\n10の産業ごとに統計量を計算したので、10行のデータが返ってきました。 このデータを用いて産業ごとのROE平均の棒グラフを作成してみます。\n\n# 作図\nggplot(df_ind) + # データフレームを指定\n    aes(x = industry_ID, y = mean_ROE) + # 変数を2つ指定\n    geom_col() + # 棒グラフ geom_bar()もあるけどこっち\n    labs(x = \"産業ID\", y = \"産業平均ROE\") + # ラベル設定\n    scale_y_continuous(expand = c(0,0)) + mystyle # グラフの原点0,0に設定\n\n\n\n\n教科書では，パイプ処理%>%で直接ggplot()にデータフレームを渡していますが，個人的に可読性が低くなりオススメできないので，上の例ではデータ操作と作図を分けて書きました。 好みの問題なので、どちらでも構いません。\n次に、2020年度の産業別ROEランキングを作ってみます。 ROEを大きい順にならべて、一番大きい企業に1、2番目の企業に2、という風にランキングを表す変数を作成するには、rank(desc())を使います。desc()は降順に並べ替える関数です。\n下のソースコードでは、前半のまとまりで、以下の処理を行ったデータを新しいデータフレームROE_rank_dataに代入しています。\n\nfinancial_dataの中から2020年度のデータを抽出し、\n必要な変数としてfirm_ID、industry_ID、ROEの3つを選択し、\nindustry_IDごとにグループ化して、\nmutate()関数でROE_rank変数を作成し,\nungroup()関数でグループ化を解除しています。\n\n後半のまとまりでは、上で作成したROE_rank_dataに対して、\n\n産業ごとのROEランキング第1位の企業を抽出し、\nROEが大きい順に並べ替えて、\nそれをknitr::kable()関数で表として出力\n\nという処理をしています。\n\n# 2020年度の産業内のROEランキングの変数を作成\nROE_rank_data <- financial_data %>%\n    filter(year == 2020) %>% # 2020年度データを抽出\n    select(firm_ID, industry_ID, ROE) %>% # 必要な変数を選択\n    group_by(industry_ID) %>% # 産業コードごとに以下の処理を実行\n    mutate(\n        ROE_rank = rank(desc(ROE)) # ROE_rank変数を降順で作成\n    ) %>%\n    ungroup()# グループ化を解除\nprint(ROE_rank_data)\n\n# A tibble: 1,363 × 4\n   firm_ID industry_ID     ROE ROE_rank\n   <fct>   <fct>         <dbl>    <dbl>\n 1 1       1           0.0762        85\n 2 2       1           0.0728        90\n 3 3       1           0.119         36\n 4 4       1           0.0216       154\n 5 5       1           0.113         39\n 6 7       1           0.00379      167\n 7 8       1           0.388          1\n 8 9       1           0.0913        68\n 9 10      1           0.111         44\n10 11      1           0.130         28\n# ℹ 1,353 more rows\n\n\n上の処理により、financial_dataのデータフレームにROE_rankという変数が追加して、ROE_rank_dataという新しいオブジェクトに代入しました。\n\nROE_rank_data %>%\n    filter(ROE_rank == 1) %>% # 各産業のランク1のものを抽出\n    arrange(desc(ROE)) %>%  # ROEが大きい順\n    knitr::kable(booktabs = TRUE, # ここから下は表の装飾\n        caption = \"2020年度産業別ROEランキング第1位企業\",\n        position = \"h!\" # 表示場所はここに\n        )\n\n\n2020年度産業別ROEランキング第1位企業\n\n\nfirm_ID\nindustry_ID\nROE\nROE_rank\n\n\n\n\n929\n7\n0.5641813\n1\n\n\n475\n3\n0.4975356\n1\n\n\n8\n1\n0.3882552\n1\n\n\n242\n2\n0.3749986\n1\n\n\n661\n5\n0.2673141\n1\n\n\n1042\n8\n0.2559963\n1\n\n\n1380\n10\n0.2497929\n1\n\n\n1167\n9\n0.2346232\n1\n\n\n619\n4\n0.1491307\n1\n\n\n719\n6\n0.1422026\n1\n\n\n\n\n\nindustry_IDが7の産業の中のfirm_IDが929の企業のROEが0.5641813ということがわかりました。 この企業は、financial_dataの中でどのような企業なのかを調べてみましょう。\n\nfinancial_data %>%\n    filter(firm_ID == 929) %>% # firm_IDが929の企業を抽出\n    select(firm_ID, industry_ID,sales,OX,BE, ROE) %>% # 必要な変数を選択\n    knitr::kable(booktabs = TRUE, # ここから下は表の装飾\n        caption = \"企業929のROE\",\n        position = \"h!\" # 表示場所はここに\n        )\n\n\n企業929のROE\n\n\nfirm_ID\nindustry_ID\nsales\nOX\nBE\nROE\n\n\n\n\n929\n7\n10696.59\n-3.23\n1134.92\nNA\n\n\n929\n7\n12423.11\n17.16\n971.44\n0.0297113\n\n\n929\n7\n8148.15\n-48.69\n980.28\n-0.0437907\n\n\n929\n7\n8173.33\n-687.52\n668.91\n-0.7019219\n\n\n929\n7\n1562.78\n132.68\n804.05\n0.2020302\n\n\n929\n7\n5832.03\n490.84\n1257.68\n0.5641813\n\n\n\n\n\n業績のばらつきが大きく、ROEも乱高下する企業であることが分かりました。"
  },
  {
    "objectID": "Chap04.html#上級デュポンモデルによるroeの分析とその可視化",
    "href": "Chap04.html#上級デュポンモデルによるroeの分析とその可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.8 上級デュポン・モデルによるROEの分析とその可視化",
    "text": "4.8 上級デュポン・モデルによるROEの分析とその可視化\n上級デュポン・モデルとは，次式で表されるROEの分解式です。\n\n\\begin{aligned}\nROE_t := \\frac{X_t}{BE_{t-1}} &= \\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} + \\underbrace{\\frac{NFO_{t-1}}{BE_{t-1}}}_{FLEV_{t-1}} \\times \\left[ \\frac{OX_t}{NOA_{t-1}} - \\frac{NFE_t}{NFO_{t-1}} \\right]\n\\end{aligned}\n\n各変数の意味は以下の通りです。 - X : 当期純利益(net income) - BE : 株主資本(book of equity) - OX : 事業利益(operating income) - NOA : 純事業資産(net operating assets) - NFO : 純金融負債(net financial obligations) - NFE : 純金融費用(net financial expenses)\nRNOA_tは，ATO_tとPM_tとに分割できます。\n\n\\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} = \\underbrace{\\frac{sales_t}{NOA_{t-1}}}_{ATO_t} \\times \\underbrace{\\frac{OX_t}{sales_t}}_{PM_t}\n\nいくつかの変数は，元のデータには含まれていないので，与えられたデータから計算する必要があります。 dplyr::mutate()関数を用いて新しい変数を作成し，データフレームに追加します。 lag()で前期末(つまり当期首)の値を取得するため，group_by()関数で企業ごとにグループ化しています。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # 企業IDごとに以下の計算を行う。\n    mutate(\n        NOA = OA - OL, # 純事業資産 = 事業資産 - 事業負債\n        RNOA = OX / lag(NOA), # 会計上の事業リターン\n        PM = OX / sales, # 利ざや profit margin\n        ATO = sales / lag(NOA), # 純事業資産回転率\n        NFO = FO - FA, # 純金融負債 = 金融負債 - 金融資産\n        lagged_FLEV = lag(NFO) / lagged_BE, #期首財務レバレッジ\n        NBC = NFE / lag(NFO), # 債権者のリターン net borrowing cost\n        ROE_DuPont = RNOA + lagged_FLEV * (RNOA - NBC) # 上級デュポン・モデルによるROE\n    ) %>%\n    ungroup()\n\nROEの分解式が合っているかどうかを確認するため，all.equal()関数を使って，第1引数と第2引数が等しいかどうかを判定してみます。 普通に計算したROEと上級デュポン・モデルの分解したものから計算したROE_DuPointとの比較しています。\n\nall.equal(financial_data$ROE, financial_data$ROE_DuPont)\n\n[1] \"Mean relative difference: 4.396878e-06\"\n\n\nとなり，差の平均は4.396878 \\times 10^{-6}となり，ほぼ0となっていることから，上級デュポン・モデルの分解式が正しいことが確認できます。 完全にゼロにならない理由は計算の過程で生じる丸め誤差によるものです。\n\n4.8.1 箱ひげ図による産業別比較\n産業別で利ざやPMがどのように分布しているのかを調べるために，箱ひげ図(box plot)を作ってみます。 箱ひげ図は，データの分布を可視化するためのグラフで，第1四分位点，中央値，第3四分位点，(異常値をのぞく)最大値，(異常値をのぞく)最小値を表現できる，非常に情報量の多いグラフです。\nggplot2パッケージのgeom_boxplot()関数を用いることで，データフレームから箱ひげ図を作図できます。\n先に作成したデータフレームfinancial_dataを用いて，PMの箱ひげ図を作成してみましょう。 あまり多くの箱ひげ図を作っても見づらくなるので，最終年度のデータ で，産業IDが2〜6までの企業に限定します。\n\ndf_2020 <- financial_data %>%\n    filter(\n        year == 2020, # 最終年度\n        industry_ID %in% 2:6 # 産業コードが2から6\n    )\ng <- ggplot(df_2020) +\n  aes(x = industry_ID, y = PM, fill = industry_ID) + \n  geom_boxplot() # 箱ひげ図\ng <- g + labs(x = \"Industry ID\") + mystyle\nprint(g)\n\n\n\n\n箱ひげ図から，産業ごとに利ざやの分布が異なることがわかります。とりわけ産業3は利ざやの散らばりが大きく，産業4は非常に散らばりが小さいことが分かります。\n\n\n4.8.2 散布図による産業別比較\n次に産業ごとに ATO(純事業資産回転率)と PM(売上高事業利益率)がどう分布しているか散布図を書いてみます。 ここでは異常値の影響を受けにくい統計量である中央値(median)を計算し，散布図を作成してみます。\n\ndf_ind_median <- financial_data %>%\n    group_by(industry_ID) %>%\n    summarise(\n        median_ATO = median(ATO, na.rm = TRUE), # ATOの中央値\n        median_PM = median(PM, na.rm = TRUE) # PMの中央値\n    )\n\ng <- ggplot(df_ind_median) + \n    aes(x = median_ATO, y = median_PM, label = industry_ID) + # 散布図\n    geom_point() + # 散布図\n    geom_text(vjust=-1) + \n    xlab(\"純事業資産回転率(ATO)の中央値\") + ylab(\"売上高事業利益率(PM)の中央値\") + mystyle# ラベル\nprint(g)\n\n\n\n\nこの産業ごとに計算された中央値のデータを用いて，線形回帰直線を引いて，ATOとPMの関係を見てみます。\n\ng <- g + geom_smooth(method = \"lm\", se = FALSE) # 線形回帰直線を追加\nprint(g)\n\n\n\n\nいい感じですが，会計学入門(1.3.4節)で学習したATO \\times RM = RNOAという関係のとおり，データからもATOとPMとの間にトレードオフの関係があることが予想されています。 もし理論どおりの関係であればデータはATO = RNOA / PMといった反比例の関係になるはずです。これを示すため，RNOAを一定としたときのATOとPMの関係，つまりを図に書き込んでみます。 関数をグラフとして図に追加するためにstat_function()関数を用います。\n\n\n\n\n\n\nTips\n\n\n\nstat_function()関数の引数は，fun = function(x) xの関数系, linetype = “スタイル”とします。 ここでは，function(x)でxの関数であることを指定し，median_RNOA / xとしてます。\n\n\n\nmedian_RNOA <- median(financial_data$RNOA, na.rm = TRUE) # 全データから計算したRNOAの中央値\n\ng <- g + stat_function(\n    fun = function(x) median_RNOA / x, \n    linetype = \"longdash\", \n    color = \"red\") # 反比例の関数を追加\nprint(g)\n\n\n\n\nかなりあてはまりが良さそうな線が引けました。 このように，データを可視化することで，理論とデータの整合性を確認することができます。"
  },
  {
    "objectID": "Chap05.html",
    "href": "Chap05.html",
    "title": "5  株式データの取得と可視化",
    "section": "",
    "text": "前章では財務データを題材に、クロスセクションデータを扱うために必要なデータの取得と操作と可視化について学習しました。 特に重要な操作として，group_by()関数とmutate()やsummarise()関数の組み合わせて，グループごとの変数の値を計算する方法を学びました。 本章では株式データを題材に，株式データの理解に必要な株式の基礎知識とともに，リターンの定義や計算について学び，最後には統計的推論と線形回帰分析についても学習します。\n株式データの理解を深めるために，株式市場の仕組みを理解する必要があるので，重要用語の説明を行います。"
  },
  {
    "objectID": "Chap05.html#時価総額とリターンの計算",
    "href": "Chap05.html#時価総額とリターンの計算",
    "title": "5  株式データの取得と可視化",
    "section": "5.1 時価総額とリターンの計算",
    "text": "5.1 時価総額とリターンの計算\n時価総額(market capitalization)を計算するためには、株式数に株価を掛けて計算します。 新しい変数を作成するときはdplyrパッケージのmutate()関数を使います。 mutate()で時価総額を表す新しい変数MEを作成します。\n\nstock_data <- stock_data %>%\n  mutate(ME = stock_price * n_shares) # 時価総額MEを作成\n\n次に時価総額のヒストグラムを作成してみます。 前節で学習した内容に加えて、いろいろ見た目の指定を増やしてみます。 グラフの体裁を整えるため、ggplot2の機能を拡張するggthemesパッケージを追加します。\n\nlibrary(ggthemes) # グラフの体裁を整えるパッケージを追加\nlibrary(scales) # 軸の表記を変えるパッケージを追加\nmystyle <- list (#  ggplotのテーマ\n  theme_few(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n\ng <- ggplot(stock_data) + aes(x = ME)\ng <- g + geom_histogram() #基本設定\ng <- g + xlab(\"Market Equity\") + ylab(\"Count\") #軸ラベル\ng <- g + scale_x_continuous(\n  limits = c(0, quantile(stock_data$ME, 0.95)), # x軸の範囲\n  labels = label_comma(scale = 1e-6) # x軸の表記を百万円単位に\n  ) + xlab(\"時価総額\") + ylab(\"度数\") +  mystyle\nprint(g) # グラフを出力\n\n\n\n\n\n5.1.1 トータル・リターンと超過リターンの計算\nある株式のt期のトータル・リターンR_tは、次式で定義されます。\n\nR_t = \\frac{(\\text{株価}_t + \\text{1株当り配当}_t) \\times \\text{調整係数}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\nたいていの場合，1株当り配当DPS_tはゼロで，調整係数adjustment\\_coefficient_tは1となるため，次式のように簡略化できます。\n\nR_t = \\frac{\\text{株価}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\n銘柄ごとにリターンを計算するので，group_by()とmutate()を使って計算します。ここでは，firm_IDごとにトータルリターンRと， トータルリターンから無リスク利子率を除いた超過リターンReを計算しています。\n\nstock_data <- stock_data %>%\n  group_by(firm_ID) %>% # 企業ごとに\n  mutate( # 新しい変数を作成\n    # トータルリターン\n    R = ( (stock_price + DPS) * adj_coef - lag(stock_price)) / lag(stock_price),\n    Re = R - R_F # 月次超過リターン\n  ) %>%\n  ungroup() # グループ化を解除\n\nここまでの処理でstock_dataに時価総額ME，トータルリターンR，超過リターンReが追加されました。 以下では，このデータを使って探索的データ分析を行います。\n\n\n5.1.2 株式データの探索的データ分析\n探索的データ分析という名の，とりあえず何も考えずに目の前のデータから何が分かるのかを調べ倒してみる，という分析を行います。\nとりあえず，summary()で基本統計量を確認します。\n\nsummary(stock_data)\n\n      year          month          month_ID        firm_ID      \n Min.   :2015   Min.   : 1.00   Min.   : 1.00   Min.   :   1.0  \n 1st Qu.:2016   1st Qu.: 3.75   1st Qu.:19.00   1st Qu.: 384.0  \n Median :2018   Median : 6.50   Median :37.00   Median : 760.0  \n Mean   :2018   Mean   : 6.50   Mean   :37.01   Mean   : 761.2  \n 3rd Qu.:2019   3rd Qu.: 9.25   3rd Qu.:55.00   3rd Qu.:1147.0  \n Max.   :2020   Max.   :12.00   Max.   :72.00   Max.   :1515.0  \n                                                                \n  stock_price          DPS              n_shares            adj_coef     \n Min.   :   112   Min.   :   0.000   Min.   :3.700e+04   Min.   :0.1000  \n 1st Qu.:  1417   1st Qu.:   0.000   1st Qu.:3.151e+06   1st Qu.:1.0000  \n Median :  2445   Median :   0.000   Median :1.014e+07   Median :1.0000  \n Mean   :  4685   Mean   :   6.802   Mean   :6.973e+07   Mean   :0.9999  \n 3rd Qu.:  4558   3rd Qu.:   0.000   3rd Qu.:3.564e+07   3rd Qu.:1.0000  \n Max.   :622796   Max.   :1913.000   Max.   :2.111e+10   Max.   :2.0000  \n                                                                         \n      R_F                   ME                  R                 Re         \n Min.   :-2.329e-04   Min.   :1.459e+08   Min.   :-0.3803   Min.   :-0.3802  \n 1st Qu.: 8.233e-06   1st Qu.:9.648e+09   1st Qu.:-0.0406   1st Qu.:-0.0408  \n Median : 8.203e-05   Median :2.563e+10   Median : 0.0103   Median : 0.0101  \n Mean   : 2.041e-04   Mean   :1.365e+11   Mean   : 0.0159   Mean   : 0.0157  \n 3rd Qu.: 4.626e-04   3rd Qu.:7.987e+10   3rd Qu.: 0.0648   3rd Qu.: 0.0646  \n Max.   : 7.368e-04   Max.   :3.293e+13   Max.   : 0.5150   Max.   : 0.5145  \n                                          NA's   :1515      NA's   :1515     \n\n\nさらに，分散と標準偏差も計算します。データには欠損値が含まれているため，na.rm = TRUEオプションをつけています。 教科書とは違いますが，dplyr::summarize()関数を使って一気に複数の統計量を計算します。 ここでは，stock_data <- stock_dataとしていないため，stock_dataには新しい変数は追加されず，結果を表示するだけです。\n\nstock_data %>%\n  summarise(\n    var_R = var(R, na.rm = TRUE), # 総リターンの分散\n    sd_R  = sd(R, na.rm = TRUE), # 総リターンの標準偏差\n    var_Re = var(Re, na.rm = TRUE), # 超過リターンの分散\n    sd_Re = sd(Re, na.rm = TRUE) # 超過リターンの標準偏差\n  )\n\n# A tibble: 1 × 4\n    var_R   sd_R  var_Re  sd_Re\n    <dbl>  <dbl>   <dbl>  <dbl>\n1 0.00830 0.0911 0.00830 0.0911\n\n\nデータの分布の形を表す統計量である，3次のモーメントである歪度(skewness)と4次のモーメントである尖度(kurtosis)も計算してみます。 たとえば確率変数xの歪度は\n\n\\text{歪度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^3\n\nで表され，正の値をとるとき分布が右に歪んでいる(裾が右に長い)ことを示している。 尖度は，\n\n\\text{尖度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^4\n\nで定義され，尖度が3のとき，正規分布と同じ尖度を持つことを示し，3より小さいとき，正規分布よりとがった分布をしていることを示します。\n歪度と尖度を計算するには，e1071パッケージのskewness()関数を使います。\n\nlibrary(\"e1071\")\nstock_data %>%\n  summarise(\n    skewness_R = skewness(R, na.rm = TRUE), # 総リターンの歪度\n    kurtosis_R = kurtosis(R, na.rm = TRUE), # 総リターンの尖度\n    skewness_Re = skewness(Re, na.rm = TRUE), # 超過リターンの歪度\n    kurtosis_Re = kurtosis(Re, na.rm = TRUE) # 超過リターンの尖度\n  )\n\n# A tibble: 1 × 4\n  skewness_R kurtosis_R skewness_Re kurtosis_Re\n       <dbl>      <dbl>       <dbl>       <dbl>\n1      0.507       1.27       0.507        1.27\n\n\nトータルリターンの歪度が0.507 >0なので，右に裾の広い分布となっており，尖度が1.27 < 3なので正規分布よりもとがった形となっていることがわかります。\n図でも確認するために，トータルリターンRのヒストグラムを書いてみます。\n\nggplot(stock_data) +\n  aes(x = R) + geom_histogram() + # トータルリターンのヒストグラム\n  xlab(\"Monthly Stock Return\") + ylab(\"Count\") + mystyle # 軸ラベル\n\n\n\n\nトータルリターンのヒストグラムに正規分布のグラフを重ねてみると，次のようになります。\n\n# トータルリターン\nR <- stock_data$R\n\n# 正規分布データ作成\nm <- mean(stock_data$R, na.rm = TRUE)\nsd <- sd(stock_data$R, na.rm = TRUE)\nx <- rnorm(95040, mean = m, sd = sd)\n\ndf <- data.frame(R,x) %>% drop_na() # 欠損値削除\ndf <- df %>% pivot_longer(everything())\n\nトータルリターンと正規分布のヒストグラムを書いてみる。\n\ng <- ggplot(df) + aes(x = value, fill = name, group = name) +\n  geom_histogram(bins = 100, alpha = 0.4, position=\"identity\") +\n  xlab(\"Monthly Stock Return\") + ylab(\"Count\")\ng <- g + annotate( # 位置を指定して文字列を追加\n  geom = \"text\", x = 0.3, y = 900, label = \"fat tail\") +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 0.3, xend = 0.3,\n  y = 800, yend = 300,\n  color = \"black\",  size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng <- g + annotate( # 位置を指定して文字列を追加\n  geom = \"text\", x = 0.3, y = 4200,\n  label = \"Sharp shape\"\n  ) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 0.2, xend = 0.1,\n  y = 4200, yend = 4200,\n  color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng <- g + mystyle\nprint(g)\n\n\n\n\n歪度と尖度の結果と整合的に、赤色で表されているトータルリターンのヒストグラムは正規分布よりも右に裾が長く，尖度も正規分布よりもとがった形となっています。"
  },
  {
    "objectID": "Chap05.html#バイアンドホールドリターンの考え方",
    "href": "Chap05.html#バイアンドホールドリターンの考え方",
    "title": "5  株式データの取得と可視化",
    "section": "6.1 バイ・アンド・ホールド・リターンの考え方",
    "text": "6.1 バイ・アンド・ホールド・リターンの考え方\nバイ・アンド・ホールド・リターン(buy-and-hold-return)は，ある時点で株式を購入し，そのまま保有し続けたときのリターンのことを指します。 たとえば，12月末に株式を購入し，3月末に売却したときの、バイ・アンド・ホールド・リターンの累積は，次式で計算できます。ただし配当は無視します。\n\n\\begin{aligned}\n\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{12月}}} \\right) =\n\\underbrace{\\left ( \\frac{W_{\\text{1月}}}{W_{\\text{12月}}} \\right)}_{1 + R_{\\text{1月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{2月}}}{W_{\\text{1月}}} \\right)}_{1 + R_{\\text{2月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{2月}}} \\right)}_{1 + R_{\\text{3月}}} \\times\n\\end{aligned}\n\n一般的に、月次でt時点からT時点までの年次リターンは、\n\n\\left ( \\frac{W_{\\text{翌年12月末}}}{W_{\\text{12月末}}} \\right) = \\prod_{t = \\text{1月}}^{\\text{12月}} (1 + R_t)\n\nと計算できます。"
  },
  {
    "objectID": "Chap05.html#年次リターンの計算",
    "href": "Chap05.html#年次リターンの計算",
    "title": "5  株式データの取得と可視化",
    "section": "6.2 年次リターンの計算",
    "text": "6.2 年次リターンの計算\nでは、stock_dataをもとに年次リターンを計算してみましょう。\n\nannual_stock_data <- stock_data %>%\n  group_by(firm_ID, year) %>% # firm_IDとyearごとにグループ化\n  summarise(\n    annual_R = prod(1 + R) - 1, # B&H年次リターン\n    annual_R_F = prod(1 + R_F) - 1 # 年次超過リターン\n  ) %>%\n  mutate(annual_Re = annual_R - annual_R_F) %>% # 年次超過リターン\n  ungroup()\nhead(annual_stock_data)\n\n# A tibble: 6 × 5\n  firm_ID  year annual_R annual_R_F annual_Re\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>\n1       1  2015   NA      0.00743      NA    \n2       1  2016    0.997  0.000565      0.997\n3       1  2017    0.688  0.0000488     0.688\n4       1  2018   -0.214  0.00579      -0.219\n5       1  2019    0.647 -0.000770      0.648\n6       1  2020   -0.284  0.000380     -0.285"
  },
  {
    "objectID": "Chap05.html#データの結合",
    "href": "Chap05.html#データの結合",
    "title": "5  株式データの取得と可視化",
    "section": "7.1 データの結合",
    "text": "7.1 データの結合\n複数のデータフレームを結合する際に重要なところは、\n\nデータの頻度の違い\nタイミングの一致\n\nとなる。 今まで使ってきた財務データは年次データであるのに対して，株式データは月次データであるため，データの頻度が異なります。 確認してみましょう。\n\nfinancial_data <- read_csv(\"data/ch04_output.csv\")\nnrow(financial_data) # 年次財務データの行数\n\n[1] 7919\n\nnrow(annual_stock_data) # 年次リターン・データの行数\n\n[1] 7920\n\nnrow(stock_data) # 月次リターン・データの行数\n\n[1] 95040\n\n\n月次リターンの行数が上の年次データとは大きく異なっていることが分かります。\n\n\n\n\n\n\n先読みバイアス(look-ahead bias)とは、ある時点での情報を使って、その時点よりも未来の情報を使っていることを指します。12月末決算の会社のディスクロジャージャーは、最速で決算日後45日以内に出される決算短信か、3ヶ月以内に出される有価証券報告書があります。 このため、年次データを使って同時期の年次リターンを計算すると、年次データの発表後に出される有価証券報告書の情報を使っていることになります。これを先読みバイアスといいます。\n\n\n\n\nannual_data <- annual_stock_data %>%\n  full_join(financial_data, by = c(\"firm_ID\", \"year\")) # firm_IDとyearのペアをキーとして設定\n\n\nannual_data <- annual_stock_data %>%\n  full_join(financial_data) # キーを省略した場合，列名が同じ変数がキーになる\nhead(annual_data)\n\n# A tibble: 6 × 17\n  firm_ID  year annual_R annual_R_F annual_Re industry_ID sales    OX   NFE\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>       <dbl> <dbl> <dbl> <dbl>\n1       1  2015   NA      0.00743      NA              NA   NA    NA   NA  \n2       1  2016    0.997  0.000565      0.997           1 5949.  564.  50.7\n3       1  2017    0.688  0.0000488     0.688           1 6505.  691.  29.5\n4       1  2018   -0.214  0.00579      -0.219           1 6846.  751.  86.5\n5       1  2019    0.647 -0.000770      0.648           1 7572.  959. 298. \n6       1  2020   -0.284  0.000380     -0.285           1 7538.  778. -65.5\n# ℹ 8 more variables: X <dbl>, OA <dbl>, FA <dbl>, OL <dbl>, FO <dbl>,\n#   BE <dbl>, lagged_BE <dbl>, ROE <dbl>\n\n\n\nmonthly_data <- stock_data %>%\n  full_join(financial_data, by = c(\"firm_ID\", \"year\")) # firm_IDとyearのペアをキーとして設定"
  },
  {
    "objectID": "Chap05.html#バブルチャート",
    "href": "Chap05.html#バブルチャート",
    "title": "5  株式データの取得と可視化",
    "section": "7.2 バブルチャート",
    "text": "7.2 バブルチャート\n\nannual_data <- stock_data %>%\n  filter(month == 12) %>% # 12月のみ\n  select(year, firm_ID, ME) %>% # 変数を選択\n  full_join(annual_data, ., by = c(\"year\", \"firm_ID\")) %>% # 年次データと結合\n  mutate(ME = ME / 1e6) # MEを百万円単位に変換\n\n\nyear2015 <- annual_data %>%\n   filter(\n      year == 2015, # 2015年のみ\n      firm_ID %in% 2:20, # firm_IDが2から20のデータを抽出\n      X > 0 # 対数を取るため当期純利益が正のデータのみ抽出\n      )\n\nggplot(year2015) +\n  aes(x = log(sales), y = log(X), size = ME, alpha = 0.4) +\n  geom_point() + # バブルチャートを描くにはsize引数を指定\n  scale_size(range = c(1, 20), name = \"Market Equity\") + # rangeでバブルの最小最大面積を指定\n  scale_x_continuous(limits = c(8, 14)) + # 両軸の範囲を指定\n  scale_y_continuous(limits = c(2, 11)) + mystyle"
  },
  {
    "objectID": "Chap05.html#リターンデータに関する仮定",
    "href": "Chap05.html#リターンデータに関する仮定",
    "title": "5  株式データの取得と可視化",
    "section": "8.1 リターン・データに関する仮定",
    "text": "8.1 リターン・データに関する仮定\n統計的推論の内容に入る前に、firm_IDが1の企業の超過リターンReのデータを眺めてみます。\n\nstock_data_1_month <- stock_data %>%\n  filter(firm_ID == 1) %>%\n  select(month_ID, Re, R)\nggplot(stock_data_1_month) +\n  aes(x = month_ID, y = Re) + # 軸の設定\n  geom_line() + mystyle # 折れ線グラフ\n\n\n\n\nこのようなデータは時系列データと呼ばれ、ある個体(ここではfirm_IDが1の企業)の一定期間にわたって観測したデータのことを指します。\n\n\n\n\n\n\n重要\n\n\n\n月次超過リターンの時系列データは、何らかの確率分布(モデル)から独立に生成されている。\n\n\n\n株価そのものでは無く変化率であるリターンをモデル化する理由\n\n株価それ自体は株式分割などの要因でも変化するし、会社の成長に応じて上昇するため、その成長率をモデル化する方が、投資のリスクに対するリターンをより明確に評価することができるからである。\n\n月次リターンではなく月次超過リターンをモデルかする理由\n\n投資リスクを取って得られる追加的なリターンであるリスクプレミアムを明確に評価するために、無リスク金利を差し引いた超過リターンをモデル化します。\n\n月次超過リターンが独立であるとする理由\n\n半強度の効率的市場であれば、過去の情報はすでに株価に織り込まれているので、過去の超過リターンは将来の超過リターンと無関係である、とし、超過リターンに系列相関はない、と仮定します。 しかし、アノマリーの存在などにより、現実には系列相関があると考えられますが、モデルが複雑になるので、ここでは独立の仮定をおいて、モデルを単純化します。\n\n月次超過リターンが正規分布に従うとする理由\n\n正規分布を仮定するといろいろ計算が楽になる、という理由とともに、 株価の動きは多くの独立した事象の結果であると考えられ、中心極限定理により、超過リターンは正規分布に従うと考えられます。\nこれらの仮定を受け入れると、超過リターンの確率分布は次式で表されます。\n\nRe_t \\sim N(\\mu, \\sigma^2)\n\nこれにより、母集団分布に対して統計的推論が可能になります。 firm 1の超過リターンのヒストグラムを書いてみます。\n\nggplot(stock_data_1_month) + aes(x = Re) + # データと変数\n  geom_histogram() + scale_y_continuous(expand = c(0,0))+ mystyle \n\n\n\n\nサンプルサイズが小さいため凸凹しているけれど、もっとサンプルを増やせば、正規分布に近い形をとるはずです。"
  },
  {
    "objectID": "Chap05.html#推定量と推定値の違い",
    "href": "Chap05.html#推定量と推定値の違い",
    "title": "5  株式データの取得と可視化",
    "section": "8.2 推定量と推定値の違い",
    "text": "8.2 推定量と推定値の違い\n推定量(estimator)とは、母集団分布の母数(パラメータ)を推定するために使われる統計量のことです。 推定値(estimates)とは、推定量に実際のデータを代入して計算した値のことです。 たとえば母集団分布が正規分布N(\\mu, \\sigma^2)に従うと仮定すると、母数は\\muと\\sigma^2の2つです。この母数を推定するために使われる統計量が、それぞれ標本平均\\bar xと標本分散s^2です。 このときの推定値とは、実際に観察された標本から計算された標本平均\\bar xと標本分散s^2のことを指します。\n次の問題を考えます。\n\n\n\n\n\n\n重要\n\n\n\nfirm_IDが1の銘柄の月次リターンR_{i,t}^eは、期待値の意味で、ゼロより大きいのだろうか？\n\n\nここで「期待値の意味で」というのは平均的に、と言い換えても問題ないです。 企業1の月次超過リターンの平均は0より大きい、ということは、企業1の月次リターンは平均的に無リスク利子率よりも大きいかどうか、を比べるということです。\nこの問題を解くために、まずは母集団分布の母数である期待値\\muを推定する必要があります。 期待値\\muを推定するために使われる推定量は標本平均\\bar xなので、ここで標本平均を計算します。\n\nstock_data_1_month %>%\n  summarise(\n    mean_Re = mean(Re, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 1\n  mean_Re\n    <dbl>\n1  0.0291\n\n\n企業1の平均月次超過リターンmean_Reが0.0291となりました。 これだけみるとゼロより大きい値ですが、これは母集団から抽出された1つのサンプルの平均ですので、他のサンプルの平均がゼロを超えるかどうかは分かりません。\n\n8.2.1 大数の法則\n母集団から無限個の標本(sample)を抽出して、それぞれの標本平均(sample mean)を計算すると、その標本平均の平均は母集団の期待値\\muに一致することが知られています。これを対数の法則(law of large number)といいます。\n数式よりも前にシミュレーションで確認してみましょう。 まずは、母集団分布を平均が10、標準偏差が2の正規分布N(10, 4)として、母集団から100のデータを抽出して標本を1つ作ります。そしてその標本の平均を計算します。\n\nset.seed(123) # 乱数の種を固定\nsize <- 100 # 標本サイズ\n# 母集団のパラメータの設定\nmu <- 10 # 平均\nsigma <- 4 # 標準偏差\npopulation <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 10.36162\n\n\n平均は10.3616236となりました。 母集団の平均10とは異なる数値になっています。 もう一度別の標本でやってみると、\n\npopulation <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 9.569813\n\n\nまた違う平均が計算されました。 この作業を何度も何度も繰り返し、標本平均をたくさん計算します。 ここでは、100個のデータをもつ標本を100個作って、それぞれの標本平均を計算します。\n\nn_sample <- 100 # サンプル数\nsample_mean <- rep(NA, n_sample) # 標本平均を格納するベクトル\nsample_sd <- rep(NA, n_sample) # 標本分散を格納するベクトル\nfor(i in 1:n_sample){\n  population <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\n  sample_mean[i] <- mean(population) # 標本平均を計算\n  sample_sd[i] <- sd(population)\n}\n\nサンプルの平均が100個計算できたので、ヒストグラムを書いてみます。\n\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\nあまり正規分布のようには見えません。 ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 9.99003\n\n\n母集団の平均10に近い値になっていることが分かります。もっとサンプルの数を増やしてみます。 データの数が100のサンプルを1,000,000個(100万個)抽出して、それぞれのサンプルの平均値を計算します。\n\nn_sample <- 10^6 # サンプル数\nsample_mean <- rep(NA, n_sample) # 標本平均を格納するベクトル\nsample_sd <- rep(NA, n_sample) # 標本分散を格納するベクトル\nfor(i in 1:n_sample){\n  population <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\n  sample_mean[i] <- mean(population) # 標本平均を計算\n  sample_sd[i] <- sd(population)\n}\n\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\nほぼ正規分布のような形をしていることが分かります。ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 10.00063\n\nmean(sample_sd) # 標本分散の平均\n\n[1] 3.990079\n\n\nこのように標本の数を無限に大きくしたとき、サンプルの平均の平均は母集団の平均10に一致するし，標本標準偏差は母集団の標準偏差4に一致する，というのが大数の法則です。"
  },
  {
    "objectID": "Chap05.html#t値の計算",
    "href": "Chap05.html#t値の計算",
    "title": "5  株式データの取得と可視化",
    "section": "8.3 t値の計算",
    "text": "8.3 t値の計算\n先ほど計算したfirm_IDが1の企業の超過リターンの平均値はNAでした。 これがゼロより大きいかどうかはすぐ分かりますが，この値はたまたま今手元にある1つのサンプルから計算された平均値なので，他の標本ではどうなるか分かりません。 このように推定量にばらつきがある場合には，その推定量の分布を考える必要があります。 ここでは，その分布をt分布(t distribution)と仮定して，t値(t-value)を計算してみます。 t値は次のように定義されます。\n\nt = \\frac{\\bar{X} - \\mu_0}{\\sqrt{s^2 / n} } \\stackrel{d}{\\approx} N(0,1)\n\nここで，\\bar Xは標本平均，\\mu_0は帰無仮説(null hypothesis)の値で，ここでは\\mu_0 = 0とします。s^2は標本分散，nは標本サイズです。 分子に注目すると，標本平均と帰無仮説の値の差となっており，もし標本平均が0に近いなら，t値は0に近い値になります。\n\nRe_firm_ID_1 <- stock_data %>%\n  filter(firm_ID == 1) %>% # firm_IDが1の企業のデータを抽出\n  select(Re) %>% #超過リターンのみ選択\n  drop_na() %>% # 欠損値を除去\n  unlist() # データフレームをベクトルに変換\n\nmu0 <- 0 # 帰無仮説の値\nn <- length(Re_firm_ID_1) # 標本サイズ\n\nt_value <- (mean(Re_firm_ID_1) - mu0) / sqrt(var(Re_firm_ID_1) / n) # $t$値の計算\nprint(t_value)\n\n[1] 2.121296\n\n\n\n8.3.1 統計的検定の考え方\nあなたがサイコロを投げるゲームをしていて、あるプレイヤーが非常に幸運だと主張しています。彼は6回サイコロを投げて、5回も「6」が出たとします。これはただの偶然なのか、それとも何か他の要因（例えば、サイコロがいかさまであるとか）が関与しているのでしょうか？\nこの問いに答えるために、我々は統計的検定(statistical test)を用いることができます。 まず帰無仮説(null hypothesis)を設定します。 この例では、帰無仮説は「サイコロは公正であり、すべての出目が等確率（1/6）で出る」とすることが適切です。\n次に、この帰無仮説が真(true)である場合に、我々が観察した結果（5回の「6」）がどれほどあり得ないかを計算します。これがp値(p value)です。この場合、6回投げて5回「6」が出る確率を計算します。\nこれを計算すると、p値は非常に小さいことが分かり（つまり、この結果は帰無仮説の下ではほぼあり得ない），帰無仮説が棄却されます。 帰無仮説が棄却されるとは，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいことを意味します。 したがって、我々はこの結果が偶然生じたとは考えにくく、その代わりにサイコロがいかさまである、または何か他の非ランダムな要因が作用している可能性を強く疑うことになります。これがp値を用いて統計的検定の考え方です。\np値が0.05より小さい場合，帰無仮説は棄却され，対立仮説が採択される，というケースが多いです。 この場合，有意水準5%で帰無仮説は棄却されます。 有意水準は，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいと判断する基準値です。 有意水準は，5%や1%がよく使われます。\nRでは，t.test()関数を使って，t値とp値を計算することができます。 ここでは，t.test()関数を使って，firm_IDが1の企業の超過リターンがゼロなのかどうなのか，を検定するために，t値とp値を計算してみましょう。\n\nt.test(Re_firm_ID_1)\n\n\n    One Sample t-test\n\ndata:  Re_firm_ID_1\nt = 2.1213, df = 70, p-value = 0.03744\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.001737894 0.056383256\nsample estimates:\n mean of x \n0.02906058"
  },
  {
    "objectID": "Chap05.html#ols推定",
    "href": "Chap05.html#ols推定",
    "title": "5  株式データの取得と可視化",
    "section": "9.1 OLS推定",
    "text": "9.1 OLS推定\n推定方法として最も有名なものが最小二乗法(ordinary least squares; OLS)です。 最小二乗法では，観測値と推定値の差の二乗の和が最小になるように\\alphaと\\betaを推定します。 このとき，観測値と推定値の差を残差(residual)と呼びます。 最小二乗法では，残差の二乗の和である残差平方和(sum of squared residuals; SSR)が最小になるように\\alphaと\\betaを推定します。\n\n\\min _{\\alpha, \\beta} \\sum _{i=1}^n (Y_i - \\alpha - \\beta X_i)^2\n\n\nlm_sample_data <- annual_data %>%\n  group_by(firm_ID) %>% # 企業IDごとに\n  mutate(\n    lagged_BEME = lag(BE) / lag(ME), # 期首簿価時価比率\n  ) %>%\n  ungroup() %>%\n  filter(year == 2016, firm_ID <= 10) %>%\n  select(firm_ID, year, annual_Re, lagged_BEME) %>%\n  drop_na() # 欠損値を除去\n\nggplot(lm_sample_data) +\n  geom_point(aes(x = lagged_BEME, y = annual_Re)) + # 散布図\n  xlab(\"簿価時価比率\") + ylab(\"超過リターン\") + mystyle\n\n\n\n\n簿価時価比率と株式リターンの散布図に回帰直線を追加します。 回帰直線を追加するには、geom_smooth()を使います。 geom_smooth()の引数には、\n\nmethod = \"lm\": 線形回帰\nse = FALSE: 標準誤差を表示しない\ncolor = \"black\": 線の色を黒にする\n\nを追加しています。\n\ng <- ggplot(lm_sample_data) + aes(x = lagged_BEME, y = annual_Re) # x軸とy軸を指定\ng <- g + geom_point() # 散布図を追加\ng <- g + geom_smooth(method = \"lm\", se = FALSE, color = \"black\") # 回帰直線を追加\ng <- g + xlab(\"t期末時価簿価費率\") + ylab(\"t+1期超過リターン\") + mystyle\nprint(g)\n\n\n\n\n\n# ch05_33: lm()関数を用いた線形回帰\nlm_results <- lm(annual_Re ~ lagged_BEME, data = lm_sample_data) # 従属変数 ~ 独立変数\nnames(lm_results)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\n\nprint(lm_results$coefficients)\n\n(Intercept) lagged_BEME \n 0.05513385  0.07552921 \n\n\nこれが目的変数を超過リターン、説明変数を時価簿価費率とする回帰モデルを最小二乗法で推定した結果である。 termは変数名、estimateが回帰係数、std.errorが標準誤差、statisticがt統計量、p.valueがp値である。 termの1つめの(intercept)は切片で、説明変数がlagged_BEMEです。 ここでの統計的検定の帰無仮説は\\beta = 0、つまりlagged_BEMEのestimateが0である、というものです。\n\n# ch05_35: broomパッケージのtidy()関数で係数の推定値に関する結果を確認\n#install.packages(\"broom\")\nlibrary(broom)\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)   0.0551    0.156      0.354   0.736\n2 lagged_BEME   0.0755    0.0844     0.895   0.405\n\n\nlagged_BEMEの回帰係数0.0755292は有意水準5%で統計的に有意ではなく、傾きがゼロかどうかは分からない、という結果となった。\ngrance()関数を使って、回帰分析の結果をまとめて表示することもできる。\n\nglance(lm_results)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.118       -0.0294 0.223     0.800   0.405     1   1.81  2.37  2.61\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\nr.squaredは決定係数R^2\nadj.r.squaredは自由度調整済み決定係数\\bar{R}^2\nsigmaは標準誤差\nstatisticはF統計量\np.valueはF検定のp値\ndfは自由度\nlogLikは対数尤度\naicは赤池情報量基準(AIC)\nbicはベイズ情報量基準(BIC)\ndevianceは逸脱度\ndf.residualは残差の自由度\nnobsは観測値の数\n\nとなっています。回帰分析の結果でよく利用されるのは、決定係数R^2です。 決定係数の数字が大きければ大きいほど、モデルの説明力が高いことを意味します。 しかし決定係数は検定統計量ではないため、どれだけ高いと良いのかは一概には言えません。\nそこでF統計量を使います。 F統計量は、帰無仮説が「説明変数の係数が全てゼロである」という仮説のもとで計算される統計量です。 この統計量が有意に正であれば、説明変数の少なくとも1つは有意にゼロではないということになり、モデルは有効であると判断できます。 ちなみにこのモデルではF統計量は有意ではなく、モデルが有効かどうかは分かりません。"
  },
  {
    "objectID": "Chap05.html#対数回帰モデル",
    "href": "Chap05.html#対数回帰モデル",
    "title": "5  株式データの取得と可視化",
    "section": "9.2 対数回帰モデル",
    "text": "9.2 対数回帰モデル\n独立変数Xが変化したときの従属変数Yへの影響は一定(つまり傾きが一定)と仮定してきましたが、 実際には傾きが一定でない場合もあります。 回帰式が非線形であることが想定される場合、対処法として\n\n多項式回帰(polynomial regression) ：独立変数にX^2とかX^3を加える\n対数回帰(logarithmic regression) ：独立変数や従属変数の対数をとる\n\nたとえば、独立変数を対数変換した場合は、次のようなモデルになります。\n\nY_i = \\beta_0 + \\beta_1 \\log (X_i) + \\varepsilon_i\n\nこのモデルを対数回帰モデルと呼びます。 Rで分析する場合は、log()関数を使って対数変換を行います。 ついでにlm()の結果をtidy()関数で整形します。\n\n# ch05_37: 線形・対数モデルによる推定\ntidy(lm(annual_Re ~ log(lagged_BEME), data = lm_sample_data)) # 右辺のみlog()関数で自然対数を取る\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic p.value\n  <chr>               <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        0.167     0.0868     1.93    0.102\n2 log(lagged_BEME)   0.0355    0.109      0.326   0.756\n\n\nlog(lagged_BEME)のp.valueの値が0.756となり、有意水準5%で帰無仮説を棄却できませんでした。 つまり、簿価時価比率の対数と株式リターンの間には統計的に関係があるかどうかについて、何も言えない、ということが分かりました。\n間違っても、帰無仮説を棄却できなかったので、簿価時価比率の対数と株式リターンの間には関係がないとは言っていはいけません。注意しましょう。\n\n9.2.1 データの保存\n作成したデータフレームをcsvファイルとして保存するには，write_csv()関数を用います。 前処理が終わった後や新しい変数を作った後に、データを保存しておくと便利です。 6章以降では、以下のデータを継続して使うので、csvファイルとして保存しておきます。\n\n# ch05_38: データの保存\nwrite_csv(monthly_data, \"data/ch05_output1.csv\")\nwrite_csv(annual_data, \"data/ch05_output2.csv\")"
  },
  {
    "objectID": "Chap01.html#企業活動とお金の流れ",
    "href": "Chap01.html#企業活動とお金の流れ",
    "title": "1  会計入門",
    "section": "1.1 企業活動とお金の流れ",
    "text": "1.1 企業活動とお金の流れ"
  },
  {
    "objectID": "Chap01.html#株主目線の価値創造企業",
    "href": "Chap01.html#株主目線の価値創造企業",
    "title": "1  会計入門",
    "section": "1.2 株主目線の価値創造企業",
    "text": "1.2 株主目線の価値創造企業"
  },
  {
    "objectID": "Chap01.html#企業分析の視点",
    "href": "Chap01.html#企業分析の視点",
    "title": "1  会計入門",
    "section": "1.3 企業分析の視点",
    "text": "1.3 企業分析の視点"
  },
  {
    "objectID": "Chap01.html#練習問題",
    "href": "Chap01.html#練習問題",
    "title": "1  会計入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap02.html#練習問題",
    "href": "Chap02.html#練習問題",
    "title": "2  ファイナンス入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap03.html#練習問題",
    "href": "Chap03.html#練習問題",
    "title": "3  R言語入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap04.html#練習問題",
    "href": "Chap04.html#練習問題",
    "title": "4  財務データの取得と可視化",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap05.html#練習問題",
    "href": "Chap05.html#練習問題",
    "title": "5  株式データの取得と可視化",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap04.html",
    "href": "Chap04.html",
    "title": "4  財務データの取得と可視化",
    "section": "",
    "text": "年次開示\n四半期開示\n重要事実\n\n\n\n\n法定開示\n有価証券報告書\n四半期報告書\n臨時報告書\n\n\n適時開示\n決算短信\n四半期決算短信\n適時開示\n\n\n\n\n\n\n\nEDINET：金融庁が運営する電子開示システムで，全上場企業の法定開示資料をデータベースとして提供\nTDnet：東京証券取引所が運営する電子開示システムで，上場企業の決算短信をデータベースとして提供\n\nXBRL(eXtensible Business Reporting Language)形式で財務諸表などの主要情報を公開しています。XBRLからデータを読み込むスキルは本書の枠を超えるため，ここでは練習用データで分析しますが、立命館大学では日経NEEDSを利用して財務データを収集します。"
  },
  {
    "objectID": "Chap03.html#for文の使い方",
    "href": "Chap03.html#for文の使い方",
    "title": "3  R言語入門",
    "section": "3.2 for文の使い方",
    "text": "3.2 for文の使い方\nプログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nの最初の要素である「繰り返し」を行うための文法がfor文です。for文は、ある処理を繰り返し行うための文法です。たとえば、1から10までの整数を順番に表示するには、次のように書きます。\n\nfor (i in 1:10) { # iは1から10まで\n    print(i) # iを表示\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nこの文の構造は、基本的には\n\nfor (好きな変数 in 繰り返す範囲) {\n    繰り返したい処理\n}\n\nとなっています。\nたとえば、教科書のように、\n\n初期投資100万円\n1年後に50万円のキャッシュ・フロー\n2年後に50万円のキャッシュ・フロー\n3年後に50万円のキャッシュ・フロー\n\nという投資プロジェクトの現在価値を計算する場合、愚直に書くと次のようになります。\n\nNPV1 <- -100 +\n    50 / (1 + 0.1)^1 +\n    50 / (1 + 0.1)^2 +\n    50 / (1 + 0.1)^3\nprint(NPV1)\n\n[1] 24.3426\n\n\nこの上のコードの2行目から4行目はほぼ同じ内容なので、数字が変化しているところに注目し、for文を使って書き換えてみます。ここでは^1のところが1ずつ大きくなってます。この部分をiという変数に置き換えてみます。 ついでに、後で変化させることがあるかもしれない部分をすべて変数として定義しておきます。\n\nR <- 0.1 # 無リスク利子率\nNPV <- -100 # 初期投資\nCF <- 50 # キャッシュ・フロー\n\nfor (i in 1:3) { # iは1から3まで\n    NPV <- NPV + CF / (1 + R)^i # 現在価値の計算\n}\nprint(NPV)\n\n[1] 24.3426\n\n\n愚直に計算した場合の同じ結果となりました。 これを10年間の現在価値を計算する場合だとすると、\n\nR <- 0.1 # 無リスク利子率\nNPV <- -100 # 初期投資\nNPV1 <- NPV +\n    50 / (1 + R)^1 +\n    50 / (1 + R)^2 +\n    50 / (1 + R)^3 +\n    50 / (1 + R)^4 +\n    50 / (1 + R)^5 +\n    50 / (1 + R)^6 +\n    50 / (1 + R)^7 +\n    50 / (1 + R)^8 +\n    50 / (1 + R)^9 +\n    50 / (1 + R)^10\nprint(NPV1)\n\n[1] 207.2284\n\n\nと面倒くさいことこの上ないですが、for文を使えば、\n\nR <- 0.1 # 無リスク利子率\nNPV <- -100 # 初期投資\nfor (i in 1:10) { # iは1から10まで\n    NPV <- NPV + 50 / (1 + R)^i\n}\nprint(NPV)\n\n[1] 207.2284\n\n\nと短く書くことができます。使いこなせるように練習しておきましょう。\n次のように、print()関数の位置を変えた場合、どうなるか考えてみてください。\n\nR <- 0.1 # 無リスク利子率\nNPV <- -100 # 初期投資\nfor (i in 1:3) { # iは1から10まで\n    print(NPV)\n    NPV <- NPV + 50 / (1 + R)^i\n}\n\n[1] -100\n[1] -54.54545\n[1] -13.22314\n\nprint(NPV)\n\n[1] 24.3426\n\n\nこの場合、最初にNPVの中を表示し、次に1期目の現在価値を計算し、またその結果を表示し、2期目の現在価値を計算し・・・という順番で繰り返しが行われるので、計算の途中経過が表示されることになります。"
  },
  {
    "objectID": "Chap03.html#if文",
    "href": "Chap03.html#if文",
    "title": "3  R言語入門",
    "section": "3.3 if文",
    "text": "3.3 if文\n次に、プログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nのうち分岐を行うための文法がif文です。if文は、ある条件を満たす場合にのみ処理を行うための文法です。たとえば、ある変数xが0より大きい場合にのみ、その変数を表示するには、次のように書きます。\n\nx <- -1\nif (x > 0) { # xが0より大きい場合\n    print(x) # xを表示\n}\n\nこの文の構造は、基本的には\n\nif (条件) {\n    条件を満たす場合に実行する処理\n}\n\nのようになっています。 このif文を使って、NPVが0より大きい場合にのみ、「プロジェクトを実行！」と表示されるようにしてみます。\n\nR <- 0.1 # 無リスク利子率\nNPV <- -100 # 初期投資\nfor (i in 1:10) { # iは1から10まで\n    NPV <- NPV + 50 / (1 + R)^i\n}\nif (NPV > 0) { # NPVが0より大きい場合\n    print(\"プロジェクトを実行！\") # 文字列を表示\n}\n\n[1] \"プロジェクトを実行！\"\n\n\nここではNPVの値が207.2284となりプラスになっているので、「プロジェクトを実行！」と表示されます。\n\n3.3.1 NPVと割引率の関係の可視化\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値NPVの値を計算してみます。\n\nR <- seq(0.1, 0.2, 0.01) # 無リスク利子率\nN <- length(R) # 無リスク利子率の要素数 11個\nNPV <- rep(NA, N) # ベクトル変数にN個のNAを代入\n\nfor (i in 1:N) { # iは1からNまで\n    NPV[i] <- -100 # 初期投資\n    for (j in 1:3) { # jは1から3まで\n        NPV[i] <- NPV[i] + 50 / (1 + R[i])^j # 現在価値\n    }\n}\nprint(NPV) # 11個の現在価値を表示\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n少し複雑な構造しているので、順番に説明します。\n\n1行目は、無リスク利子率のベクトル変数Rを定義しています。ここでは、0.1から0.2まで0.01刻みのデータを作成しています。\n2行目は、ベクトル変数Rの要素数をNとして定義しています。ここでは、Nは11となります。\n3行目は、ベクトル変数NPVにN個のNAを代入しています。NAはNot Availableの略で、欠損値を表します。NAを代入することで、空っぽの箱が11個入ったベクトル変数NPVを用意します。\n4行目から9行目は、for文を使って、NPVの中身を計算しています。 forが2回出てきているので、二重に繰り返しの処理を行っています。これをネストと呼びます。 1つのめforはiが1からN(ここでは11)まで変化し、2つめのforはjが1から3まで変化します。1つめのfor文のiが1のとき、次のfor文のjが1から3までの処理を繰り返し、次に1つめのfor文のiが2のとき、次のfor文のjが1から3までの処理を繰り返し・・・という順番で処理が行われます。\n10行目は、NPVの中身を表示しています。\n\n\nTABキーを使って、インデントを行い、ソースコードのまとまりをわかりやすくしています。インデントは、プログラムの構造をわかりやすくするために行います。インデントを行うときは、半角スペース2つか4つを使います。どちらを使っても構いませんが、どちらかに統一することが大切です。\n\nこの結果をグラフにしてみます。\n\npar(family = \"HiraKakuProN-W3\") # 日本語フォントの設定\nplot(\n    x = R, # x軸のデータ\n    y = NPV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"図：無リスク利子率と現在価値\", # グラフのタイトル\n    type = \"l\" # 線グラフ\n)\n\n\n\n\n\n\nベクトル化\n上のコードは、for文を使って、NPVの中身を計算しています。しかし、R言語では、for文を使わずに、ベクトルを使って、同じことを行うことができます。このように、for文を使わずに、ベクトルを使って処理を行うことをベクトル化と呼びます。ベクトル化を行うと、処理が高速化されることがあります。\n\nR <- 0.1 # 無リスク利子率 10%\nCF <- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nyear <- 0:3 # 年度のベクトル\nPV_CF <- CF / (1 + R)^year # 各期の現在価値を計算\nNPV <- sum(PV_CF) # 現在価値の合計\nprint(NPV)\n\n[1] 24.3426"
  },
  {
    "objectID": "Chap03.html#独自関数の定義の仕方",
    "href": "Chap03.html#独自関数の定義の仕方",
    "title": "3  R言語入門",
    "section": "3.4 独自関数の定義の仕方",
    "text": "3.4 独自関数の定義の仕方\nプログラミングの基本要素である\n\n繰り返し\n分岐\n関数\n\nの作り方について説明します。 Rでは自分で関数を定義することができます。関数を定義することで、同じ処理を何度も書く必要がなくなり、プログラムの見通しがよくなります。 例えば、足し算をする関数my_add()を定義してみます。\n\nmy_add <- function(x, y){\n    x + y\n}\n\nこの関数の構造は、\n\n好きな関数名 <- function(引数1, 引数2){\n    処理内容\n}\n\nとなっています。つまり、この独自関数my_add()は、xとyという2つの引数(ひきすう)を足し合わせる関数です。数学的に書くなら、\n\nf(x, y) = x + y\n\nとなります。これはfという関数は2つの引数を足す関数であるという意味になっています。 作成した独自関数my_add()を使ってみます。\n\nmy_add(1, 2)\n\n[1] 3\n\n\n3が出力されました。\nこのように、独自関数を作成する場合には、\n\nどのような引数を与えるのか？\nそれに対してどのような処理を行うのか？\n最終的にどの値を返す(出力させる)のか？\n\nを考えておく必要があります。\nでは今までの流れで、現在価値を計算する関数を作成してみます。変化させたい値は、キャッシュフローCFと無リスク利子率Rなので、その2つを引数とする独自関数を作成します。 少し注意する必要がある点として、以下の計算例ではCFの1番目の要素は初期投資額となることに注意しましょう。\n\ncalc_PV <- function(CF, R) {\n    PV <- CF[1] # 初期投資額なのでマイナスの値\n    for (i in 2:length(CF)) { # iは2からCFの要素数まで\n        PV <- PV + CF[i] / (1 + R)^(i - 1) # 現在価値\n    }\n    return(PV) # 現在価値を返す\n}\n\nこの関数calc_PV()を使って、現在価値を計算してみます。\n\ncalc_PV(c(-100, 50, 50, 50), 0.1)\n\n[1] 24.3426\n\n\nちゃんと計算されました。この関数を使って、無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値を計算してみます。\n\nCF <- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nR <- seq(0.1, 0.2, 0.01) # 無リスク利子率のベクトル\ncalc_PV(CF,R)\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n計算されました。 関数の引数にデフォルトで値を設定することで、入力を楽にすることができます。例えば、無リスク利子率のデフォルト値を0.1に設定してみます。\n\ncalc_PV <- function(CF, R = 0.1) {\n    PV <- CF[1] # 初期投資額なのでマイナスの値\n    for (i in 2:length(CF)) { # iは2からCFの要素数まで\n        PV <- PV + CF[i] / (1 + R)^(i - 1) # 現在価値\n    }\n    return(PV) # 現在価値を返す\n}\n\nすると、無リスク利子率を指定しなくても、デフォルト値が使われるようになります。\n\nCF <- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\ncalc_PV(CF)\n\n[1] 24.3426\n\n\nただ計算を間違えるもとにもなるので、なるべく省略せずに、しっかり書くことが大事です。\n\n3.4.0.1 もっと凝った独自関数\n繰り返し、分岐、関数というプログラミングの基本要素を勉強したので、もう少し複雑なプログラムを作成してみます。\nまずは、引数に正の数字以外のもの、あるいは文字列を入力した場合にエラーを表示する関数を作成します。\n\ncalc_PV_new <- function(CF, R) {\n    if (R <= 0) {\n        stop(\"無リスク利子率は正の値を入力してください。\") # エラー処理\n    }\n    if ( !is.numeric(CF) ) {\n        stop(\"キャッシュ・フローは数値を入力してください。\")\n    }\n    if ( !is.numeric(R) ) {\n        stop(\"無リスク利子率は数値を入力してください。\")\n    }\n\n    PV <- CF[1]\n    for (i in 2:length(CF)) {\n        PV <- PV + CF[i] / (1 + R)^(i - 1)\n    }\n    return(PV)\n}\n\nできました。ついでに、NPVの計算結果とともに、NPVが0より大きい場合にのみ、「プロジェクトを実行！」と表示する機能も実装してみます。\n\ncalc_PV_new <- function(CF, R = 0.1) {\n    if (R <= 0) {\n        stop(\"無リスク利子率は正の値を入力してください。\") # エラー処理\n    }\n    if ( !is.numeric(CF) ) {\n        stop(\"キャッシュ・フローは数値を入力してください。\")\n    }\n    if ( !is.numeric(R) ) {\n        stop(\"無リスク利子率は数値を入力してください。\")\n    }\n\n    PV <- CF[1]\n    for (i in 2:length(CF)) {\n        PV <- PV + CF[i] / (1 + R)^(i - 1)\n    }\n\n    if (PV >= 0) { # NPVが0より大きい場合\n    paste0(\"NPVが\", round(PV, digits = 2), \"なので、プロジェクトを実行！\") # 文字列を表示\n    } else {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なのでプロジェクト中止！\") # 文字列を表示\n    }\n}\n\nいろいろ駆使してより短く簡単に書くなら、\n\ncalc_PV <- function(CF, R = 0.1) {\n  if (!is.numeric(CF) || !is.numeric(R) || R <= 0) {\n    stop(\"キャッシュ・フローと無リスク利子率は数値を入力し、無リスク利子率は正の値を入力してください。\")\n  }\n  PV <- sum(sapply(1:length(CF), function(i) CF[i] / (1 + R)^(i - 1)))\n\n  if (PV >= 0) {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なので、プロジェクトを実行！\")\n  } else {\n    paste0(\"NPVが\", round(PV, digits = 2), \"なのでプロジェクト中止！\")\n  }\n}\n\n\nCF <- c(-100, 50, 50, 50)\ncalc_PV(CF)\n\n[1] \"NPVが24.34なので、プロジェクトを実行！\"\n\n\nうまくいきました。 ちょっとキャッシュフローのベクトルを変化させて、初期投資を-200にすると、\n\nCF <- c(-200, 50, 50, 50)\ncalc_PV(CF)\n\n[1] \"NPVが-75.66なのでプロジェクト中止！\"\n\n\nちゃんと中止のメッセージが出ました。\nこのように、分岐、繰り返し、関数を駆使して、様々なプログラムを作成することができます。プログラミングの基本要素を使いこなせるように、練習を重ねてください。まずは教科書に書いてあるソースコードを自分のPC上で実行してみてください。その際は、コピペせずに自分で入力するようにしてください。\n\n\n3.4.0.2 付録：ベクトル化で早くなるのか？\nどれほど高速化されるのかを確認するため、100万年分の現在価値を計算してみます。 最初に松浦のR環境を確認してみます。 Mac miniで、CPUはM1、メモリは8GBです。\n\nR.version # PCの環境\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          2.2                         \nyear           2022                        \nmonth          10                          \nday            31                          \nsvn rev        83211                       \nlanguage       R                           \nversion.string R version 4.2.2 (2022-10-31)\nnickname       Innocent and Trusting       \n\nsessionInfo() # Rの環境\n\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.3.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] ja_JP.UTF-8/ja_JP.UTF-8/ja_JP.UTF-8/C/ja_JP.UTF-8/ja_JP.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2 compiler_4.2.2    fastmap_1.1.1     cli_3.6.1        \n [5] tools_4.2.2       htmltools_0.5.5   rmarkdown_2.21    knitr_1.42       \n [9] xfun_0.39         digest_0.6.31     jsonlite_1.8.4    rlang_1.1.0      \n[13] evaluate_0.20    \n\n\nまずは、for文を使って計算してみます。 forで現在価値を計算する関数を作成します。 この関数では、繰り返し毎期の現在価値を計算し、それを足し合わせていく、という処理を繰り返し行っています。\n\ncalc_PV_for <- function(CF, R = 0.1) {\n    PV <- CF[1] # 初期投資額なのでマイナスの値\n    for (i in 2:length(CF)) { # iは2からCFの要素数まで\n        PV <- PV + CF[i] / (1 + R)^(i - 1) # 現在価値\n    }\n    return(PV) # 現在価値を返す\n}\n\nプログラムの実行時間を計算するため、system.time()関数を使います。\n\nCF <- c(-100, rep(50, 10^6))\n(res_for <- system.time(calc_PV_for(CF)))\n\n   ユーザ   システム       経過  \n     0.035      0.000      0.035 \n\n\n0.035 秒かかりました。 次に、ベクトル化した計算結果を見てみましょう。\n\ncalc_PV_vec <- function(CF, R = 0.1){\n    year <- 0:(length(CF) - 1) # 年度のベクトル\n    PV_CF <- CF / (1 + R)^year # 各期の現在価値を計算\n    NPV <- sum(PV_CF) # 現在価値の合計\n    return(NPV)\n}\n\nベクトルから直接現在価値を計算する関数を用いた計算速度を測ってみます。\n\nCF <- c(-100, rep(50, 10^6))\n(res_vec <- system.time(calc_PV_vec(CF)))\n\n   ユーザ   システム       経過  \n     0.009      0.000      0.009 \n\n\n0.009 秒と、for文を使った場合に比べて、約 3.89 倍高速化されました。これがベクトル化による実行速度の効率化です。 とはいえ、演算に時間がかかるような大規模データや複雑なシミュレーションをするようになるまで、ベクトル化の恩恵はそれほど大きくないので、まずは読みやすく、確実に動くプログラムを書くことを心がけましょう。"
  },
  {
    "objectID": "Chap01.html",
    "href": "Chap01.html",
    "title": "1  会計入門",
    "section": "",
    "text": "第1章会計入門では、\nを学習します。 学習目標として、"
  },
  {
    "objectID": "Chap06.html",
    "href": "Chap06.html",
    "title": "6  ファクターモデルの導入",
    "section": "",
    "text": "CAPMの実証的検証に必要な市場ポートフォリオの構築\nある特徴に基づいて各銘柄をランキングにし，ランキングに応じたポートフォリオの構築\n\n\n\n市場ポートフォリオ (market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいいます。 厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれますが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多いです。\nここでは，データとして入手可能な全銘柄の時価総額と個別銘柄の時価総額の比率をウェイトとして市場ポートフォリオを構築します。\n毎年1月に年次リバランスを想定し，前年度末の時価総額に比例した保有費率の計算をします。\n\n\n\nlibrary(tidyverse) # いつものやつ\nlibrary(broom) # データフレームを整形するパッケージ\nlibrary(ggthemes)\n\nmystyle <- list (#  ggplotのテーマ\n  theme_calc(), # ggthemesパッケージ\n  scale_colour_calc(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n第6章で使うデータを読み込みます。 第5章で作成し，保存したcsvファイルを読み込みます。\n\n# ファイルの読み込み\nmonthly_data <- read_csv(\"data/ch05_output1.csv\") # 第5章の最後で保存した\nannual_data <- read_csv(\"data/ch05_output2.csv\") # 第5章の最後で保存した\n\nここでもデータの構造を確認しておきます。 monthly_dataは月次の株価の終値，一株当り配当額，発行済株式数，調整係数，無リスク利子率，時価総額といった株式データが収録されています。 annual_dataは年次の売上高や当期純利益など財務データが収録されています。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 24\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nglimpse(annual_data)\n\nRows: 7,920\nColumns: 18\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ year        <dbl> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ annual_R    <dbl> NA, 0.99727265, 0.68786382, -0.21361287, 0.64683576, -0.28…\n$ annual_R_F  <dbl> 7.432089e-03, 5.649890e-04, 4.884804e-05, 5.786109e-03, -7…\n$ annual_Re   <dbl> NA, 0.99670766, 0.68781497, -0.21939898, 0.64760569, -0.28…\n$ industry_ID <dbl> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ sales       <dbl> NA, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505.75, …\n$ OX          <dbl> NA, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.25, …\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> NA, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.37, …\n$ OA          <dbl> NA, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86, 2977…\n$ FA          <dbl> NA, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 2258.33,…\n$ OL          <dbl> NA, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840.35, …\n$ FO          <dbl> NA, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2340.8…\n$ BE          <dbl> NA, 10013.82, 10426.33, 10842.01, 11074.95, 11593.58, 1054…\n$ lagged_BE   <dbl> NA, NA, 10013.82, 10426.33, 10842.01, 11074.95, NA, 1054.9…\n$ ROE         <dbl> NA, NA, 0.06607269, 0.06376165, 0.06091859, 0.07619267, NA…\n$ ME          <dbl> 3577.294, 6883.324, 11376.990, 8694.752, 13957.518, 9708.9…\n\n\n市場ポートフォリオの構築に用いるウェイトwは次のように計算します。 ME_{i,t}はt期末における銘柄iの時価総額を表します。 分母は，N個ある全銘柄の時価総額を合計しています。\n\nw_{i,t}^M = \\frac{ME_{i,t-1}^{12\\text{月}}}{\\sum_{j = 1}^N ME_{j,t-1}^{12\\text{月}}}\n\n\n\n\n図6.1 市場ポートフォリオを作成する際の各銘柄の保有比率\n\n\nこの銘柄ごとの保有費率を計算するために，前年度末の時価総額を計算し，lagged_MEに代入します。 annual_dataは2015年から2020年のデータが入っています。 lag()で前期末の時価総額をlagged_MEに代入しようとしても2015年の前年のデータは存在しないので，欠損値になることに注意しましょう。\n\nannual_data <- annual_data %>%\n    group_by(firm_ID) %>% # 企業ごとに\n    mutate(lagged_ME = lag(ME)) %>% # 前期末時価総額\n    ungroup() # グループ化解除\n\nこの処理の結果がおおよそこんな感じになっているはずです。\n\n\n\nfirm_ID\nyear\nME\nlagged_ME\n\n\n\n\n1\n2015\n3577.294\nNA\n\n\n1\n2016\n6883.324\n3577.294\n\n\n1\n2017\n11376.990\n6883.324\n\n\n\nこのlagged_MEを使って保有費率を計算します。 年度ごとに時価総額を合計し、ある企業の前期末時価総額を合計時価総額で割ることで保有費率w_Mを計算します。\n\nannual_data <- annual_data %>%\n    group_by(year) %>% # 年度ごとに\n    mutate(\n        w_M = lagged_ME / sum(lagged_ME, na.rm = TRUE) # ウェイト\n        ) %>%\n    ungroup()\n\n2015年のlagged_MEは欠損値なので，w_Mも欠損値になっていますが，2015年のデータはもう使わないので無視します。\n次に，2016年以降の欠損値の行は，削除するのではなく保有費率w_Mをゼロに置き換えることで投資しないことを表します。 mutate()とreplace()を用いて変数の置き換えをします。\n\nannual_data <- annual_data %>%\n    mutate( # w_Mの欠損値を0に置き換える\n        w_M = replace(w_M, year >= 2016 & is.na(w_M), 0)\n    )\n\nreplace()関数は，第1引数のデータに対して，第2引数の条件を満たす要素を，第3引数の値に置き換えます。 ここでは，w_Mに対して，yearが2016以上で，かつw_Mが欠損値の場合のw_Mを0に置き換えています。\n作成した保有費率を表すウェイトw_Mの合計が1になっているかどうかを確認します。\n\nannual_data %>%\n    group_by(year) %>%\n    summarise(\n        weight_sum = sum(w_M)\n    )\n\n# A tibble: 6 × 2\n   year weight_sum\n  <dbl>      <dbl>\n1  2015      NA   \n2  2016       1.00\n3  2017       1.00\n4  2018       1   \n5  2019       1   \n6  2020       1.00\n\n\n確認できました。 これまでの操作で変数を追加したannual_dataにmonthly_dataに結合します。 完全外部結合(full outer join)を行います。 完全外部結合とは，データベースを連結する操作の1つで、2つのデータフレームからそれぞれ特定のキーとなる列を指定して，キーの値が一致する行同士は連結し、一致しない残りの行もそのまますべて抽出するものです。\n\n\n\n\n\n\n内部結合と外部結合\n\n\n\n内部結合(inner join)とは，最も単純なタイプの結合で，キーとなる変数が等しいときに観測値のペアを対応付ける操作をいいます。 内部結合の最も重要な特性は、キーが一致しない行は結果に含まれないということです。 つまり、一般的に内部結合は多くのデータが落ちるため，あまり分析に使用しません。\n内部結合は両方のデータベースに存在する観測値のみを保持しますが，外部結合は、少なくとも1つのテーブルに存在する観測値を保持します。 外部結合には以下の3つがあります。\n\n左結合(left join)は、xのすべてのオブザベーションを保持します。\n右結合(right join)は、yのすべてのオブザベーションを保持します。\n完全結合(full join)は、xとyのすべてのオブザベーションを保持します。\n\n\n\n\n外部結合の例\n\n\n最もよく使われる結合は左結合です。 他のテーブルから追加データを調べるときはいつもこれを使います。 左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。\n外部結合をベン図で表すとこうなります。\n\n\n\n外部結合のベン図\n\n\n\n\nではfull_join()関数を使って，annual_dataとmonthly_dataをyearとfirm_IDの2つのキーで結合し，その結果をmonthly_dataに代入します。\n\nmonthly_data <- annual_data %>%\n  select(year, firm_ID, w_M) %>% # 必要な変数のみ\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # 完全外部結合\n  select(-w_M, w_M) # w_Mを最終列に移動\n\nできあがった拡大データセットmonthly_dataを確認します。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 25\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ w_M         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.233661e-…\n\n\n準備が整ったので，市場ポートフォリオの月次リターンを計算します。 t時点における市場ポートフォリオのリターンR_{M,t}は、個別銘柄のリターンR_{i,t}とウェイトw_{i,t}^Mの積の合計で表されます。\n\nR_{M,t} = \\sum_{i=1}^{N} w_{i,t}^M R_{i,t}\n\nこれをRで実装します。 monthly_dataをmonth_IDでグループ化し，summarise()関数を用いて，R_Mを計算し，その後でmutate()関数を用いて，R_Meを計算し，その結果をfactor_dataに代入します。\n\nfactor_data <- monthly_data %>%\n  filter(month_ID >= 13) %>% # 2016以降のデータを抽出\n  group_by(month_ID) %>% # 月次データを月ごとに\n  summarise(\n    R_F = R_F[1], # 無リスク金利を抽出\n    R_M = sum(w_M * R, na.rm = TRUE) # 月次リターンの加重平均\n  ) %>%\n  mutate(R_Me = R_M - R_F) # 月次超過リターン変数を作成\n\nfactor_dataの中身をsummary()で確認します。\n\nsummary(factor_data)\n\n    month_ID          R_F                  R_M                 R_Me          \n Min.   :13.00   Min.   :-2.329e-04   Min.   :-0.102438   Min.   :-0.102438  \n 1st Qu.:27.75   1st Qu.:-4.107e-05   1st Qu.:-0.011056   1st Qu.:-0.010890  \n Median :42.50   Median : 3.870e-05   Median : 0.006081   Median : 0.006186  \n Mean   :42.50   Mean   : 9.991e-05   Mean   : 0.004100   Mean   : 0.004000  \n 3rd Qu.:57.25   3rd Qu.: 1.323e-04   3rd Qu.: 0.031698   3rd Qu.: 0.031649  \n Max.   :72.00   Max.   : 6.326e-04   Max.   : 0.111043   Max.   : 0.110819  \n\n\n作成した市場ポートフォリオの超過リターンをヒストグラムにして分布を確認します。\n\n# 市場ポートフォリオの月次超過リターンをヒストグラムで可視化\nggplot(factor_data) + aes(x = R_Me) + geom_histogram() +\n  labs(x = \"市場ポートフォリオの月次超過リターン\", y = \"度数\") + mystyle\n\n\n\n\n次に、市場ポートフォリオの累積リターンを計算します。 計算の仮定は以下の通りです。\n\nmonth_IDが13の月初から運用スタートし、バイアンドホールドで運用すると仮定する。\n毎年1月にコストなしでリバランスし、リバランス前後で元本の変動はないと仮定する。\n\n市場ポートフォリオの累積グロス・リターンを計算します。\n\ndf_g <- factor_data %>%\n  mutate(\n    gross_R_M = 1 + R_M, # rに1足してグラスリターン\n    cumulative_gross_R_M = cumprod(gross_R_M) # 累積グロスリターン\n    )\n\n作成した累積グロス・リターンを折れ線グラフで可視化します。\n\ng <- ggplot(df_g) + aes(x = month_ID, y = cumulative_gross_R_M) + geom_line()\ng <- g + labs(x = \"Month ID\", y = \"累積グロスリターン\") + mystyle\nprint(g)\n\n\n\n\n累積リターンであることが一発で分かるように、始点を1として、折れ線グラフを描き直します。 rbind()で始点となるデータを追加し、geom_hline()で始点の水準を点線で図示します。\n\n# ch06_10: 市場ポートフォリオの累積リターンの可視化 (2)\ndf_g <- factor_data %>%\n  mutate(gross_R_M = 1 + R_M,\n         cumulative_gross_R_M = cumprod(gross_R_M)) %>%\n  select(month_ID, cumulative_gross_R_M) %>%\n  rbind(c(12, 1), .) # 折れ線グラフの始点を追加\n# 折れ線グラフを作成\ng <- ggplot(df_g) +\n  geom_line(aes(x = month_ID, y = cumulative_gross_R_M)) +\n  geom_hline(yintercept = 1, linetype = \"dotted\", color = \"red\") + # 元本の水準を点線で図示\n  labs(x = \"Month ID\", y = \"Cumulative Gross Return\") +\n  scale_x_continuous(expand = c(0, 0)) + ylim(0.5,1.5) +  mystyle\nprint(g)\n\n\n\n\n\n\n\n\nある特性に基づいて株式銘柄をランキングにし、そのランキングに基づいてポートフォリオを構築することをポートフォリオ・ソートと呼びます。 ポートフォリオ・ソートは、ファクター・モデルの検証において重要な手法です。 ここでは前年度末の時価総額に基づいて、企業を10個のグループに分類して、実現リターンの比較をしてみましょう。\n\n\n\n図6.2 前年度末の時価総額に基づくポートフォリオ・ソート\n\n\nRで時価総額ランキングを作成するには、ntile()関数を用います。 ntile()関数は、データを指定した数のグループに分類します。 以下のコードでは、mutate()関数でME_rank10を新たに作成しています。 ME_rank10は、lagged_ME変数をntile()関数で10個に分類し、as.factor()関数で因子型に変換したものです。\n\n# ch06_11: 前年度末の時価総額に基づくポートフォリオ・ソート (1)\nannual_data <- annual_data %>%\n  group_by(year) %>% # 年度ごとに\n  mutate(\n    ME_rank10 = as.factor(ntile(lagged_ME, 10))\n    ) %>% # ntile()関数を用いて十個のグループに分類\n  ungroup() # グループ化解除\nhead(annual_data)\n\n# A tibble: 6 × 21\n  firm_ID  year annual_R annual_R_F annual_Re industry_ID sales    OX   NFE\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>       <dbl> <dbl> <dbl> <dbl>\n1       1  2015   NA      0.00743      NA              NA   NA    NA   NA  \n2       1  2016    0.997  0.000565      0.997           1 5949.  564.  50.7\n3       1  2017    0.688  0.0000488     0.688           1 6505.  691.  29.5\n4       1  2018   -0.214  0.00579      -0.219           1 6846.  751.  86.5\n5       1  2019    0.647 -0.000770      0.648           1 7572.  959. 298. \n6       1  2020   -0.284  0.000380     -0.285           1 7538.  778. -65.5\n# ℹ 12 more variables: X <dbl>, OA <dbl>, FA <dbl>, OL <dbl>, FO <dbl>,\n#   BE <dbl>, lagged_BE <dbl>, ROE <dbl>, ME <dbl>, lagged_ME <dbl>, w_M <dbl>,\n#   ME_rank10 <fct>\n\n\nME_rank10の値と、年・ランキングごとの会社数を確認してみましょう。\n\nsummary(annual_data$ME_rank10)\n\n   1    2    3    4    5    6    7    8    9   10 NA's \n 643  642  641  641  640  640  640  640  639  639 1515 \n\ntable(annual_data$year,  annual_data$ME_rank10)\n\n      \n         1   2   3   4   5   6   7   8   9  10\n  2015   0   0   0   0   0   0   0   0   0   0\n  2016 125 124 124 124 124 124 124 124 124 124\n  2017 127 127 127 127 127 127 127 127 127 127\n  2018 127 127 127 127 127 127 127 127 126 126\n  2019 131 131 131 131 130 130 130 130 130 130\n  2020 133 133 132 132 132 132 132 132 132 132\n\n\nここでは、ME_rank10の値が10の企業が時価総額ランキングの上位10%に、1の企業が時価総額ランキングの下位10%に属することを意味します。\n前回と同様に、full_join()関数でmonthly_dataとannual_dataを結合します。 drop_na()関数で欠損行を削除し、group_by()関数でmonth_IDとME_rank10に関してグループ化した上で、summarize()関数で月次超過リターンReの平均値を計算して、Re変数としています。\n\n# ch06_13: 前年度末の時価総額に基づくポートフォリオ・ソート (2)\n\nME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, ME_rank10) %>% # 年次データから追加したい情報を抽出\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # yearとfirm_IDをキーに月次データと結合\n  drop_na() %>% # 欠損行を削除\n  group_by(month_ID, ME_rank10) %>% # month_IDとME_rank10に関してグループ化\n  summarize(Re = mean(Re)) %>% # 各グループで月次超過リターンの平均値を計算\n  ungroup()\nME_sorted_portfolio\n\n# A tibble: 600 × 3\n   month_ID ME_rank10     Re\n      <dbl> <fct>      <dbl>\n 1       13 1         0.0291\n 2       13 2         0.0272\n 3       13 3         0.0353\n 4       13 4         0.0545\n 5       13 5         0.0460\n 6       13 6         0.0438\n 7       13 7         0.0530\n 8       13 8         0.0398\n 9       13 9         0.0536\n10       13 10        0.0478\n# ℹ 590 more rows\n\n\n準備が出来たので、各ポートフォリオの平均超過リターンを可視化してみましょう。 これにより、時価総額の大きい企業のポートフォリオが、時価総額の小さい企業のポートフォリオよりも高い、あるいは低いリターンを上げているかどうかを確認することができます。\n\n# ch06_14: 各ポートフォリオの平均超過リターンを可視化\nME_cross_sectional_return <- ME_sorted_portfolio %>%\n  group_by(ME_rank10) %>% # ME_rank10に関してグループ化\n  summarize(mean_Re = mean(Re)) # 月次超過リターンの平均値を計算\n\ng <- ggplot(ME_cross_sectional_return) + aes(x = ME_rank10, y = mean_Re)\ng <- g + geom_col() # 棒グラフ\ng <- g + xlab(\"時価総額ランク\") + ylab(\"平均月次超過リターン\")\ng <- g + scale_y_continuous(expand = c(0, 0)) + ylim(0,0.02) + mystyle\nprint(g)\n\n\n\n\n小型株ほど月次超過リターンの平均が高いことが分かりました。 このように、時価総額の大きい企業のポートフォリオと小さい企業のポートフォリオのリターンの差をサイズ・プレミアムと呼びます。\n先ほどは各ポートフォリオの区分を同じウェイトで保有した場合のリターンを計算しましたが，コラムでは，時価総額の大きさに応じてウェイトを変えた時価総額加重ポートフォリオを作成して，先ほどの結果を再現してみる。\nまずは等加重の場合のコードを確認する。\n\n# ch06_15a: 簿価時価比率に基づくポートフォリオ・ソート（等加重の場合）\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>% # 簿価時価比率に基づいて十個のグループに分類\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  summarize(Re = mean(Re)) %>% # 月次超過リターンの平均値を計算\n  ungroup()\n# 作図\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) + # y = 0の直線を追加\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n次に時価総額加重の場合のコードを確認します。\n\n# ch06_15b: 簿価時価比率に基づくポートフォリオ・ソート（時価総額加重の場合）\n# 中盤で保有比率wと月次超過リターンReを計算している箇所を除けば,ch06_15aと全く同じ\n\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>%\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  mutate(w = lagged_ME / sum(lagged_ME)) %>% # 各ポートフォリオで保有比率を計算\n  summarize(Re = sum(w * Re)) %>% # 時価総額加重の月次超過リターンを計算\n  ungroup()\n\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n結果が異なっていることに注意しましょう。\n次節では，この現象を，資産価格モデルの1つであるCAPM(Capital Asset Pricing Model)が説明できるかどうかを検証します。"
  },
  {
    "objectID": "Chap06.html#ファクター構築の準備",
    "href": "Chap06.html#ファクター構築の準備",
    "title": "6  ファクターモデルの導入",
    "section": "6.1 ファクター構築の準備",
    "text": "6.1 ファクター構築の準備\n\nCAPMの実証的検証に必要な市場ポートフォリオの構築\nある特徴に基づいて各銘柄をランキングにし，ランキングに応じたポートフォリオの構築\n\n\n6.1.1 市場ポートフォリオの構築\n市場ポートフォリオ (market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいいます。 厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれますが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多いです。\nここでは，データとして入手可能な全銘柄の時価総額と個別銘柄の時価総額の比率をウェイトとして市場ポートフォリオを構築します。\n毎年1月に年次リバランスを想定し，前年度末の時価総額に比例した保有費率の計算をします。\n\nRの事前\n\nlibrary(tidyverse) # いつものやつ\nlibrary(broom) # データフレームを整形するパッケージ\nlibrary(ggthemes)\n\nmystyle <- list (#  ggplotのテーマ\n  theme_calc(), # ggthemesパッケージ\n  scale_colour_calc(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n第6章で使うデータを読み込みます。 第5章で作成し，保存したcsvファイルを読み込みます。\n\n# ファイルの読み込み\nmonthly_data <- read_csv(\"data/ch05_output1.csv\") # 第5章の最後で保存した\nannual_data <- read_csv(\"data/ch05_output2.csv\") # 第5章の最後で保存した\n\nここでもデータの構造を確認しておきます。 monthly_dataは月次の株価の終値，一株当り配当額，発行済株式数，調整係数，無リスク利子率，時価総額といった株式データが収録されています。 annual_dataは年次の売上高や当期純利益など財務データが収録されています。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 24\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nglimpse(annual_data)\n\nRows: 7,920\nColumns: 18\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ year        <dbl> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ annual_R    <dbl> NA, 0.99727265, 0.68786382, -0.21361287, 0.64683576, -0.28…\n$ annual_R_F  <dbl> 7.432089e-03, 5.649890e-04, 4.884804e-05, 5.786109e-03, -7…\n$ annual_Re   <dbl> NA, 0.99670766, 0.68781497, -0.21939898, 0.64760569, -0.28…\n$ industry_ID <dbl> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ sales       <dbl> NA, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505.75, …\n$ OX          <dbl> NA, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.25, …\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> NA, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.37, …\n$ OA          <dbl> NA, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86, 2977…\n$ FA          <dbl> NA, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 2258.33,…\n$ OL          <dbl> NA, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840.35, …\n$ FO          <dbl> NA, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2340.8…\n$ BE          <dbl> NA, 10013.82, 10426.33, 10842.01, 11074.95, 11593.58, 1054…\n$ lagged_BE   <dbl> NA, NA, 10013.82, 10426.33, 10842.01, 11074.95, NA, 1054.9…\n$ ROE         <dbl> NA, NA, 0.06607269, 0.06376165, 0.06091859, 0.07619267, NA…\n$ ME          <dbl> 3577.294, 6883.324, 11376.990, 8694.752, 13957.518, 9708.9…\n\n\n市場ポートフォリオの構築に用いるウェイトwは次のように計算します。 ME_{i,t}はt期末における銘柄iの時価総額を表します。 分母は，N個ある全銘柄の時価総額を合計しています。\n\nw_{i,t}^M = \\frac{ME_{i,t-1}^{12\\text{月}}}{\\sum_{j = 1}^N ME_{j,t-1}^{12\\text{月}}}\n\n\n\n\n図6.1 市場ポートフォリオを作成する際の各銘柄の保有比率\n\n\nこの銘柄ごとの保有費率を計算するために，前年度末の時価総額を計算し，lagged_MEに代入します。 annual_dataは2015年から2020年のデータが入っています。 lag()で前期末の時価総額をlagged_MEに代入しようとしても2015年の前年のデータは存在しないので，欠損値になることに注意しましょう。\n\nannual_data <- annual_data %>%\n    group_by(firm_ID) %>% # 企業ごとに\n    mutate(lagged_ME = lag(ME)) %>% # 前期末時価総額\n    ungroup() # グループ化解除\n\nこの処理の結果がおおよそこんな感じになっているはずです。\n\n\n\nfirm_ID\nyear\nME\nlagged_ME\n\n\n\n\n1\n2015\n3577.294\nNA\n\n\n1\n2016\n6883.324\n3577.294\n\n\n1\n2017\n11376.990\n6883.324\n\n\n\nこのlagged_MEを使って保有費率を計算します。 年度ごとに時価総額を合計し、ある企業の前期末時価総額を合計時価総額で割ることで保有費率w_Mを計算します。\n\nannual_data <- annual_data %>%\n    group_by(year) %>% # 年度ごとに\n    mutate(\n        w_M = lagged_ME / sum(lagged_ME, na.rm = TRUE) # ウェイト\n        ) %>%\n    ungroup()\n\n2015年のlagged_MEは欠損値なので，w_Mも欠損値になっていますが，2015年のデータはもう使わないので無視します。\n次に，2016年以降の欠損値の行は，削除するのではなく保有費率w_Mをゼロに置き換えることで投資しないことを表します。 mutate()とreplace()を用いて変数の置き換えをします。\n\nannual_data <- annual_data %>%\n    mutate( # w_Mの欠損値を0に置き換える\n        w_M = replace(w_M, year >= 2016 & is.na(w_M), 0)\n    )\n\nreplace()関数は，第1引数のデータに対して，第2引数の条件を満たす要素を，第3引数の値に置き換えます。 ここでは，w_Mに対して，yearが2016以上で，かつw_Mが欠損値の場合のw_Mを0に置き換えています。\n作成した保有費率を表すウェイトw_Mの合計が1になっているかどうかを確認します。\n\nannual_data %>%\n    group_by(year) %>%\n    summarise(\n        weight_sum = sum(w_M)\n    )\n\n# A tibble: 6 × 2\n   year weight_sum\n  <dbl>      <dbl>\n1  2015      NA   \n2  2016       1.00\n3  2017       1.00\n4  2018       1   \n5  2019       1   \n6  2020       1.00\n\n\n確認できました。 これまでの操作で変数を追加したannual_dataにmonthly_dataに結合します。 完全外部結合(full outer join)を行います。 完全外部結合とは，データベースを連結する操作の1つで、2つのデータフレームからそれぞれ特定のキーとなる列を指定して，キーの値が一致する行同士は連結し、一致しない残りの行もそのまますべて抽出するものです。\n\n\n\n\n\n\n内部結合と外部結合\n\n\n\n内部結合(inner join)とは，最も単純なタイプの結合で，キーとなる変数が等しいときに観測値のペアを対応付ける操作をいいます。 内部結合の最も重要な特性は、キーが一致しない行は結果に含まれないということです。 つまり、一般的に内部結合は多くのデータが落ちるため，あまり分析に使用しません。\n内部結合は両方のデータベースに存在する観測値のみを保持しますが，外部結合は、少なくとも1つのテーブルに存在する観測値を保持します。 外部結合には以下の3つがあります。\n\n左結合(left join)は、xのすべてのオブザベーションを保持します。\n右結合(right join)は、yのすべてのオブザベーションを保持します。\n完全結合(full join)は、xとyのすべてのオブザベーションを保持します。\n\n\n\n\n外部結合の例\n\n\n最もよく使われる結合は左結合です。 他のテーブルから追加データを調べるときはいつもこれを使います。 左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。\n外部結合をベン図で表すとこうなります。\n\n\n\n外部結合のベン図\n\n\n\n\nではfull_join()関数を使って，annual_dataとmonthly_dataをyearとfirm_IDの2つのキーで結合し，その結果をmonthly_dataに代入します。\n\nmonthly_data <- annual_data %>%\n  select(year, firm_ID, w_M) %>% # 必要な変数のみ\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # 完全外部結合\n  select(-w_M, w_M) # w_Mを最終列に移動\n\nできあがった拡大データセットmonthly_dataを確認します。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 25\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ w_M         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.233661e-…\n\n\n準備が整ったので，市場ポートフォリオの月次リターンを計算します。 t時点における市場ポートフォリオのリターンR_{M,t}は、個別銘柄のリターンR_{i,t}とウェイトw_{i,t}^Mの積の合計で表されます。\n\nR_{M,t} = \\sum_{i=1}^{N} w_{i,t}^M R_{i,t}\n\nこれをRで実装します。 monthly_dataをmonth_IDでグループ化し，summarise()関数を用いて，R_Mを計算し，その後でmutate()関数を用いて，R_Meを計算し，その結果をfactor_dataに代入します。\n\nfactor_data <- monthly_data %>%\n  filter(month_ID >= 13) %>% # 2016以降のデータを抽出\n  group_by(month_ID) %>% # 月次データを月ごとに\n  summarise(\n    R_F = R_F[1], # 無リスク金利を抽出\n    R_M = sum(w_M * R, na.rm = TRUE) # 月次リターンの加重平均\n  ) %>%\n  mutate(R_Me = R_M - R_F) # 月次超過リターン変数を作成\n\nfactor_dataの中身をsummary()で確認します。\n\nsummary(factor_data)\n\n    month_ID          R_F                  R_M                 R_Me          \n Min.   :13.00   Min.   :-2.329e-04   Min.   :-0.102438   Min.   :-0.102438  \n 1st Qu.:27.75   1st Qu.:-4.107e-05   1st Qu.:-0.011056   1st Qu.:-0.010890  \n Median :42.50   Median : 3.870e-05   Median : 0.006081   Median : 0.006186  \n Mean   :42.50   Mean   : 9.991e-05   Mean   : 0.004100   Mean   : 0.004000  \n 3rd Qu.:57.25   3rd Qu.: 1.323e-04   3rd Qu.: 0.031698   3rd Qu.: 0.031649  \n Max.   :72.00   Max.   : 6.326e-04   Max.   : 0.111043   Max.   : 0.110819  \n\n\n作成した市場ポートフォリオの超過リターンをヒストグラムにして分布を確認します。\n\n# 市場ポートフォリオの月次超過リターンをヒストグラムで可視化\nggplot(factor_data) + aes(x = R_Me) + geom_histogram() +\n  labs(x = \"市場ポートフォリオの月次超過リターン\", y = \"度数\") + mystyle\n\n\n\n\n次に、市場ポートフォリオの累積リターンを計算します。 計算の仮定は以下の通りです。\n\nmonth_IDが13の月初から運用スタートし、バイアンドホールドで運用すると仮定する。\n毎年1月にコストなしでリバランスし、リバランス前後で元本の変動はないと仮定する。\n\n市場ポートフォリオの累積グロス・リターンを計算します。\n\ndf_g <- factor_data %>%\n  mutate(\n    gross_R_M = 1 + R_M, # rに1足してグラスリターン\n    cumulative_gross_R_M = cumprod(gross_R_M) # 累積グロスリターン\n    )\n\n作成した累積グロス・リターンを折れ線グラフで可視化します。\n\ng <- ggplot(df_g) + aes(x = month_ID, y = cumulative_gross_R_M) + geom_line()\ng <- g + labs(x = \"Month ID\", y = \"累積グロスリターン\") + mystyle\nprint(g)\n\n\n\n\n累積リターンであることが一発で分かるように、始点を1として、折れ線グラフを描き直します。 rbind()で始点となるデータを追加し、geom_hline()で始点の水準を点線で図示します。\n\n# ch06_10: 市場ポートフォリオの累積リターンの可視化 (2)\ndf_g <- factor_data %>%\n  mutate(gross_R_M = 1 + R_M,\n         cumulative_gross_R_M = cumprod(gross_R_M)) %>%\n  select(month_ID, cumulative_gross_R_M) %>%\n  rbind(c(12, 1), .) # 折れ線グラフの始点を追加\n# 折れ線グラフを作成\ng <- ggplot(df_g) +\n  geom_line(aes(x = month_ID, y = cumulative_gross_R_M)) +\n  geom_hline(yintercept = 1, linetype = \"dotted\", color = \"red\") + # 元本の水準を点線で図示\n  labs(x = \"Month ID\", y = \"Cumulative Gross Return\") +\n  scale_x_continuous(expand = c(0, 0)) + ylim(0.5,1.5) +  mystyle\nprint(g)\n\n\n\n\n\n\n\n6.1.2 ポートフォリオ・ソート\nある特性に基づいて株式銘柄をランキングにし、そのランキングに基づいてポートフォリオを構築することをポートフォリオ・ソートと呼びます。 ポートフォリオ・ソートは、ファクター・モデルの検証において重要な手法です。 ここでは前年度末の時価総額に基づいて、企業を10個のグループに分類して、実現リターンの比較をしてみましょう。\n\n\n\n図6.2 前年度末の時価総額に基づくポートフォリオ・ソート\n\n\nRで時価総額ランキングを作成するには、ntile()関数を用います。 ntile()関数は、データを指定した数のグループに分類します。 以下のコードでは、mutate()関数でME_rank10を新たに作成しています。 ME_rank10は、lagged_ME変数をntile()関数で10個に分類し、as.factor()関数で因子型に変換したものです。\n\n# ch06_11: 前年度末の時価総額に基づくポートフォリオ・ソート (1)\nannual_data <- annual_data %>%\n  group_by(year) %>% # 年度ごとに\n  mutate(\n    ME_rank10 = as.factor(ntile(lagged_ME, 10))\n    ) %>% # ntile()関数を用いて十個のグループに分類\n  ungroup() # グループ化解除\nhead(annual_data)\n\n# A tibble: 6 × 21\n  firm_ID  year annual_R annual_R_F annual_Re industry_ID sales    OX   NFE\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>       <dbl> <dbl> <dbl> <dbl>\n1       1  2015   NA      0.00743      NA              NA   NA    NA   NA  \n2       1  2016    0.997  0.000565      0.997           1 5949.  564.  50.7\n3       1  2017    0.688  0.0000488     0.688           1 6505.  691.  29.5\n4       1  2018   -0.214  0.00579      -0.219           1 6846.  751.  86.5\n5       1  2019    0.647 -0.000770      0.648           1 7572.  959. 298. \n6       1  2020   -0.284  0.000380     -0.285           1 7538.  778. -65.5\n# ℹ 12 more variables: X <dbl>, OA <dbl>, FA <dbl>, OL <dbl>, FO <dbl>,\n#   BE <dbl>, lagged_BE <dbl>, ROE <dbl>, ME <dbl>, lagged_ME <dbl>, w_M <dbl>,\n#   ME_rank10 <fct>\n\n\nME_rank10の値と、年・ランキングごとの会社数を確認してみましょう。\n\nsummary(annual_data$ME_rank10)\n\n   1    2    3    4    5    6    7    8    9   10 NA's \n 643  642  641  641  640  640  640  640  639  639 1515 \n\ntable(annual_data$year,  annual_data$ME_rank10)\n\n      \n         1   2   3   4   5   6   7   8   9  10\n  2015   0   0   0   0   0   0   0   0   0   0\n  2016 125 124 124 124 124 124 124 124 124 124\n  2017 127 127 127 127 127 127 127 127 127 127\n  2018 127 127 127 127 127 127 127 127 126 126\n  2019 131 131 131 131 130 130 130 130 130 130\n  2020 133 133 132 132 132 132 132 132 132 132\n\n\nここでは、ME_rank10の値が10の企業が時価総額ランキングの上位10%に、1の企業が時価総額ランキングの下位10%に属することを意味します。\n前回と同様に、full_join()関数でmonthly_dataとannual_dataを結合します。 drop_na()関数で欠損行を削除し、group_by()関数でmonth_IDとME_rank10に関してグループ化した上で、summarize()関数で月次超過リターンReの平均値を計算して、Re変数としています。\n\n# ch06_13: 前年度末の時価総額に基づくポートフォリオ・ソート (2)\n\nME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, ME_rank10) %>% # 年次データから追加したい情報を抽出\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # yearとfirm_IDをキーに月次データと結合\n  drop_na() %>% # 欠損行を削除\n  group_by(month_ID, ME_rank10) %>% # month_IDとME_rank10に関してグループ化\n  summarize(Re = mean(Re)) %>% # 各グループで月次超過リターンの平均値を計算\n  ungroup()\nME_sorted_portfolio\n\n# A tibble: 600 × 3\n   month_ID ME_rank10     Re\n      <dbl> <fct>      <dbl>\n 1       13 1         0.0291\n 2       13 2         0.0272\n 3       13 3         0.0353\n 4       13 4         0.0545\n 5       13 5         0.0460\n 6       13 6         0.0438\n 7       13 7         0.0530\n 8       13 8         0.0398\n 9       13 9         0.0536\n10       13 10        0.0478\n# ℹ 590 more rows\n\n\n準備が出来たので、各ポートフォリオの平均超過リターンを可視化してみましょう。 これにより、時価総額の大きい企業のポートフォリオが、時価総額の小さい企業のポートフォリオよりも高い、あるいは低いリターンを上げているかどうかを確認することができます。\n\n# ch06_14: 各ポートフォリオの平均超過リターンを可視化\nME_cross_sectional_return <- ME_sorted_portfolio %>%\n  group_by(ME_rank10) %>% # ME_rank10に関してグループ化\n  summarize(mean_Re = mean(Re)) # 月次超過リターンの平均値を計算\n\ng <- ggplot(ME_cross_sectional_return) + aes(x = ME_rank10, y = mean_Re)\ng <- g + geom_col() # 棒グラフ\ng <- g + xlab(\"時価総額ランク\") + ylab(\"平均月次超過リターン\")\ng <- g + scale_y_continuous(expand = c(0, 0)) + ylim(0,0.02) + mystyle\nprint(g)\n\n\n\n\n小型株ほど月次超過リターンの平均が高いことが分かりました。 このように、時価総額の大きい企業のポートフォリオと小さい企業のポートフォリオのリターンの差をサイズ・プレミアムと呼びます。\n先ほどは各ポートフォリオの区分を同じウェイトで保有した場合のリターンを計算しましたが，コラムでは，時価総額の大きさに応じてウェイトを変えた時価総額加重ポートフォリオを作成して，先ほどの結果を再現してみる。\nまずは等加重の場合のコードを確認する。\n\n# ch06_15a: 簿価時価比率に基づくポートフォリオ・ソート（等加重の場合）\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>% # 簿価時価比率に基づいて十個のグループに分類\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  summarize(Re = mean(Re)) %>% # 月次超過リターンの平均値を計算\n  ungroup()\n# 作図\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) + # y = 0の直線を追加\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n次に時価総額加重の場合のコードを確認します。\n\n# ch06_15b: 簿価時価比率に基づくポートフォリオ・ソート（時価総額加重の場合）\n# 中盤で保有比率wと月次超過リターンReを計算している箇所を除けば,ch06_15aと全く同じ\n\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>%\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  mutate(w = lagged_ME / sum(lagged_ME)) %>% # 各ポートフォリオで保有比率を計算\n  summarize(Re = sum(w * Re)) %>% # 時価総額加重の月次超過リターンを計算\n  ungroup()\n\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n結果が異なっていることに注意しましょう。\n次節では，この現象を，資産価格モデルの1つであるCAPM(Capital Asset Pricing Model)が説明できるかどうかを検証します。"
  },
  {
    "objectID": "Chap06.html#市場ポートフォリオの構築",
    "href": "Chap06.html#市場ポートフォリオの構築",
    "title": "6  ファクターモデルの導入",
    "section": "6.2 市場ポートフォリオの構築",
    "text": "6.2 市場ポートフォリオの構築\n市場ポートフォリオ (market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいいます。 厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれますが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多いです。\nここでは，データとして入手可能な全銘柄の時価総額と個別銘柄の時価総額の比率をウェイトとして市場ポートフォリオを構築します。\n毎年1月に年次リバランスを想定し，前年度末の時価総額に比例した保有費率の計算をします。\n\nlibrary(tidyverse) # いつものやつ\nlibrary(broom) # データフレームを整形するパッケージ\nmonthly_data <- read_csv(\"data/ch05_output1.csv\") # 第5章の最後で保存した\nannual_data <- read_csv(\"data/ch05_output2.csv\") # 第5章の最後で保存した\n\nここでもデータの構造を確認しておきます。 monthly_dataは月次の株価の終値，一株当り配当額，発行済株式数，調整係数，無リスク利子率，時価総額といった株式データが収録されています。 annual_dataは年次の売上高や当期純利益など財務データが収録されています。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 24\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nglimpse(annual_data)\n\nRows: 7,920\nColumns: 18\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ year        <dbl> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ annual_R    <dbl> NA, 0.99727265, 0.68786382, -0.21361287, 0.64683576, -0.28…\n$ annual_R_F  <dbl> 7.432089e-03, 5.649890e-04, 4.884804e-05, 5.786109e-03, -7…\n$ annual_Re   <dbl> NA, 0.99670766, 0.68781497, -0.21939898, 0.64760569, -0.28…\n$ industry_ID <dbl> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ sales       <dbl> NA, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505.75, …\n$ OX          <dbl> NA, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.25, …\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> NA, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.37, …\n$ OA          <dbl> NA, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86, 2977…\n$ FA          <dbl> NA, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 2258.33,…\n$ OL          <dbl> NA, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840.35, …\n$ FO          <dbl> NA, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2340.8…\n$ BE          <dbl> NA, 10013.82, 10426.33, 10842.01, 11074.95, 11593.58, 1054…\n$ lagged_BE   <dbl> NA, NA, 10013.82, 10426.33, 10842.01, 11074.95, NA, 1054.9…\n$ ROE         <dbl> NA, NA, 0.06607269, 0.06376165, 0.06091859, 0.07619267, NA…\n$ ME          <dbl> 3577.294, 6883.324, 11376.990, 8694.752, 13957.518, 9708.9…\n\n\n市場ポートフォリオの構築に用いるウェイトwは次のように計算します。 ME_{i,t}はt期末における銘柄iの時価総額を表します。 分母は，N個ある全銘柄の時価総額を合計しています。\n\nw_{i,t}^M = \\frac{ME_{i,t-1}^{12\\text{月}}}{\\sum_{j = 1}^N ME_{j,t-1}^{12\\text{月}}}\n\n\n\n\n図6.1 市場ポートフォリオを作成する際の各銘柄の保有比率\n\n\nこの銘柄ごとの保有費率を計算するために，前年度末の時価総額を計算し，lagged_MEに代入します。 annual_dataは2015年から2020年のデータが入っています。 lag()で前期末の時価総額をlagged_MEに代入しようとしても2015年の前年のデータは存在しないので，欠損値になることに注意しましょう。\n\nannual_data <- annual_data %>%\n    group_by(firm_ID) %>% # 企業ごとに\n    mutate(lagged_ME = lag(ME)) %>% # 前期末時価総額\n    ungroup() # グループ化解除\n\nこの処理の結果がおおよそこんな感じになっているはずです。\n\n\n\nfirm_ID\nyear\nME\nlagged_ME\n\n\n\n\n1\n2015\n3577.294\nNA\n\n\n1\n2016\n6883.324\n3577.294\n\n\n1\n2017\n11376.990\n6883.324\n\n\n\nこのlagged_MEを使って保有費率を計算します。 年度ごとに時価総額を合計し、ある企業の前期末時価総額を合計時価総額で割ることで保有費率w_Mを計算します。\n\nannual_data <- annual_data %>%\n    group_by(year) %>% # 年度ごとに\n    mutate(\n        w_M = lagged_ME / sum(lagged_ME, na.rm = TRUE) # ウェイト\n        ) %>%\n    ungroup()\n\n2015年のlagged_MEは欠損値なので，w_Mも欠損値になっていますが，2015年のデータはもう使わないので無視します。\n次に，2016年以降の欠損値の行は，削除するのではなく保有費率w_Mをゼロに置き換えることで投資しないことを表します。 mutate()とreplace()を用いて変数の置き換えをします。\n\nannual_data <- annual_data %>%\n    mutate( # w_Mの欠損値を0に置き換える\n        w_M = replace(w_M, year >= 2016 & is.na(w_M), 0)\n    )\n\nreplace()関数は，第1引数のデータに対して，第2引数の条件を満たす要素を，第3引数の値に置き換えます。 ここでは，w_Mに対して，yearが2016以上で，かつw_Mが欠損値の場合のw_Mを0に置き換えています。\n作成した保有費率を表すウェイトw_Mの合計が1になっているかどうかを確認します。\n\nannual_data %>%\n    group_by(year) %>%\n    summarise(\n        weight_sum = sum(w_M)\n    )\n\n# A tibble: 6 × 2\n   year weight_sum\n  <dbl>      <dbl>\n1  2015      NA   \n2  2016       1.00\n3  2017       1.00\n4  2018       1   \n5  2019       1   \n6  2020       1.00\n\n\n確認できました。 これまでの操作で変数を追加したannual_dataにmonthly_dataに結合します。 完全外部結合(full outer join)を行います。 完全外部結合とは，データベースを連結する操作の1つで、2つのデータフレームからそれぞれ特定のキーとなる列を指定して，キーの値が一致する行同士は連結し、一致しない残りの行もそのまますべて抽出するものです。\n\n\n\n\n\n\n内部結合と外部結合\n\n\n\n内部結合(inner join)とは，最も単純なタイプの結合で，キーとなる変数が等しいときに観測値のペアを対応付ける操作をいいます。 内部結合の最も重要な特性は、キーが一致しない行は結果に含まれないということです。 つまり、一般的に内部結合は多くのデータが落ちるため，あまり分析に使用しません。\n内部結合は両方のデータベースに存在する観測値のみを保持しますが，外部結合は、少なくとも1つのテーブルに存在する観測値を保持します。 外部結合には以下の3つがあります。\n\n左結合(left join)は、xのすべてのオブザベーションを保持します。\n右結合(right join)は、yのすべてのオブザベーションを保持します。\n完全結合(full join)は、xとyのすべてのオブザベーションを保持します。\n\n\n\n\n外部結合の例\n\n\n最もよく使われる結合は左結合です。 他のテーブルから追加データを調べるときはいつもこれを使います。 左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。\n外部結合をベン図で表すとこうなります。\n\n\n\n外部結合のベン図\n\n\n\n\nではfull_join()関数を使って，annual_dataとmonthly_dataをyearとfirm_IDの2つのキーで結合し，その結果をmonthly_dataに代入します。\n\nmonthly_data <- annual_data %>%\n  select(year, firm_ID, w_M) %>% # 必要な変数のみ\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # 完全外部結合\n  select(-w_M, w_M) # w_Mを最終列に移動\n\nできあがった拡大データセットmonthly_dataを確認します。\n\nglimpse(monthly_data)\n\nRows: 95,040\nColumns: 25\n$ year        <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ month       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, 6, 7…\n$ month_ID    <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ stock_price <dbl> 954, 960, 1113, 1081, 1317, 1366, 1353, 1209, 1291, 1407, …\n$ DPS         <dbl> 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 0, 40, 0…\n$ n_shares    <dbl> 2422000, 2422000, 2422000, 2422000, 2422000, 2422000, 2422…\n$ adj_coef    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ R_F         <dbl> 6.506826e-04, 5.834099e-04, 6.114423e-04, 6.848180e-04, 7.…\n$ ME          <dbl> 2310588000, 2325120000, 2695686000, 2618182000, 3189774000…\n$ R           <dbl> NA, 0.006289308, 0.159375000, -0.028751123, 0.218316374, 0…\n$ Re          <dbl> NA, 0.005705898, 0.158763558, -0.029435941, 0.217579602, 0…\n$ industry_ID <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 1, 1, 1…\n$ sales       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5948.96, 5…\n$ OX          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 564.14, 56…\n$ NFE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 50.66750, …\n$ X           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 513.48, 51…\n$ OA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 13865.58, …\n$ FA          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4642.16, 4…\n$ OL          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4534.22, 4…\n$ FO          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3959.70, 3…\n$ BE          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 10013.82, …\n$ lagged_BE   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ ROE         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ w_M         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2.233661e-…\n\n\n準備が整ったので，市場ポートフォリオの月次リターンを計算します。 t時点における市場ポートフォリオのリターンR_{M,t}は、個別銘柄のリターンR_{i,t}とウェイトw_{i,t}^Mの積の合計で表されます。\n\nR_{M,t} = \\sum_{i=1}^{N} w_{i,t}^M R_{i,t}\n\nこれをRで実装します。 monthly_dataをmonth_IDでグループ化し，summarise()関数を用いて，R_Mを計算し，その後でmutate()関数を用いて，R_Meを計算し，その結果をfactor_dataに代入します。\n\nfactor_data <- monthly_data %>%\n  filter(month_ID >= 13) %>% # 2016以降のデータを抽出\n  group_by(month_ID) %>% # 月次データを月ごとに\n  summarise(\n    R_F = R_F[1], # 無リスク金利を抽出\n    R_M = sum(w_M * R, na.rm = TRUE) # 月次リターンの加重平均\n  ) %>%\n  mutate(R_Me = R_M - R_F) # 月次超過リターン変数を作成\n\nfactor_dataの中身をsummary()で確認します。\n\nsummary(factor_data)\n\n    month_ID          R_F                  R_M                 R_Me          \n Min.   :13.00   Min.   :-2.329e-04   Min.   :-0.102438   Min.   :-0.102438  \n 1st Qu.:27.75   1st Qu.:-4.107e-05   1st Qu.:-0.011056   1st Qu.:-0.010890  \n Median :42.50   Median : 3.870e-05   Median : 0.006081   Median : 0.006186  \n Mean   :42.50   Mean   : 9.991e-05   Mean   : 0.004100   Mean   : 0.004000  \n 3rd Qu.:57.25   3rd Qu.: 1.323e-04   3rd Qu.: 0.031698   3rd Qu.: 0.031649  \n Max.   :72.00   Max.   : 6.326e-04   Max.   : 0.111043   Max.   : 0.110819  \n\n\n作成した市場ポートフォリオの超過リターンをヒストグラムにして分布を確認します。\n\n# 市場ポートフォリオの月次超過リターンをヒストグラムで可視化\nggplot(factor_data) + aes(x = R_Me) + geom_histogram() +\n  labs(x = \"市場ポートフォリオの月次超過リターン\", y = \"度数\") + mystyle\n\n\n\n\n次に、市場ポートフォリオの累積リターンを計算します。 計算の仮定は以下の通りです。\n\nmonth_IDが13の月初から運用スタートし、バイアンドホールドで運用すると仮定する。\n毎年1月にコストなしでリバランスし、リバランス前後で元本の変動はないと仮定する。\n\n市場ポートフォリオの累積グロス・リターンを計算します。\n\ndf_g <- factor_data %>%\n  mutate(\n    gross_R_M = 1 + R_M, # rに1足してグラスリターン\n    cumulative_gross_R_M = cumprod(gross_R_M) # 累積グロスリターン\n    )\n\n作成した累積グロス・リターンを折れ線グラフで可視化します。\n\ng <- ggplot(df_g) + aes(x = month_ID, y = cumulative_gross_R_M) + geom_line()\ng <- g + labs(x = \"Month ID\", y = \"累積グロスリターン\") + mystyle\nprint(g)\n\n\n\n\n累積リターンであることが一発で分かるように、始点を1として、折れ線グラフを描き直します。 rbind()で始点となるデータを追加し、geom_hline()で始点の水準を点線で図示します。\n\n# ch06_10: 市場ポートフォリオの累積リターンの可視化 (2)\ndf_g <- factor_data %>%\n  mutate(gross_R_M = 1 + R_M,\n         cumulative_gross_R_M = cumprod(gross_R_M)) %>%\n  select(month_ID, cumulative_gross_R_M) %>%\n  rbind(c(12, 1), .) # 折れ線グラフの始点を追加\n# 折れ線グラフを作成\ng <- ggplot(df_g) +\n  geom_line(aes(x = month_ID, y = cumulative_gross_R_M)) +\n  geom_hline(yintercept = 1, linetype = \"dotted\", color = \"red\") + # 元本の水準を点線で図示\n  labs(x = \"Month ID\", y = \"Cumulative Gross Return\") +\n  scale_x_continuous(expand = c(0, 0)) + ylim(0.5,1.5) +  mystyle\nprint(g)"
  },
  {
    "objectID": "Chap06.html#ポートフォリオソート",
    "href": "Chap06.html#ポートフォリオソート",
    "title": "6  ファクターモデルの導入",
    "section": "6.3 ポートフォリオ・ソート",
    "text": "6.3 ポートフォリオ・ソート\nある特性に基づいて株式銘柄をランキングにし、そのランキングに基づいてポートフォリオを構築することをポートフォリオ・ソートと呼びます。 ポートフォリオ・ソートは、ファクター・モデルの検証において重要な手法です。 ここでは前年度末の時価総額に基づいて、企業を10個のグループに分類して、実現リターンの比較をしてみましょう。\n\n\n\n図6.2 前年度末の時価総額に基づくポートフォリオ・ソート\n\n\nRで時価総額ランキングを作成するには、ntile()関数を用います。 ntile()関数は、データを指定した数のグループに分類します。 以下のコードでは、mutate()関数でME_rank10を新たに作成しています。 ME_rank10は、lagged_ME変数をntile()関数で10個に分類し、as.factor()関数で因子型に変換したものです。\n\n# ch06_11: 前年度末の時価総額に基づくポートフォリオ・ソート (1)\nannual_data <- annual_data %>%\n  group_by(year) %>% # 年度ごとに\n  mutate(\n    ME_rank10 = as.factor(ntile(lagged_ME, 10))\n    ) %>% # ntile()関数を用いて十個のグループに分類\n  ungroup() # グループ化解除\nhead(annual_data)\n\n# A tibble: 6 × 21\n  firm_ID  year annual_R annual_R_F annual_Re industry_ID sales    OX   NFE\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>       <dbl> <dbl> <dbl> <dbl>\n1       1  2015   NA      0.00743      NA              NA   NA    NA   NA  \n2       1  2016    0.997  0.000565      0.997           1 5949.  564.  50.7\n3       1  2017    0.688  0.0000488     0.688           1 6505.  691.  29.5\n4       1  2018   -0.214  0.00579      -0.219           1 6846.  751.  86.5\n5       1  2019    0.647 -0.000770      0.648           1 7572.  959. 298. \n6       1  2020   -0.284  0.000380     -0.285           1 7538.  778. -65.5\n# ℹ 12 more variables: X <dbl>, OA <dbl>, FA <dbl>, OL <dbl>, FO <dbl>,\n#   BE <dbl>, lagged_BE <dbl>, ROE <dbl>, ME <dbl>, lagged_ME <dbl>, w_M <dbl>,\n#   ME_rank10 <fct>\n\n\nME_rank10の値と、年・ランキングごとの会社数を確認してみましょう。\n\nsummary(annual_data$ME_rank10)\n\n   1    2    3    4    5    6    7    8    9   10 NA's \n 643  642  641  641  640  640  640  640  639  639 1515 \n\ntable(annual_data$year,  annual_data$ME_rank10)\n\n      \n         1   2   3   4   5   6   7   8   9  10\n  2015   0   0   0   0   0   0   0   0   0   0\n  2016 125 124 124 124 124 124 124 124 124 124\n  2017 127 127 127 127 127 127 127 127 127 127\n  2018 127 127 127 127 127 127 127 127 126 126\n  2019 131 131 131 131 130 130 130 130 130 130\n  2020 133 133 132 132 132 132 132 132 132 132\n\n\nここでは、ME_rank10の値が10の企業が時価総額ランキングの上位10%に、1の企業が時価総額ランキングの下位10%に属することを意味します。\n前回と同様に、full_join()関数でmonthly_dataとannual_dataを結合します。 drop_na()関数で欠損行を削除し、group_by()関数でmonth_IDとME_rank10に関してグループ化した上で、summarize()関数で月次超過リターンReの平均値を計算して、Re変数としています。\n\n# ch06_13: 前年度末の時価総額に基づくポートフォリオ・ソート (2)\n\nME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, ME_rank10) %>% # 年次データから追加したい情報を抽出\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # yearとfirm_IDをキーに月次データと結合\n  drop_na() %>% # 欠損行を削除\n  group_by(month_ID, ME_rank10) %>% # month_IDとME_rank10に関してグループ化\n  summarize(Re = mean(Re)) %>% # 各グループで月次超過リターンの平均値を計算\n  ungroup()\nME_sorted_portfolio\n\n# A tibble: 600 × 3\n   month_ID ME_rank10     Re\n      <dbl> <fct>      <dbl>\n 1       13 1         0.0291\n 2       13 2         0.0272\n 3       13 3         0.0353\n 4       13 4         0.0545\n 5       13 5         0.0460\n 6       13 6         0.0438\n 7       13 7         0.0530\n 8       13 8         0.0398\n 9       13 9         0.0536\n10       13 10        0.0478\n# ℹ 590 more rows\n\n\n準備が出来たので、各ポートフォリオの平均超過リターンを可視化してみましょう。 これにより、時価総額の大きい企業のポートフォリオが、時価総額の小さい企業のポートフォリオよりも高い、あるいは低いリターンを上げているかどうかを確認することができます。\n\n# ch06_14: 各ポートフォリオの平均超過リターンを可視化\nME_cross_sectional_return <- ME_sorted_portfolio %>%\n  group_by(ME_rank10) %>% # ME_rank10に関してグループ化\n  summarize(mean_Re = mean(Re)) # 月次超過リターンの平均値を計算\n\ng <- ggplot(ME_cross_sectional_return) + aes(x = ME_rank10, y = mean_Re)\ng <- g + geom_col() # 棒グラフ\ng <- g + xlab(\"時価総額ランク\") + ylab(\"平均月次超過リターン\")\ng <- g + scale_y_continuous(expand = c(0, 0)) + ylim(0,0.02) + mystyle\nprint(g)\n\n\n\n\n小型株ほど月次超過リターンの平均が高いことが分かりました。 このように、時価総額の大きい企業のポートフォリオと小さい企業のポートフォリオのリターンの差をサイズ・プレミアムと呼びます。\n先ほどは各ポートフォリオの区分を同じウェイトで保有した場合のリターンを計算しましたが，コラムでは，時価総額の大きさに応じてウェイトを変えた時価総額加重ポートフォリオを作成して，先ほどの結果を再現してみる。\nまずは等加重の場合のコードを確認する。\n\n# ch06_15a: 簿価時価比率に基づくポートフォリオ・ソート（等加重の場合）\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>% # 簿価時価比率に基づいて十個のグループに分類\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  summarize(Re = mean(Re)) %>% # 月次超過リターンの平均値を計算\n  ungroup()\n# 作図\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) + # y = 0の直線を追加\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n次に時価総額加重の場合のコードを確認します。\n\n# ch06_15b: 簿価時価比率に基づくポートフォリオ・ソート（時価総額加重の場合）\n# 中盤で保有比率wと月次超過リターンReを計算している箇所を除けば,ch06_15aと全く同じ\n\nannual_data <- annual_data %>%\n  mutate(lagged_BEME = lagged_BE / lagged_ME) %>%\n  group_by(year) %>%\n  mutate(BEME_rank10 = as.factor(ntile(lagged_BEME, 10))) %>%\n  ungroup()\n\nBEME_sorted_portfolio <- annual_data %>%\n  select(year, firm_ID, BEME_rank10, lagged_ME) %>%\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>%\n  drop_na() %>%\n  group_by(month_ID, BEME_rank10) %>%\n  mutate(w = lagged_ME / sum(lagged_ME)) %>% # 各ポートフォリオで保有比率を計算\n  summarize(Re = sum(w * Re)) %>% # 時価総額加重の月次超過リターンを計算\n  ungroup()\n\ngroup_by(BEME_sorted_portfolio, BEME_rank10) %>%\n  summarize(mean_Re = mean(Re)) %>%\n  ggplot() +\n  geom_col(aes(x = BEME_rank10, y = mean_Re)) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"BE/ME Rank\", y = \"Mean Monthly Excess Return\") +\n  scale_y_continuous(limits = c(-0.005, 0.02)) + mystyle\n\n\n\n\n結果が異なっていることに注意しましょう。\n次節では，この現象を，資産価格モデルの1つであるCAPM(Capital Asset Pricing Model)が説明できるかどうかを検証します。"
  },
  {
    "objectID": "Chap06.html#capmを検証する意義",
    "href": "Chap06.html#capmを検証する意義",
    "title": "6  ファクターモデルの導入",
    "section": "7.1 CAPMを検証する意義",
    "text": "7.1 CAPMを検証する意義\nまずはCAPMの復習から始めましょう。 CAPMは，資産の期待リターンを，市場ポートフォリオの期待リターンと市場ポートフォリオとの共分散で説明するモデルです。\n\n\n\n\n\n\nCAPM\n\n\n\n\n第1命題: 市場ポートフォリオは接点ポートフォリオと一致し，効率的フ ロンティア(資本市場線)上に位置する.\n第2命題: 各証券のリスクプレミアムは，その証券のマーケット・ベータ に比例する.\n\n\n\\mathbb{E}[R_i] - R_F = \\beta_i \\left ( \\mathbb{E}[R_M] - R_F \\right )\n\nただし，\n\n\\beta_i = \\frac{\\mathrm{COV}_{R_i,  R_M}}{\\mathrm{Var}_M}\n\n\n\nこのCAPMを回帰式で表現すると次のようになります。\n\nR_{i,t}^e = \\beta_i \\times R_{M,t}^e + \\varepsilon_{i,t}\n\nここで、R^e_{i,t} = R_{i,t} - R_{F,t}である。 つまり、t時点における証券iの実現超過リターンR_{i,t}^eは、t時点における市場ポートフォリオの実現超過リターンR_{M,t}^eと、証券iの市場ポートフォリオに対するベータ係数\\beta_iの積に、誤差項\\varepsilon_{i,t}を加えたものとして表現されます。\nまた、誤差項\\varepsilon_{i,t}に関して次の仮定を置きます。\n\nvarepsilon _{i,t}は独立同一分布(i.i.d.)に従う\nE[\\varepsilon_{i,t}] = 0\nE[R_{M,t}^e , \\ \\varepsilon_{i,t} ] = 0\n\nこうすることで、CAPM式を線形回帰モデルで表現できるので、\\beta_iの推定が可能となります。\n\n7.1.0.1 6.2.2 時系列回帰\nCAPM式は任意のi証券で成立するモデルのため、ポートフォリオにも応用できます。 つまりあるポートフォリオの超過リターンを、市場ポートフォリオの超過リターンと、そのポートフォリオに対するベータ係数の積で説明することができます。\n\nR_{P,t}^e = \\alpha _P + \\beta_P R_{M,t}^e + \\varepsilon_{P,t}\n\nCAPMの式と比較すると、切片である\\alpha _Pが追加されていることが分かります。 もし証券市場にCAPMの関係が成立しているなら、\\alpha _Pはゼロとなっているはずです。 この$$を調べることで、CAPMの検証が可能となります。\nここでは、時系列回帰を使って、市場ポートフォリオの超過リターンを説明変数として、各ポートフォリオの超過リターンを説明するモデルを推定します。\n\n# 市場ポートフォリオの超過リターンを追加\nME_sorted_portfolio <- factor_data %>%\n  select(-R_F) %>% # 無リスク金利は重複するので結合前に削除\n  full_join(ME_sorted_portfolio, by = \"month_ID\") %>% # month_IDをキーに\n  select(-R_Me, R_Me) # R_Meを最終列へ移動\n\nfactor_dataとME_sorted_portfolioをmonth_IDで結合て，ME_sorted_portfolioに代入してます。要するに，ME_sorted_portfolioにfactor_dataを追加しているだけです。\n次に，時価総額が最小の企業群ME_rank10 ==1を抽出し，超過リターンReを市場ポートフォリオの超過リターンR_Meで回帰します。 data = .とすることで，lm()関数の第二引数にデータを代入するようにしています。 最後に，結果をtidy()関数でデータフレームに変換しています。\n\n# 時系列回帰 (1)\nME_sorted_portfolio %>%\n  filter(ME_rank10 == 1) %>% # 時価総額が最小のポートフォリオを抽出\n  lm(Re ~ R_Me, data = .) %>% # .を使ってlm()関数の第二引数にデータを代入\n  tidy() # 線形回帰の結果をtidy()関数でデータフレームに変換\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)   0.0121   0.00404      3.00 0.00395      \n2 R_Me          0.654    0.0976       6.70 0.00000000937\n\n\n次はこの回帰式を図示します。\n\n# MEの最小グループを抽出\ndf_rank1 <- ME_sorted_portfolio %>%\n  filter(ME_rank10 == 1)\n# 散布図と回帰式を描画\ng <- ggplot(df_rank1) + aes(x = R_Me, y = Re)\ng <- g + geom_point() + geom_smooth(method = \"lm\", color = \"black\")\ng <- g + xlab(\"市場ポートフォリオの超過リターン\") + ylab(\"小型株ポートフォリオの超過リターン\") + mystyle\nprint(g)\n\n\n\n\n\n\n7.1.1 ポートフォリオごとの回帰\n次に，時価総額ランクごとに回帰分析を行います。 複数のグループに同じ処理を繰り返して適用したい場合，3つの方法があります。\n\nforループを使う\n基本関数であるapply関数を使う\ntidyverseのpurrrパッケージのmap関数を使う\n\n\nforループを使う方法\n最初に，forループを使って，時価総額ランクごとに回帰分析を行います。 次のソースコードの構造は，次のようになっています。\n\n空のリストCAPM_resultsを作成\nforで繰り返す範囲を指定\nME_rank10のグループを抽出し，\nlm()関数で平均超過リターンを市場超過リターンで回帰\ntidy()関数でデータフレームに変換\n分析しているランクを示す変数ME_rank10を作成\nselect()関数でME_rank10を第一列に移動\n\n\n# : CAPMの実証的な検証 (1)\nCAPM_results <- list(NA) # 推定結果を入れる空のリストを準備\n\nfor(i in 1:10){ # i を1から10まで変化させて以下を繰り返す\n  CAPM_results[[i]] <- ME_sorted_portfolio %>%\n    filter(ME_rank10 == i) %>% # ランクごとに\n    lm(Re ~ R_Me, data = .) %>% # 回帰\n    tidy() %>% # データ整形\n    mutate(ME_rank10 = i) %>% # 推定対象のポートフォリオ名を保存\n    select(ME_rank10, everything()) # ME_rank10を第一列に移動\n}\n\nこれでリスト型オブジェクトであるCAPM_resultsに各ポートフォリオの回帰の推定結果が入りました。 CAPM_resultsはリスト型になっているので，rbindをdo.call関数で実行することで，データフレームに変換します。\n\n# CAPMの実証的な検証 (2)\nCAPM_results <- do.call(rbind, CAPM_results) # do.call()関数を用いて複数のデータフレームから構成されるリストを一つのデータフレームに統合\n\nこれでCAPM_resultsに規模グループごとの回帰の推定結果が入りました。\n\n\nlapplyループを使う方法\n複数のグループに同じ処理を繰り返す2番目の方法は，基本関数であるapply関数を使う方法です。ここではリスト型オブジェクトに対して処理を繰り返すlapply()関数を使います。\n\n\n\n\n\n\nlapply()関数\n\n\n\nlapply()関数は，リスト型のオブジェクトに対して，指定した関数を適用する関数です。 lapply()関数は2つの引数をとり，1つ目がデータが入ったリスト型のオブジェクト，2つ目が適用する関数となります。 lapply()関数は，リスト型に関数を適用してリスト型のオブジェクトを返します。\n\n\nまず時価総額ランクME_rank10ごとに，ME_sorted_portfolioを分割するためにsplit()関数を使います。\n\n\n\n\n\n\nsplit()関数\n\n\n\nベクトルやデータフレームといったオブジェクトを、指定した要素ごとに分割したいとき，split()関数を使います。 split()関数は2つの引数をとり，1つ目がデータが入ったオブジェクト，2つ目が分割するための基準となる変数となります。分割後はリスト型になります。\n\n\n次のソースコードでは，\n\nsplit()でME_sorted_portfolioをME_rank10を基準に分割\n線形回帰結果を出力するestimate_CAPM関数を定義\nlapply()関数を使って，estimate_CAPM関数を各グループに適用\n\nという処理を行っています。\n\nME_sorted_portfolio_splitted <- split(ME_sorted_portfolio, ME_sorted_portfolio$ME_rank10) # データを分割してリスト型に\n# 独自関数を定義\nestimate_CAPM <- function(return_data) {\n  lm_results <- lm(Re ~ R_Me, data = return_data) # 線形回帰\n  tidied_lm_results <- tidy(lm_results) # tidy()関数でデータ整形\n}\n\nCAPM_results_by_lapply <- lapply(ME_sorted_portfolio_splitted, estimate_CAPM) #\n\nforループに比べて，ソースコードがかなりシンプルになったかと思います。\n\n\npurrrのmap()関数を使う方法\ntidyverseのpurrrパッケージのmap()関数を使ってグループごとに処理を繰り返す方法について説明します。 purrrパッケージは，tidyverseの1つで，リスト型オブジェクトに対して処理を繰り返す関数を提供しています。 基本関数のapply系関数よりも，purrrパッケージのmap()関数を使った方が，コードがシンプルになり読みやすくなります。\n以下では，purrrのmap()関数を使って時価総額ランクごとに線形回帰を行います。 以下では，グループごとにデータを分割し、分割されたデータを各セルに埋め込むnest()関数を使って，ME_rank10ごとにグループ化しています。 group_by()とnest()をまとめたgroup_nest()関数を使います。\n\nME_sorted_portfolio %>%\n  group_nest(ME_rank10) %>% # ランクごとにグループ化しセルに埋め込む\n  mutate(\n    CAPM_regression = map(data, ~lm(Re ~ R_Me, data = .)), # 回帰\n    CAPM_summary = map(CAPM_regression, tidy) # tidy()を適用\n    ) %>% # tidy()関数を用いて線形回帰の結果を整理\n  select(-c(data, CAPM_regression)) %>% # 線形回帰の結果のみを抽出\n  unnest(cols = CAPM_summary) %>% # nest()関数による畳み込みを解除\n  ungroup()\n\n# A tibble: 20 × 6\n   ME_rank10 term         estimate std.error statistic  p.value\n   <fct>     <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n 1 1         (Intercept)  0.0121     0.00404     3.00  3.95e- 3\n 2 1         R_Me         0.654      0.0976      6.70  9.37e- 9\n 3 2         (Intercept)  0.0106     0.00375     2.83  6.44e- 3\n 4 2         R_Me         0.711      0.0908      7.83  1.19e-10\n 5 3         (Intercept)  0.0120     0.00312     3.86  2.90e- 4\n 6 3         R_Me         0.770      0.0754     10.2   1.42e-14\n 7 4         (Intercept)  0.00957    0.00289     3.31  1.62e- 3\n 8 4         R_Me         0.848      0.0699     12.1   1.54e-17\n 9 5         (Intercept)  0.00728    0.00234     3.11  2.86e- 3\n10 5         R_Me         0.896      0.0565     15.9   9.35e-23\n11 6         (Intercept)  0.00653    0.00195     3.34  1.45e- 3\n12 6         R_Me         0.904      0.0472     19.2   9.39e-27\n13 7         (Intercept)  0.00284    0.00173     1.64  1.06e- 1\n14 7         R_Me         0.943      0.0418     22.6   2.16e-30\n15 8         (Intercept)  0.00122    0.00168     0.723 4.73e- 1\n16 8         R_Me         0.956      0.0407     23.5   2.59e-31\n17 9         (Intercept)  0.000406   0.00144     0.282 7.79e- 1\n18 9         R_Me         1.03       0.0349     29.5   1.33e-36\n19 10        (Intercept) -0.000659   0.00113    -0.582 5.63e- 1\n20 10        R_Me         1.06       0.0273     38.9   2.93e-43\n\n\nこれで，時価総額ランク1〜10ごとに線形回帰を行った結果，切片(Intercept)と説明変数R_Meの係数estimate，標準誤差std.error，t値statistic，p値p.valueが計算されています。\n\n\n7.1.1.1 6.2.4 CAPMアルファ\nCAPMが成立している世界では，\\alpha _Pはゼロとなるはずです。 そこで，時価総額ランクに応じて10個に分けた企業群ごとの\\alpha _Pを図示してみます。\n\n# : CAPMアルファの可視化\n\ndf_g <- CAPM_results %>%\n  filter(term == \"(Intercept)\") %>% # 切片を抽出\n  mutate(ME_rank10 = as.factor(ME_rank10)) # ME_rank10をファクター型\ng <- ggplot(df_g) + aes(x = ME_rank10, y = estimate)\ng <- g + geom_col() + geom_hline(yintercept = 0)\ng <- g + xlab(\"時価総額ランク\") + ylab(\"CAPMアルファ\")\ng <- g + scale_y_continuous(limits = c(-0.003, 0.013)) + mystyle\nprint(g)\n\n\n\n\n小型株ほどCAPMアルファが高く，時価総額が大きくなるにつれて\\alpha _Pがゼロに近づいていることが分かります。 各グループの回帰分析の切片が統計的にゼロかどうかを確認するために、検定してみます。\n\n# : CAPMアルファの統計的な有意性を評価\n\nCAPM_results %>%\n  filter(term == \"(Intercept)\") %>% # 定数項に関する推定結果のみを抽出\n  rename(CAPM_alpha = estimate, p_value = p.value) %>% # 列名を変更\n  mutate(significance = cut(p_value,\n                            breaks = c(0, 0.01, 0.05, 0.1, 1),\n                            labels = c(\"***\", \"**\", \"*\", \"\"),\n                            include.lowest = TRUE)) %>% # 統計的に有意な結果を*で強調\n  select(ME_rank10, CAPM_alpha, p_value, significance) # 出力したい列を指定\n\n# A tibble: 10 × 4\n   ME_rank10 CAPM_alpha  p_value significance\n       <int>      <dbl>    <dbl> <fct>       \n 1         1   0.0121   0.00395  \"***\"       \n 2         2   0.0106   0.00644  \"***\"       \n 3         3   0.0120   0.000290 \"***\"       \n 4         4   0.00957  0.00162  \"***\"       \n 5         5   0.00728  0.00286  \"***\"       \n 6         6   0.00653  0.00145  \"***\"       \n 7         7   0.00284  0.106    \"\"          \n 8         8   0.00122  0.473    \"\"          \n 9         9   0.000406 0.779    \"\"          \n10        10  -0.000659 0.563    \"\"          \n\n\n分析結果より，ME_rank10が7から10のグループでは，CAPMアルファはp統計量が10%以上となっており，統計的にゼロと異なっているかどうか分かりません。\n次に，R_Meの回帰係数を取り出し，CAPM_betaという列名に変更します。\n\n# : 証券市場線の推定\n\nME_cross_sectional_return <- CAPM_results %>%\n  filter(term == \"R_Me\") %>% # R_Meの係数に関する推定結果のみを抽出\n  rename(CAPM_beta = estimate) %>% # 推定値をestimateからCAPM_betaに名称変更\n  select(ME_rank10, CAPM_beta) %>%\n  mutate(ME_rank10 = as.factor(ME_rank10)) %>% # ME_rank10を整数型からファクター型に\n  full_join(ME_cross_sectional_return, ., by = \"ME_rank10\") # 超過リターンのデータと結合\n\nmean_R_Me <- mean(factor_data$R_Me) # 市場ポートフォリオの実現超過リターンにより証券市場線の傾きを推定\n\ng <- ggplot(ME_cross_sectional_return) + aes(x = CAPM_beta, y = mean_Re)\ng <- g + geom_point() + geom_abline(intercept = 0, slope = mean_R_Me)\ng <- g + xlab(\"市場ベータ\") + ylab(\"平均超過リターン\")\ng <- g + scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0))\ng <- g + scale_y_continuous(limits = c(0, 0.02)) + mystyle\nprint(g)"
  },
  {
    "objectID": "Chap06.html#fama-frenchの3ファクターモデル",
    "href": "Chap06.html#fama-frenchの3ファクターモデル",
    "title": "6  ファクターモデルの導入",
    "section": "6.3 Fama-Frenchの3ファクター・モデル",
    "text": "6.3 Fama-Frenchの3ファクター・モデル\n\n6.3.1 線形ファクター・モデル\n線形ファクター・モデルとは、超過リターンをファクター・リターンの線形結合として表すモデルです。 N個のファクターF^nと誤差項\\varepsilon_iの線形結合として銘柄iのt時点における超過リターンR_{i,t}を表すとします。 \nR_{i,t}^e = \\beta_i^1 F_t^1 + \\beta_i^2 F_t^2 + \\cdots + \\beta_i^N F_t^N + \\varepsilon_{i,t}\n\n\n\n6.3.2 サイズ・ファクターとバリュー・ファクター\nここでは，Fama-Frenchの3ファクター・モデル(以下，FF3モデル)について説明します。 「CAPMでリターンを説明しようとすると，小型株やバリュー株がアルファをもつ」という実証結果をうけて，FF3モデルはこれらのファクターをモデルに加えて次のようなモデルを作りました。\n\nR_{i,t}^e = \\beta_i^M R_{M,t}^e + \\beta_i^{SMB} SMB_t + \\beta_i^{HML} HML_t + \\varepsilon_{i,t}\n ここで，\n\nSMB_tはサイズ・ファクターで，小型株と大型株の平均リターンの差を表します。サイズは時価総額の大きさで測ります。\nHML_tはバリュー・ファクターで，バリュー株とグロース株の平均リターンの差を表します。バリューは簿価時価比率で測ります。\n\n実際にSMBとHMLを計算する方法は，次の通りです。\n\n\n\nSMBとHMLの計算方法\n\n\nすべての銘柄を上の図のように6分割し，各グループごとに時価総額加重ポートフォリオを作成します。\n大型株(Big)に属するB/H，B/N，B/Lの3グループをそれぞれ1/3ずつの割合で総額x円を空売り(ショート)して，それで得たx円を小型株(Small)に属するS/H，S/N，S/Lのポートフォリオに1/3ずつ総額x円を購入(ロング)する，という投資戦略を実行した場合のリターンがサイズ・ファクターSMBとなる。\n\nSMB_t = \\underbrace{\\left ( \\frac{S/H_t + S/N_t + S/L_t}{3} \\right)}_{\\text{小型株の平均リターン}} - \\underbrace{\\left ( \\frac{B/H_t + B/N_t + B/L_t}{3} \\right)}_{\\text{大型株の平均リターン}}\n\n同様に，バリュー・ファクターHMLも次のように計算します。 \nHML_t = \\underbrace{\\left ( \\frac{S/H_t + B/H_t}{2} \\right)}_{\\text{バリュー株の平均リターン}} - \\underbrace{\\left ( \\frac{S/L_t + B/L_t}{2} \\right)}_{\\text{グロース株の平均リターン}}\n\n\n\n6.3.3 銘柄のランク付け\n実際にシミュレーション・データを使ってファクターを計算してみます。 最初に，上の図で示したような6つの時価総額でウェイト付けたポートフォリオを作成するために，\n\n前年度の時価総額 lagged_ME\n前年度の簿価時価比率 lagged_BEME\n\nで銘柄をランク付けします。\n\nannual_data <- annual_data %>%\n  mutate(lagged_ME = replace(lagged_ME, is.na(lagged_BEME), NA)) %>% # lagged_BEMEがNAのときlagged_MEもNAに\n  group_by(year) %>% # 年度ごとに\n  mutate(ME_rank2 = as.factor(ntile(lagged_ME, 2))) %>% # 2つのグループに分ける\n  ungroup()\n\n簿価時価比率に基づくランク付け (1)\n\nannual_data %>%\n  group_by(year) %>%\n  mutate(BEME_percent_rank = percent_rank(lagged_BEME)) %>% # 年度ごとに簿価時価比率のパーセンタイル順位を計算\n  select(firm_ID, year, lagged_BEME, ME_rank2, BEME_percent_rank) %>%\n  ungroup()\n\n# A tibble: 7,920 × 5\n   firm_ID  year lagged_BEME ME_rank2 BEME_percent_rank\n     <dbl> <dbl>       <dbl> <fct>                <dbl>\n 1       1  2015      NA     <NA>              NA      \n 2       1  2016      NA     <NA>              NA      \n 3       1  2017       1.45  1                  0.729  \n 4       1  2018       0.916 1                  0.529  \n 5       1  2019       1.25  1                  0.626  \n 6       1  2020       0.793 1                  0.481  \n 7       2  2015      NA     <NA>              NA      \n 8       2  2016       0.258 1                  0.0331 \n 9       2  2017       0.193 1                  0.0158 \n10       2  2018       0.124 1                  0.00631\n# ℹ 7,910 more rows\n\n\n\n\n\n\n\n\npercent_rank()関数\n\n\n\ndplyrパッケージのpercent_rank()関数は，データのパーセンタイル順位を計算する関数です。 パーセンタイル順位とは，データの中で自分の値が何パーセントに位置するかを表す数値です。 50パーセンタイルは中央値を意味します。\n\n\n任意のパーセンタイルでデータを分析したいので，先ほどのntile()関数ではなく，percent_rank()関数をつかってパーセンタイル順位を計算し，30％と70％のパーセンタイルで3つのグループに分けます。 そのパーセンタイル順序を基準として，cut()関数で3つのグループに分けます。\n\n\n\n\n\n\ncut()関数\n\n\n\ncut()関数は，データを指定した区間に分割する関数です。 cut()関数は4つの引数をとり，1つ目がデータが入ったオブジェクト，2つ目が区間の境界値，3つ目が区間のラベル，4つ目が区間の境界値に含めるかどうかを指定する引数です。\n\n\n\nannual_data <- annual_data %>%\n  group_by(year) %>% # 年度ごとに\n  mutate(BEME_percent_rank = percent_rank(lagged_BEME)) %>% # 簿価時価比率のパーセンタイル順位を計算\n  ungroup() %>% # グループ化解除\n  mutate(BEME_rank3 = cut(BEME_percent_rank,\n                          breaks = c(0, 0.3, 0.7, 1),\n                          labels = c(1, 2, 3),\n                          include.lowest = TRUE)) # BEME_percent_rankの値に応じて1から3までBEME_rank3の値を定義\n\n\n\n6.3.4 時価総額とBE/MEに基づくポートフォリオ・ソート\n次に，時価総額と簿価時価比率に基づくポートフォリオ・ソートを行います。 先ほど，時価総額と簿価時価比率に基づくランク付けを行ったので、ここでは時価総額と簿価時価比率のランクを組み合わせて，6つのポートフォリオを作成します。\ninteraction()関数を使って，複数のカテゴリー変数を組み合わせて新しいカテゴリー変数を作成します。\n\nannual_data <- annual_data %>%\n  mutate(FF_portfolio_type = interaction(ME_rank2, BEME_rank3)) # ME_rank2とBEME_rank3の組合せ\n\nannual_dataデータフレームにFF_portfolio_typeという新しいカテゴリー変数が追加されました。 interaction()関数で作成されたカテゴリー変数を確認してみます。\n\nhead(annual_data$FF_portfolio_type)\n\n[1] <NA> <NA> 1.3  1.2  1.2  1.2 \nLevels: 1.1 2.1 1.2 2.2 1.3 2.3\n\ntable(annual_data$FF_portfolio_type)\n\n\n 1.1  2.1  1.2  2.2  1.3  2.3 \n 773 1149 1130 1430 1299  623 \n\n\ninteraction()関数で作成されたカテゴリー変数が、ME_rank2とBEME_rank3のランクを組み合わせたものであることがわかります。 このままだと見づらいので、fct_recode()関数を使って、カテゴリー変数の水準を変更します。\n\nannual_data <- annual_data %>%\n  mutate(FF_portfolio_type = fct_recode(FF_portfolio_type, # ラベル変更\n                                        SL = \"1.1\",\n                                        BL = \"2.1\",\n                                        SN = \"1.2\",\n                                        BN = \"2.2\",\n                                        SH = \"1.3\",\n                                        BH = \"2.3\"))\n\nこれでSmallとBig、Low・Neutral・Highの組み合わせを意味するSL、BL、SN、BN、SH、BHの6つのカテゴリーを持つカテゴリー変数が作成されました。\n\nannual_data %>%\n  group_by(FF_portfolio_type) %>% # 6グループごとに\n#  group_by(ME_rank2, BEME_rank3) %>% # ME_rank2とBEME_rank3のペアでグループ化\n  summarize(\n    mean_BEME = mean(lagged_BEME),\n    mean_ME = mean(lagged_ME),\n    mean_N_stocks = n() / length(unique(year))) %>%\n  ungroup() %>%\n  drop_na() # 欠損データを削除\n\n# A tibble: 6 × 4\n  FF_portfolio_type mean_BEME mean_ME mean_N_stocks\n  <fct>                 <dbl>   <dbl>         <dbl>\n1 SL                    0.416  11601.          155.\n2 BL                    0.468 414941.          230.\n3 SN                    0.973  11868.          226 \n4 BN                    0.960 211793.          286 \n5 SH                    1.97   11023.          260.\n6 BH                    1.72  151135.          125.\n\n\n準備ができたので、あとは年度ごとに各ポートフォリオの時価総額加重lagged_MEに基づいて保有比率wを計算します。\n\nannual_data <- annual_data %>%\n  group_by(year, FF_portfolio_type) %>% # yearとFF_portfolio_typeのペアでグループ化\n  mutate(\n    w = lagged_ME  / sum(lagged_ME, na.rm = TRUE)\n    ) %>% # 各ポートフォリオ内で時価総額加重の保有比率を計算\n  ungroup()\n\n6グループへの投資割合を示すウェイトwを計算しました。 このウェイトを使って、各ポートフォリオの月次の時価総額加重の平均リターンを計算します。\n\nFF_portfolio <- annual_data %>%\n  select(year, firm_ID, FF_portfolio_type, ME_rank2, BEME_rank3, w) %>% # 使う偏すのみ\n  full_join(monthly_data, by = c(\"year\", \"firm_ID\")) %>% # 月次データと結合\n  group_by(month_ID, FF_portfolio_type) %>% # 月と6グループ\n  summarize(\n    ME_rank2 = ME_rank2[1], # グラフ作成用に残す\n    BEME_rank3 = BEME_rank3[1], # グラフ作成用に残す\n    R = sum(w * R, na.rm = TRUE), # 各ポートフォリオの月次リターンを計算\n    R_F = R_F[1] # 無リスク利子率\n    ) %>%\n  ungroup() %>%\n  drop_na() # 欠損データを削除\n\nFF_portfolioデータフレームには、6つのポートフォリオの月次の時価総額加重の平均リターンRが計算されています。 Rから無リスク利子率R_Fを引いた超過リターンReを計算します。\n\nFF_mean_return <- FF_portfolio %>%\n  mutate(Re = R - R_F) %>% # 超過リターン\n  group_by(FF_portfolio_type) %>% # FF_portfolio_typeでグループ化\n  summarize(\n    ME_rank2 = ME_rank2[1],\n    BEME_rank3 = BEME_rank3[1],\n    mean_Re = mean(Re)\n    ) # 各ポートフォリオの超過リターンの平均値を計算\n\n計算した超過リターンを簿価時価比率グループを横軸とした棒グラフにします。\n\ng <- ggplot(FF_mean_return) + aes(x = BEME_rank3, y = mean_Re, fill = ME_rank2)\ng <- g + geom_col(position = \"dodge\") # 棒グラフを作成\ng <- g + xlab(\"簿価時価比率ランク\") + ylab(\"月次超過リターン\") + labs(fill=\"時価総額ランク\")\ng <- g + geom_text(aes(x = BEME_rank3, y = mean_Re, group = ME_rank2, label = FF_portfolio_type), # (x, y)座標を指定して各ポートフォリオの名前をグラフに挿入\n            vjust = -0.5, # 棒グラフが重ならないよう文字ラベルを上にずらす\n            position = position_dodge(width = 0.9)\n            ) # ME_rank2のサブグループで文字ラベルが左右にずれるよう調整\ng <- g + mystyle\nprint(g)\n\n\n\n\n次に、時価総額と簿価時価比率で分けた6グループの両端のグループの超過リターンを比較します。 具体的には、B/LグループとS/Hグループの累積グロス・リターンを比較するために、基準点を1とする折れ線グラフを書いてみます。\n\ninitial_point <- tibble(month_ID = c(12, 12), # 累積リターンの起点を定義\n                            cumulative_gross_R = c(1, 1),\n                            FF_portfolio_type = c(\"BL\", \"SH\"))\n\nFF_CR <- FF_portfolio %>%\n  group_by(FF_portfolio_type) %>% # グループ別\n  mutate(\n    cumulative_gross_R = cumprod(1 + R) # グロス・リターンを累積\n    ) %>% \n  ungroup() %>% \n  filter(FF_portfolio_type %in% c(\"BL\", \"SH\")) %>% # B/LグループとS/Hグループのみ\n  select(month_ID, cumulative_gross_R, FF_portfolio_type) %>% # 必要な変数のみ\n  rbind(initial_point, .) # initial_pointを第一行に挿入\n\nこれでFF_CRデータフレームには、B/LグループとS/Hグループの累積グロス・リターンcumulative_gross_Rが計算されたので、作図してみます。\n\ng <- ggplot(FF_CR) + aes(x = month_ID, y = cumulative_gross_R, linetype = FF_portfolio_type, color = FF_portfolio_type) \ng <- g + geom_line() +   scale_linetype_manual(values = c(\"longdash\", \"solid\"))\ng <- g + geom_hline(yintercept = 1, linetype = \"dotted\")\ng <- g + xlab(\"月次ID\") + ylab(\"累積グロス・リターン\") + mystyle\nprint(g)\n\n\n\n\n\n\n6.3.5 ファクター・リターンの計算\n6グループから構成されるポートフォリオの月次リターンを計算したので、次にサイズ・ファクターSMB_tとバリュー・ファクターHML_tを計算します。 サイズ・ファクターは、小型株ポートフォリオの平均リターンと大型株ポートフォリオの平均リターンの差を計算し、バリュー・ファクターは、バリュー株ポートフォリオの平均リターンとグロース株ポートフォリオの平均リターンの差を計算します。 よって、各ポートフォリオのリターンを加減するために、pivot_wider()関数を使って、縦長のデータを横長のデータに変換します。\nイメージ図は以下のとおりです。 \nやってみましょう。\n\nFF_portfolio <- FF_portfolio %>%\n  pivot_wider(\n    id_cols = month_ID, \n    names_from = FF_portfolio_type, \n    values_from = R) # FF_portfolio_typeの値に基づく列を作成し, 縦長から横長のデータに変換\nhead(FF_portfolio)\n\n# A tibble: 6 × 7\n  month_ID      SL       BL       SN       BN        SH       BH\n     <dbl>   <dbl>    <dbl>    <dbl>    <dbl>     <dbl>    <dbl>\n1       13  0.0344  0.0487   0.0408   0.0432   0.0493    0.0379 \n2       14  0.0162  0.0188   0.0392   0.0432   0.0265    0.0400 \n3       15 -0.0114 -0.0650  -0.00748 -0.0583  -0.000905 -0.0360 \n4       16 -0.0509 -0.00970 -0.0296   0.0132  -0.00850   0.0161 \n5       17 -0.0504 -0.00648 -0.0208  -0.00310 -0.0139   -0.00901\n6       18 -0.0101 -0.0453  -0.0210  -0.0259  -0.0198   -0.0309 \n\n\nこれで6グループごとのリターンが6つの変数として並んだので、サイズ・ファクターとバリュー・ファクターを計算します。 以下では、mutate()関数でバリュー・ファクター変数としてSMBとHMLを定義通りに計算しています。\n\n# ch06_38 : SMBとHMLの構築 (2)\nfactor_data <- FF_portfolio %>%\n  mutate(SMB = (SH + SN + SL) / 3 - (BH + BN + BL) / 3, # SMBを計算\n         HML = (SH + BH) / 2 - (SL + BL) / 2 # HMLを計算\n         ) %>% \n  select(month_ID, SMB, HML) %>% # 月とバリュー・ファクターのみ\n  full_join(factor_data, by = \"month_ID\") %>% # 3ファクターの実現値をfactor_dataに集約\n  select(-c(\"SMB\", \"HML\"), c(\"SMB\", \"HML\")) # SMBとHMLを最後列に移動\nhead(factor_data)\n\n# A tibble: 6 × 6\n  month_ID       R_F      R_M     R_Me      SMB     HML\n     <dbl>     <dbl>    <dbl>    <dbl>    <dbl>   <dbl>\n1       13 0.0000433  0.0458   0.0458  -0.00178 0.00200\n2       14 0.0000346  0.0284   0.0284  -0.00670 0.0158 \n3       15 0.0000393 -0.0580  -0.0580   0.0465  0.0198 \n4       16 0.0000662 -0.00107 -0.00114 -0.0362  0.0341 \n5       17 0.0000360 -0.00642 -0.00645 -0.0222  0.0170 \n6       18 0.0000257 -0.0371  -0.0371   0.0171  0.00232\n\n\n\n\n6.3.6 FF3アルファ\nCAPMではアルファがゼロにはならず、小型株で大きなアルファが観察されました。 しかし、FF3モデルでは、サイズ・ファクターとバリュー・ファクターを考慮することで、アルファがゼロになることが予測されます。 実際に、FF3モデルを推定してみましょう。\n\nR_{P,t}^e = \\alpha_P^{FF3} + \\beta_P^M  R_{M,t}^e + \\beta_P^{SMB} SMB_t + \\beta_P^{HML} HML_t + \\varepsilon_{P,t}\n\nこの回帰モデルのパラメータを、いままで計算してきたデータを使って推定します。 とりわけ\\alpha_{P}^{FF3}の値に注目します。 \\alpha_{P}^{FF3}は、FF3モデルのアルファと呼ばれ、ポートフォリオPのリスク・プレミアムを計算する際に使われます。\n\nME_sorted_portfolio <- ME_sorted_portfolio %>%\n  select(-c(R_Me, R_M)) %>% # 重複するので除外しておく\n  full_join(factor_data, by = \"month_ID\") \n\nFF3_results <- list(NA)  # 空のリストを準備\n\nfor(i in 1:10) {\n  FF3_results[[i]] <- ME_sorted_portfolio %>%\n    filter(ME_rank10 == i) %>%\n    lm(Re ~ R_Me + SMB + HML, data = .) %>% # 3ファクターの実現値を独立変数として重回帰\n    tidy() %>%\n    mutate(ME_rank10 = i) %>% # 推定対象のポートフォリオ名を保存\n    select(ME_rank10, everything()) # ME_rank10を第一列に移動\n}\n\nFF3_results <- do.call(rbind, FF3_results)\n\nFF3モデルを推定して得られた回帰式の切片であるFF3アルファを，棒グラフにしてみます。\n\ndf_g <- FF3_results %>% # FF3推定結果\n  filter(term == \"(Intercept)\") %>% # 切片のみ\n  mutate(ME_rank10 = as.factor(ME_rank10)) # ME_rank10をファクター\n\ng <- ggplot(df_g) + aes(x = ME_rank10, y = estimate) # 軸を設定\ng <- g + geom_col() + geom_hline(yintercept = 0) # 棒グラフと直線\ng <- g + xlab(\"時価総額ランク\") + ylab(\"FF3アルファ\") # 軸ラベル\ng <- g + scale_y_continuous(limits = c(-0.003, 0.013)) + mystyle\nprint(g) # 出力\n\n\n\n\nFF3アルファの統計的な有意性を評価するため，切片がゼロである，という帰無仮説を検定します。\n\nFF3_results %>%\n  filter(term == \"(Intercept)\") %>% # 切片のみ\n  rename(FF3_alpha = estimate, p_value = p.value) %>% # 列名を変更\n  mutate(significance = cut(p_value,\n                            breaks = c(0, 0.01, 0.05, 0.1, 1),\n                            labels = c(\"***\", \"**\", \"*\", \"\"),\n                            include.lowest = TRUE)) %>% # 統計的に有意な結果を*で強調\n  select(ME_rank10, FF3_alpha, p_value, significance) # 出力したい列を指定\n\n# A tibble: 10 × 4\n   ME_rank10 FF3_alpha p_value significance\n       <int>     <dbl>   <dbl> <fct>       \n 1         1  0.00244   0.181  \"\"          \n 2         2  0.00134   0.412  \"\"          \n 3         3  0.00246   0.0893 \"*\"         \n 4         4 -0.000843  0.335  \"\"          \n 5         5 -0.000924  0.336  \"\"          \n 6         6  0.000957  0.456  \"\"          \n 7         7 -0.00183   0.119  \"\"          \n 8         8  0.000842  0.555  \"\"          \n 9         9 -0.00100   0.522  \"\"          \n10        10 -0.00228   0.0492 \"**\"        \n\n\n推定した結果が入ったfactor_dataをch06_output.csvとして出力するため，write_csv()関数を使います。\n\nwrite_csv(factor_data, \"ch06_output.csv\") # data.frameをcsvで保存"
  },
  {
    "objectID": "Chap06.html#capmの実証的な検証",
    "href": "Chap06.html#capmの実証的な検証",
    "title": "6  ファクターモデルの導入",
    "section": "6.2 CAPMの実証的な検証",
    "text": "6.2 CAPMの実証的な検証\n\n6.2.1 CAPMを検証する意義\nまずはCAPMの復習から始めましょう。 CAPMは，資産の期待リターンを，市場ポートフォリオの期待リターンと市場ポートフォリオとの共分散で説明するモデルです。\n\n\n\n\n\n\nCAPM\n\n\n\n\n第1命題: 市場ポートフォリオは接点ポートフォリオと一致し，効率的フ ロンティア(資本市場線)上に位置する.\n第2命題: 各証券のリスクプレミアムは，その証券のマーケット・ベータ に比例する.\n\n\n\\mathbb{E}[R_i] - R_F = \\beta_i \\left ( \\mathbb{E}[R_M] - R_F \\right )\n ただし， \n\\beta_i = \\frac{\\mathrm{COV}_{R_i,  R_M}}{\\mathrm{Var}_M}\n\n\n\nこのCAPMを回帰式で表現すると次のようになります。\n\nR_{i,t}^e = \\beta_i \\times R_{M,t}^e + \\varepsilon_{i,t}\n ここで、R^e_{i,t} = R_{i,t} - R_{F,t}である。 つまり、t時点における証券iの実現超過リターンR_{i,t}^eは、t時点における市場ポートフォリオの実現超過リターンR_{M,t}^eと、証券iの市場ポートフォリオに対するベータ係数\\beta_iの積に、誤差項\\varepsilon_{i,t}を加えたものとして表現されます。\nまた、誤差項\\varepsilon_{i,t}に関して次の仮定を置きます。\n\n\\varepsilon _{i,t}は独立同一分布(i.i.d.)に従う\nE[\\varepsilon_{i,t}] = 0\nE[R_{M,t}^e , \\ \\varepsilon_{i,t} ] = 0\n\nこうすることで、CAPM式を線形回帰モデルで表現できるので、\\beta_iの推定が可能となります。\n\n\n6.2.2 時系列回帰\nCAPM式は任意のi証券で成立するモデルのため、ポートフォリオにも応用できます。 つまりあるポートフォリオの超過リターンを、市場ポートフォリオの超過リターンと、そのポートフォリオに対するベータ係数の積で説明することができます。\n\nR_{P,t}^e = \\alpha _P + \\beta_P R_{M,t}^e + \\varepsilon_{P,t}\n\nCAPMの式と比較すると、切片である\\alpha _Pが追加されていることが分かります。 もし証券市場にCAPMの関係が成立しているなら、\\alpha _Pはゼロとなっているはずです。 この\\alphaを調べることで、CAPMの検証が可能となります。\nここでは、時系列回帰を使って、市場ポートフォリオの超過リターンを説明変数として、各ポートフォリオの超過リターンを説明するモデルを推定します。\n\n# 市場ポートフォリオの超過リターンを追加\nME_sorted_portfolio <- factor_data %>%\n  select(-R_F) %>% # 無リスク金利は重複するので結合前に削除\n  full_join(ME_sorted_portfolio, by = \"month_ID\") %>% # month_IDをキーに\n  select(-R_Me, R_Me) # R_Meを最終列へ移動\n\nfactor_dataとME_sorted_portfolioをmonth_IDで結合て，ME_sorted_portfolioに代入してます。要するに，ME_sorted_portfolioにfactor_dataを追加しているだけです。\n次に，時価総額が最小の企業群ME_rank10 == 1をfilter()で抽出し，超過リターンReを市場ポートフォリオの超過リターンR_Meでlm()関数で回帰します。 data = .とすることで，lm()関数の第二引数にデータを代入するようにしています。 最後に，結果をtidy()関数でデータフレームに変換しています。\n\nME_sorted_portfolio %>%\n  filter(ME_rank10 == 1) %>% # 時価総額が最小のポートフォリオを抽出\n  lm(Re ~ R_Me, data = .) %>% # 回帰\n  tidy() # 結果をデータフレームに変換\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n1 (Intercept)   0.0121   0.00404      3.00 0.00395      \n2 R_Me          0.654    0.0976       6.70 0.00000000937\n\n\n次はこの回帰式を図示します。\n\ndf_rank1 <- ME_sorted_portfolio %>%\n  filter(ME_rank10 == 1) # 散布図と回帰式を描画\n\ng <- ggplot(df_rank1) + aes(x = R_Me, y = Re)\ng <- g + geom_point() + geom_smooth(method = \"lm\", color = \"black\")\ng <- g + xlab(\"市場ポートフォリオの超過リターン\") + ylab(\"小型株ポートフォリオの超過リターン\") + mystyle\nprint(g)\n\n\n\n\n\n\n6.2.3 ポートフォリオごとの回帰\n次に，時価総額ランクごとに回帰分析を行います。 複数のグループに同じ処理を繰り返して適用したい場合，3つの方法があります。\n\nforループを使う\n基本関数であるapply関数を使う\ntidyverseのpurrrパッケージのmap関数を使う\n\n\nforループを使う方法\n最初に，forループを使って，時価総額ランクごとに回帰分析を行います。 次のソースコードの構造は，次のようになっています。\n\n空のリストCAPM_resultsを作成\nforで繰り返す範囲を指定\nME_rank10のグループを抽出し，\nlm()関数で平均超過リターンを市場超過リターンで回帰\ntidy()関数でデータフレームに変換\n分析しているランクを示す変数ME_rank10を作成\nselect()関数でME_rank10を第一列に移動\n\n\nCAPM_results <- list(NA) # 空のリスト作成\n\nfor(i in 1:10){ # i を1から10まで\n  CAPM_results[[i]] <- ME_sorted_portfolio %>%\n    filter(ME_rank10 == i) %>% # ランクごとに\n    lm(Re ~ R_Me, data = .) %>% # 回帰\n    tidy() %>% # データ整形\n    mutate(ME_rank10 = i) %>% # 推定対象のポートフォリオ名を保存\n    select(ME_rank10, everything()) # ME_rank10を第一列に移動\n}\n\nこれでリスト型オブジェクトであるCAPM_resultsに各ポートフォリオの回帰の推定結果が入りました。 CAPM_resultsはリスト型になっているので，rbindをdo.call関数で実行することで，データフレームに変換します。\n\nCAPM_results <- do.call(rbind, CAPM_results)\n# do.call()関数を用いてリストの中身を1つのデータフレームに統合\nprint(CAPM_results)\n\n# A tibble: 20 × 6\n   ME_rank10 term         estimate std.error statistic  p.value\n       <int> <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n 1         1 (Intercept)  0.0121     0.00404     3.00  3.95e- 3\n 2         1 R_Me         0.654      0.0976      6.70  9.37e- 9\n 3         2 (Intercept)  0.0106     0.00375     2.83  6.44e- 3\n 4         2 R_Me         0.711      0.0908      7.83  1.19e-10\n 5         3 (Intercept)  0.0120     0.00312     3.86  2.90e- 4\n 6         3 R_Me         0.770      0.0754     10.2   1.42e-14\n 7         4 (Intercept)  0.00957    0.00289     3.31  1.62e- 3\n 8         4 R_Me         0.848      0.0699     12.1   1.54e-17\n 9         5 (Intercept)  0.00728    0.00234     3.11  2.86e- 3\n10         5 R_Me         0.896      0.0565     15.9   9.35e-23\n11         6 (Intercept)  0.00653    0.00195     3.34  1.45e- 3\n12         6 R_Me         0.904      0.0472     19.2   9.39e-27\n13         7 (Intercept)  0.00284    0.00173     1.64  1.06e- 1\n14         7 R_Me         0.943      0.0418     22.6   2.16e-30\n15         8 (Intercept)  0.00122    0.00168     0.723 4.73e- 1\n16         8 R_Me         0.956      0.0407     23.5   2.59e-31\n17         9 (Intercept)  0.000406   0.00144     0.282 7.79e- 1\n18         9 R_Me         1.03       0.0349     29.5   1.33e-36\n19        10 (Intercept) -0.000659   0.00113    -0.582 5.63e- 1\n20        10 R_Me         1.06       0.0273     38.9   2.93e-43\n\n\nこれでCAPM_resultsに規模グループごとの回帰の推定結果が入りました。\n\n\nlapplyループを使う方法\n複数のグループに同じ処理を繰り返す2番目の方法は，基本関数であるapply関数を使う方法です。ここではリスト型オブジェクトに対して処理を繰り返すlapply()関数を使います。\n\n\n\n\n\n\nlapply()関数\n\n\n\nlapply()関数は，リスト型のオブジェクトに対して，指定した関数を適用する関数です。 lapply()関数は2つの引数をとり，1つ目がデータが入ったリスト型のオブジェクト，2つ目が適用する関数となります。 lapply()関数は，リスト型に関数を適用してリスト型のオブジェクトを返します。\n\n\nまず時価総額ランクME_rank10ごとに，ME_sorted_portfolioを分割するためにsplit()関数を使います。\n\n\n\n\n\n\nsplit()関数\n\n\n\nベクトルやデータフレームといったオブジェクトを、指定した要素ごとに分割したいとき，split()関数を使います。 split()関数は2つの引数をとり，1つ目がデータが入ったオブジェクト，2つ目が分割するための基準となる変数となります。分割後はリスト型になります。\n\n\n次のソースコードでは，\n\nsplit()でME_sorted_portfolioをME_rank10を基準に分割\n線形回帰結果を出力するestimate_CAPM関数を定義\nlapply()関数を使って，estimate_CAPM関数を各グループに適用\n\nという処理を行っています。\n\nME_sorted_portfolio_splitted <- split(ME_sorted_portfolio, ME_sorted_portfolio$ME_rank10) # データを分割してリスト型に\n# 独自関数を定義\nestimate_CAPM <- function(return_data) {\n  lm_results <- lm(Re ~ R_Me, data = return_data) # 線形回帰\n  tidied_lm_results <- tidy(lm_results) # tidy()関数でデータ整形\n}\n\nCAPM_results_by_lapply <- lapply(ME_sorted_portfolio_splitted, estimate_CAPM) #\n\nforループに比べて，ソースコードがかなりシンプルになったかと思います。\n\n\npurrrのmap()関数を使う方法\ntidyverseのpurrrパッケージのmap()関数を使ってグループごとに処理を繰り返す方法について説明します。 purrrパッケージは，tidyverseの1つで，リスト型オブジェクトに対して処理を繰り返す関数を提供しています。 基本関数のapply系関数よりも，purrrパッケージのmap()関数を使った方が，コードがシンプルになり読みやすくなります。\n以下では，purrrのmap()関数を使って時価総額ランクごとに線形回帰を行います。 以下では，グループごとにデータを分割し、分割されたデータを各セルに埋め込むnest()関数を使って，ME_rank10ごとにグループ化しています。 group_by()とnest()をまとめたgroup_nest()関数を使います。\n\nME_sorted_portfolio %>%\n  group_nest(ME_rank10) %>% # ランクごとにグループ化しセルに埋め込む\n  mutate(\n    CAPM_regression = map(data, ~lm(Re ~ R_Me, data = .)), # 回帰\n    CAPM_summary = map(CAPM_regression, tidy) # tidy()を適用\n    ) %>% # tidy()関数を用いて線形回帰の結果を整理\n  select(-c(data, CAPM_regression)) %>% # 線形回帰の結果のみを抽出\n  unnest(cols = CAPM_summary) %>% # nest()関数による畳み込みを解除\n  ungroup()\n\n# A tibble: 20 × 6\n   ME_rank10 term         estimate std.error statistic  p.value\n   <fct>     <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n 1 1         (Intercept)  0.0121     0.00404     3.00  3.95e- 3\n 2 1         R_Me         0.654      0.0976      6.70  9.37e- 9\n 3 2         (Intercept)  0.0106     0.00375     2.83  6.44e- 3\n 4 2         R_Me         0.711      0.0908      7.83  1.19e-10\n 5 3         (Intercept)  0.0120     0.00312     3.86  2.90e- 4\n 6 3         R_Me         0.770      0.0754     10.2   1.42e-14\n 7 4         (Intercept)  0.00957    0.00289     3.31  1.62e- 3\n 8 4         R_Me         0.848      0.0699     12.1   1.54e-17\n 9 5         (Intercept)  0.00728    0.00234     3.11  2.86e- 3\n10 5         R_Me         0.896      0.0565     15.9   9.35e-23\n11 6         (Intercept)  0.00653    0.00195     3.34  1.45e- 3\n12 6         R_Me         0.904      0.0472     19.2   9.39e-27\n13 7         (Intercept)  0.00284    0.00173     1.64  1.06e- 1\n14 7         R_Me         0.943      0.0418     22.6   2.16e-30\n15 8         (Intercept)  0.00122    0.00168     0.723 4.73e- 1\n16 8         R_Me         0.956      0.0407     23.5   2.59e-31\n17 9         (Intercept)  0.000406   0.00144     0.282 7.79e- 1\n18 9         R_Me         1.03       0.0349     29.5   1.33e-36\n19 10        (Intercept) -0.000659   0.00113    -0.582 5.63e- 1\n20 10        R_Me         1.06       0.0273     38.9   2.93e-43\n\n\nこれで，時価総額ランク1〜10ごとに線形回帰を行った結果，切片(Intercept)と説明変数R_Meの係数estimate，標準誤差std.error，t値statistic，p値p.valueが計算されています。\n\n\n\n6.2.4 CAPMアルファ\nCAPMが成立している世界では，\\alpha _Pはゼロとなるはずです。 そこで，時価総額ランクに応じて10個に分けた企業群ごとの\\alpha _Pを図示してみます。\n\n# : CAPMアルファの可視化\n\ndf_g <- CAPM_results %>%\n  filter(term == \"(Intercept)\") %>% # 切片を抽出\n  mutate(ME_rank10 = as.factor(ME_rank10)) # ME_rank10をファクター型\ng <- ggplot(df_g) + aes(x = ME_rank10, y = estimate)\ng <- g + geom_col() + geom_hline(yintercept = 0)\ng <- g + xlab(\"時価総額ランク\") + ylab(\"CAPMアルファ\")\ng <- g + scale_y_continuous(limits = c(-0.003, 0.013)) + mystyle\nprint(g)\n\n\n\n\n小型株ほどCAPMアルファが高く，時価総額が大きくなるにつれて\\alpha _Pがゼロに近づいていることが分かります。 各グループの回帰分析の切片が統計的にゼロかどうかを確認するために、検定してみます。\n\n# : CAPMアルファの統計的な有意性を評価\n\nCAPM_results %>%\n  filter(term == \"(Intercept)\") %>% # 定数項に関する推定結果のみを抽出\n  rename(CAPM_alpha = estimate, p_value = p.value) %>% # 列名を変更\n  mutate(significance = cut(p_value,\n                            breaks = c(0, 0.01, 0.05, 0.1, 1),\n                            labels = c(\"***\", \"**\", \"*\", \"\"),\n                            include.lowest = TRUE)) %>% # 統計的に有意な結果を*で強調\n  select(ME_rank10, CAPM_alpha, p_value, significance) # 出力したい列を指定\n\n# A tibble: 10 × 4\n   ME_rank10 CAPM_alpha  p_value significance\n       <int>      <dbl>    <dbl> <fct>       \n 1         1   0.0121   0.00395  \"***\"       \n 2         2   0.0106   0.00644  \"***\"       \n 3         3   0.0120   0.000290 \"***\"       \n 4         4   0.00957  0.00162  \"***\"       \n 5         5   0.00728  0.00286  \"***\"       \n 6         6   0.00653  0.00145  \"***\"       \n 7         7   0.00284  0.106    \"\"          \n 8         8   0.00122  0.473    \"\"          \n 9         9   0.000406 0.779    \"\"          \n10        10  -0.000659 0.563    \"\"          \n\n\n分析結果より，ME_rank10が7から10のグループでは，CAPMアルファはp統計量が10%以上となっており，統計的にゼロと異なっているかどうか分かりません。\n次に，R_Meの回帰係数を取り出し，CAPM_betaという列名に変更します。\n\n# : 証券市場線の推定\n\nME_cross_sectional_return <- CAPM_results %>%\n  filter(term == \"R_Me\") %>% # R_Meの係数に関する推定結果のみを抽出\n  rename(CAPM_beta = estimate) %>% # 推定値をestimateからCAPM_betaに名称変更\n  select(ME_rank10, CAPM_beta) %>%\n  mutate(ME_rank10 = as.factor(ME_rank10)) %>% # ME_rank10を整数型からファクター型に\n  full_join(ME_cross_sectional_return, ., by = \"ME_rank10\") # 超過リターンのデータと結合\n\nmean_R_Me <- mean(factor_data$R_Me) # 市場ポートフォリオの実現超過リターンにより証券市場線の傾きを推定\n\ng <- ggplot(ME_cross_sectional_return) + aes(x = CAPM_beta, y = mean_Re)\ng <- g + geom_point() + geom_abline(intercept = 0, slope = mean_R_Me)\ng <- g + xlab(\"市場ベータ\") + ylab(\"平均超過リターン\")\ng <- g + scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0))\ng <- g + scale_y_continuous(limits = c(0, 0.02)) + mystyle\nprint(g)"
  },
  {
    "objectID": "Chap06.html#パフォーマンス評価尺度としてのアルファ",
    "href": "Chap06.html#パフォーマンス評価尺度としてのアルファ",
    "title": "6  ファクターモデルの導入",
    "section": "6.4 パフォーマンス評価尺度としてのアルファ",
    "text": "6.4 パフォーマンス評価尺度としてのアルファ"
  }
]