[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "実証会計・ファイナンスのノート",
    "section": "",
    "text": "この資料は、笠原・村宮 (2022)「実証会計・ファイナンス」をゼミで輪読した際に使用した講義ノートである。本資料の内容は、上記教科書の内容を補足するために作成したもので、基本的には笠原・村宮本の章立てに沿っています。\nただし、本資料の内容は、笠原・村宮本の内容を簡略化しつつ、内容を補足するために作成したものですので、本資料だけで笠原・村宮本の内容を理解することは不可能です。 従って、本資料を理解するためには、笠原・村宮本を読むことを強く推奨します。"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Chap02.html",
    "href": "Chap02.html",
    "title": "1  第2章 ファイナンス入門",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n 次のパッケージを付け加えます: 'plotly' \n\n\n 以下のオブジェクトは 'package:ggplot2' からマスクされています:\n\n    last_plot\n\n\n 以下のオブジェクトは 'package:stats' からマスクされています:\n\n    filter\n\n\n 以下のオブジェクトは 'package:graphics' からマスクされています:\n\n    layout"
  },
  {
    "objectID": "Chap02.html#割引率",
    "href": "Chap02.html#割引率",
    "title": "2  ファイナンス入門",
    "section": "2.1 割引率",
    "text": "2.1 割引率\nファイナンスでは，ある財の今の価値と将来の価値は異なる，という考えが基礎にあります。 今の100万円と1年後の100万円の価値は異なるのです。 この現在の価値と未来の価値をつなぐ概念を割引率(discount rate)といい，将来キャッシュ・フローを現在価値(present value)に変換する際に用いる値です。 ファイナンス(finance)という学問は、この割引率がどのように決まるのかを明らかにする研究分野であるといえます。\n\n2.1.1 確実なキャッシュ・フローに対する割引率\nまず、確実に得られるキャッシュ・フローに対する割引率を考えてみましょう。 確実に得られる、とは特定の結果が確率1で実現することを意味します。\n用語の意味は以下の通りです。\n\n現在価値 ：一般に将来発生するキャッシュフローの現時点における価値\n時間価値 ：将来と現在の価値の違い\n無リスク金利 (risk-free rate) ：安全資産(無リスク資産)へと投資したときのリターンであり，安全資産への投資時点でリターンとして獲得できる額が確定します。 無リスク金利は確率変数ではなく定数(parameter)として扱います。\n\nT年後の確実なキャッシュフローをCF_Tで表し，無リスク割引率を無リスク金利R_Fとすると，その現在価値は以下のように計算されます。\n\nPV = \\frac{CF_T}{(1 + R_F)^T}\n\n\n\n\n\n\n\nノート\n\n\n\n現時点でCF_0を1年間貯金する。利息rは0.1とします。 1年後に受け取れるキャッシュフローCF_1は、貯金した元本CF_0と利息CF_0 \\times 0.1となります。 つまり、CF_0 + CF_0 \\times 0.1 = (1+0.1)CF_0です。\n逆に、来年CF_1受け取るためには、今いくら貯金するかを考えてみましょう。 必要な貯金額をXとすると、X \\times (1 + 0.1) = CF_1となる。つまりX = CF_1/ (1.1)となります。 これが現在価値(present value)です。\n\n\n将来の確実なキャッシュ・フローCF_Tの現在価値は、無リスク割引率R_Fと将来受け取る時点であるTに依存して決まります。 CF_T = 100の場合、R_FとTの変化に応じて現在価値がどのように変化するのか確認してみましょう。\nT=1として(時点を固定して)、横軸を無リスク割引率R_F、縦軸を現在価値PVとしたグラフが以下のものです。 割引率が大きくなるにつれて現在価値が小さくなることが分かります。\n\nT = 1 # 時点を1とする\nR_F <- c(0.01, seq(0.1,1, by = 0.01)) #0.1から1の間を0.01刻みで変化\nPV <- 100/(1+R_F)^T # 現在価値\ndf <- data.frame(R_F, PV) # データフレームの作成\n# 作図\nggplot(df) + aes(x = R_F, y = PV) + geom_line(color = \"blue\") +\n  xlab(\"割引率\") + ylab(\"現在価値\") + mystyle\n\n\n\n\n次に、無リスク利子率R_F = 0.1として、横軸を時点T、縦軸を現在価値PVとしてグラフが以下のものです。 キャッシュ・フローCFを受け取る時点が遠くなるほど(T\\rightarrow \\infty)、現在価値が小さくなる(PV \\rightarrow 0)ことがわかります。\n\nR_F <- 0.1\nT <- c(seq(0,10, by = 0.1))\nPV <- 100/(1 + R_F)^T\ndf <- data.frame(T, PV)\nggplot(df) + aes(x = T, y = PV) + geom_line(color = \"red\") +\n  xlab(\"T年後\") + ylab(\"現在価値\") + mystyle\n\n\n\n\n\n\n2.1.2 不確実なキャッシュ・フローに対する割引率\nリスクプレミアム(risk premium)の反映が割引率の2つ目の役割です。 普通、将来に得られるキャッシュ・フローCFがいくらになるのか分かりませんし、将来CFは様々な要因に影響を受けて変化する確率変数(random variable)ですので、現時点における期待値(expected value)で評価することにします。\n\n\n\n\n\n\n期待値\n\n\n\nここで、期待値をとる演算子(operator)を\\mathbb{E}で表し、期待値をとる時点を添え字で表す。ここでは現時点t=0における期待値を\\mathbb{E}_0と表現している。 たとえば，現時点をt=0として，1期先に起こりうる結果Xが100か200であることが分かっていて，それぞれの発生確率が50%であったとする。この将来に起こりうる結果を現時点での情報を基に期待値をとる，ということは， \n\\mathbb{E}[X] = 0.5 \\times 100 + 0.5 \\times 200 = 150\n となる。このように起こりうる結果と発生確率を掛けて足したものを期待値という。\n\n\nリスクプレミアム(risk premium)は割引率の調整で定量化されます。 つまり、リスクの高い投資に対しては無リスク利子率R_Fにリスクプレミアムを加えたリスク調整済みの割引率を用いることになります。\n\nPV_0 = \\frac{\\mathbb{E_0}[\\tilde {CF}_1]}{1+R_F+\\underbrace{(\\tilde{R}-R_F)}_{\\text{リスクプレミアム}}}=\\frac{\\mathbb{E_0}[\\tilde {CF}_1]}{\\underbrace{1+\\tilde{R}}_{\\text{リスク調整済み割引率}}}\n\n割引率は時間価値やリスクプレミアムに関する定量的な情報を含むので、タイミングやリスクの異なるキャッシュフローを現在価値という同一の尺度で評価できるようになります。\n\n\n2.1.3 NPV法\nNPV法とは、割引現在価値(net present value: 以下NPV)を基準に投資の意思決定を行う考え方をいう。\n投資を目論む現時点を時点0とする。 0時点におけるキャッシュ・フローCF_0は初期投資を意味します。 つまり企業の財布から現金が減るためマイナスとなります。\n向こうT年間にわたり毎年\\mathbb{E}[\\tilde{CF}_t],\\quad t = 1,\\dots ,Tの期待キャッシュフローが生み出されるならば、それらを割引率1 + \\tilde{R}で現在価値に直して足し合わせた値(つまりNPV)が、現時点で評価したプロジェクトの成果となります。\nNPVはそのプロジェクトから発生するすべてのキャッシュフローの現在価値として解釈できます。 コーポレートファイナンスでは，\n\nNPVがゼロ以上のプロジェクトは投資を実行\nNPVが負のプロジェクトは投資を見送る\n\nことで企業価値を最大化する投資を行うことになります。\n\n\n\n\n\n\n例: プロジェクトA\n\n\n\n\n現時点(t=0)で280万円の初期投資が必要\n1年後に 115万円の期待キャッシュフロー\n2年後に 264.5万円の期待キャッシュフロー\n無リスク金利 0.1，リスクプレミアム0.05とするときの割引率0.15\n\nプロジェクトの成果を将来キャッシュフローの現在価値によって評価する。 2年分の将来キャッシュフローの現在価値を足し合わせて300万円\n\n\\text{プロジェクトAの成果} = \\frac{115}{1.15}+\\frac{264.5}{1.15^2}=300\n\nよって、NPV = -280 + 300 = 20 >0\n\n\n一般的なNPV法は以下のようにかかれる。 \n\\begin{aligned}\nNPV_0 &= \\frac{CF_0}{(1+\\tilde{R})^0}+\\frac{\\mathbb{E}[CF_1]}{(1+\\tilde{R})^1}+\\frac{\\mathbb{E}[CF_2]}{(1+\\tilde{R})^2}+ \\cdots +\\frac{\\mathbb{E}[CF_T]}{(1+\\tilde{R})^T}\\\\\n&= \\underbrace{CF_0}_{\\tiny 初期投資額}+\n\\underbrace{\\sum_{t=1}^T\\frac{\\mathbb{E}[CF_t]}{(1+\\tilde{R})^t}}_{\\tiny 現時点で評価した成果}\n\\end{aligned}\n\n\n\n2.1.4 配当割引モデル\nNPVの考え方を株式に適用する。株式から生み出される将来得られるキャッシュ・フローは、一株当たり配当(Dividend Per Share: DPS)であり、t時点の一株当たり配当をD_tで表す。 将来DPSは確率変数であるため期待値で考え、それを割引率\\tilde{R}で割り引くことで、一株当たりの株式価値を求める。\n\n\\begin{aligned}\nP_0^* &= \\frac{\\mathbb{E_0}[D_1]}{1 + \\tilde R} + \\frac{\\mathbb{E_0}[D_2]}{(1 + \\tilde R)^2} + \\cdots + \\frac{\\mathbb{E_0}[D_{\\infty}]}{(1 + \\tilde R)^{\\infty}} \\\\\n&= \\sum^{\\infty}_{t=1}\\frac{\\mathbb{E_0}[D_t]}{(1+\\tilde{R})^t}\n\\end{aligned}\n\n\n\n2.1.5 ゴードン成長モデル\n期待DPSが一定の割合で成長していくと仮定した割引配当モデルをゴードン成長モデルという。 直近の実現したDPSをD_0と置き、将来にわたってこの配当の期待値が一定割合G%で成長していくと仮定する。つまり1時点先の配当額が(1 + G)D_0となる、と仮定する。 すると、t時点先の配当額\\mathbb{E}[D_t]は、 \n\\begin{aligned}\n\\mathbb{E}[D_t] &= D_0 \\times \\underbrace{(1+G) \\times \\cdots \\times (1+G)}_{複利でt回}\\\\\n&= (1+G)^tD_0\n\\end{aligned}\n で表すことができる。 一定割合で配当額が成長する株式の理論価値P_0を配当割引モデルで計算すると， \n\\begin{aligned}\nP_0 &= \\frac{(1+G) D_0}{(1+\\tilde{R})} + \\frac{(1+G)^2 D_0}{(1+\\tilde{R})^3} + \\frac{(1+G)^3 D_0}{(1+\\tilde{R})^3} + \\cdots \\\\\n    &= \\sum^{\\infty}_{t=1}\\frac{(1+G)^tD_0}{(1+\\tilde{R})^t} \\\\\n    &=\\frac{(1+G)D_0}{\\tilde{R}-G}\n\\end{aligned}\n 2本目の式から3本目の式への計算で、等比級数の和の公式を利用している。\n\n\n\n\n\n\nノート\n\n\n\n初項a，公比rの等比数列 \na, ar, ar^2, ar^3, \\dots , ar^{n-1},ar^n , \\dots\n がある。この等比数列の和をS_nで表す。 \nS_n = a + ar + ar^2 + \\cdots + ar^{n-1} + \\cdots\n 両辺にrを乗じると， \nrS_n =  ar + ar^2 + \\cdots + ar^{n-1} + ar^{n} + \\cdots\n となる。そして，S_n - rS_nを計算すると， \n\\begin{aligned}\nS_n - r S_n &= a\\\\\n(1-r)S_n &= a\\\\\nS_n &= \\frac{a}{1-r}\n\\end{aligned}\n 上のゴードン成長モデルの初項は(1+G)D_0/(1+\\tilde R)，公比は(1 +G)/(1+\\tilde R)なので， \n\\begin{aligned}\nS_n\n%P_0^* &= \\frac{(1+G)D_0}{1+ \\tilde R} + \\frac{(1+G)^2 D_0}{(1+ \\tilde R)^2} + \\frac{(1+G)^3 D_0}{(1+ \\tilde R)^3} + \\cdots \\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)D_0}{(1 + \\tilde R)}}{1 - \\frac{1+G}{1+\\tilde R}}\\\\\n&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\tilde R)}D_0}{\\frac{(1+ \\tilde R) - (1+G)}{1+\\tilde R}}\\\\\n%&= \\displaystyle  \\frac{\\frac{(1+G)}{(1 + \\tilde R)}D_0}{\\frac{\\tilde R - G}{1+\\tilde R}}\\\\\n&= \\displaystyle  \\frac{1+G}{\\tilde R - G}D_0\\\\\n\\end{aligned}\n ただし，\\tilde{R} \\not = Gの場合のみである。\n\n\n\n\n2.1.6 割引率と期待リターンの関係\n割引率Rは投資家が将来キャッシュフローを購入するにあたって最低限要求する期待リターン(要求収益率)とも解釈できる。\n\n\n\n\n\n\n例\n\n\n\n1年後の期待DPSが100万円で配当支払後に即解散する予定(=DPSがゼロ)の企業の理論株価を考える。 たとえば，確率50%で配当が200となるが，確率50％で配当が0となる株式を考えてみる。期待配当は，0.5 \\times 200 + 0.5 \\times 0 = 100となる。\nリスク調整済みの割引率r = 0.25であるときの現在価値は100/(1 + 0.25)で理論株価は80万円となる。 この株式を購入するか検討している投資家にとって、「現時点でこの株式を購入し、1年後に配当を受け取ることは一種の投資プロジェクト」とみなせる。 この投資プロジェクトに対して必要な投資額は現時点の株価P_0であり、現時点で評価した成果は配当として受け取り予定の将来キャッシュフローの現在価値P^*_0である。 よって、 \nNPV = -P_0 + P_0^*\n したがって、市場価値が理論株価以下である限り、NPVが非負となるためこの株式を購入することが経済合理的である。 \nNPV  \\geq 0 \\Leftrightarrow P_0 \\leq P^*_0 =80\n つまり株式を80未満の価格で購入できれば、NPVがプラスとなる。"
  },
  {
    "objectID": "Chap02.html#平均分散アプローチ入門",
    "href": "Chap02.html#平均分散アプローチ入門",
    "title": "2  ファイナンス入門",
    "section": "2.2 平均分散アプローチ入門",
    "text": "2.2 平均分散アプローチ入門\n個々の投資家にとって最適となる証券の組み合わせの比率を決めることを最適ポートフォリオ選択という。 分散投資によりリスクを逓減できる、という現象がなぜ生じるのかを、数理的に明らかにする。 このアプローチを平均・分散アプローチといい、ポートフォリオの望ましさを、ポートフォリオのリターンの期待値と分散で評価する。\n\n2.2.1 ポートフォリオのリスクとリターン\nいま、銘柄Aと銘柄Bの2銘柄のみが投資対象である場合を考える。 それぞれの銘柄への投資割合をw_Aとw_Bとし、w_A + w_B = 1とする。\n\n元本 X\n投資銘柄Aのリターン 1 + R_A\n投資銘柄Bのリターン 1 + R_B\n\n元本Xのうちw_A分だけ銘柄Aに投資すると、1年後に期待値で\\mathbb{E}[X \\times w_A \\times (1+R_A)]になる。銘柄Bについても同様に考えると、手元にある元本を全額銘柄AとBに振り分けると、 \n\\begin{aligned}\n(1+R_A) w_A X + ( 1 + R_B) w_B X\n&= w_AX + w_AR_AX + w_BX + w_B R_B X\\\\\n&= \\left [\\underbrace{(w_A+w_B)}_{\\text{定義より} = 1}+(w_AR_A+w_BR_B) \\right ]X\\\\&=(1+w_AR_A+w_BR_B)X\n\\end{aligned}\n となる。元本を2銘柄に投資すると、1年後に(1+w_AR_A+w_BR_B)Xとなる。 1年後の価値と初期投資額の比としてこのポートフォリオのリターンR_Pを計算する。 \n\\begin{aligned}\n\\frac{\\overbrace{(1+R_A)w_AX+(1+R_B)w_BX}^{将来時点の評価額}}{\\underbrace{X}_{初期投資}} & = 1 + w_A R_A + w_B R_B\n\\end{aligned}\n ここで、w_AR_A + w_B R_B = R_Pとおくと、 \n\\text{ポートフォリオのリターン} = 1 + R_P\n となる。 元本を除いたポートフォリオのリターンR_Pは、構成銘柄のリターンを保有比率で加重平均した値となる。\n\n\n\n\n\n\nノート\n\n\n\nリターンの定義(P_t - P_{t-1})/P_{t-1} = P_t/P_{t-1} -1はネット・リターン(net return)と呼ばれるものである。 これにたいして，元本も含めたリターン1 + R_t = P_t/P_{t-1}はグロス・リターン(gross return)という。\n\n\nポートフォリオ構築時には、各銘柄の実現リターンはわからないので(つまり確率変数)、かわりに期待値や分散を評価する。\n銘柄Aと銘柄Bのネット・リターンの\n\n期待値\\mathbb{E}[R_A]と\\mathbb{E}[R_B]をそれぞれ(\\mu_A,\\mu_B)\n分散\\mathbb{V}[R_A]と\\mathbb{V}[R_B]をそれぞれ(\\sigma^2_A,\\sigma^2_B)\n共分散\\mathbb{Cov}[R_A, R_B]を\\sigma_{AB}\n\nで表す。\nリターンR_AとR_Bの相関係数を\\rhoと表記する。相関係数の定義から、 \n\\begin{aligned}\n\\rho\n%&= \\frac{\\mathbb{E}[(R_A - \\bar R_A)(R_B - \\bar R_B)]}{\\mathbb{E}[(R_A - \\bar R_A)^2]}\n&= \\frac{\\sigma _{AB}}{\\sigma _A \\sigma _B} \\\\\n\\Leftrightarrow \\sigma_{AB} & = \\rho\\sigma_A\\sigma_B\n\\end{aligned}\n が成立する。\n上の式より、R_P = w_A R_A + w_B R_Bであるから、その期待値\\mathbb{E}[R_P] = \\mu_Pも各銘柄の期待リターンの加重平均となる。ここで投資割合w_Aとw_Bはパラメータであり，R_A, R_Bは確率変数である。 \n\\begin{aligned}\n\\mathbb{E}[R_p] = \\mu_P &= \\mathbb{E}[w_A R_A + w_B R_B]\\\\\n&= w_A \\mathbb{E}[R_A] + w_B \\mathbb{E}[R_B]\\\\\n&=w_A\\mu_A+w_B\\mu_B\n\\end{aligned}\n\nポートフォリオPの分散\\mathbb{V}[R_P] = \\sigma^2_Pは各銘柄の分散及び相関係数を用いて計算できる。\n\n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma_P^2 &= \\mathbb{V}[w_A R_A + w_B R_B]\\\\\n&= w_A^2 \\mathbb{V}[R_A] + w_b^2 \\mathbb{V}[R_B] + 2 w_A w_B \\mathbb{Cov}[R_A,R_B]\\\\\n&= w_A^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2w_A w_B \\sigma _{AB}\\\\\n&= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B +\n\\underbrace{2 w_A w_B \\rho \\sigma_A \\sigma_B}_{ここの\\rho の符号が重要}\n\\end{aligned}\n\nポートフォリオPの分散は，各銘柄の分散に投資割合の二乗を乗じたものに，各銘柄のリターンの相関関係部分を加えたものとなっている。 つまり，この2銘柄のリターンの相関係数\\rhoに応じて，ポートフォリオPの分散が大きくなるかどうかが決まる，ということである。\n\n\n2.2.2 分散投資のメリット\n保有比率(w_A,w_B)を変化させたときのポートフォリオの\\mu_Pと\\sigma_Pがそのように変化するかを確認する。\n\n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma_P^2 &= w^2_A \\sigma^2_A + w^2_B \\sigma^2_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n&= (w_A \\sigma_A + w_B \\sigma_B)^2 - 2w_A  w_B \\sigma _A \\sigma_B + 2\\rho{w_Aw_B\\sigma_A\\sigma_B}\\\\\n&= (w_A \\sigma_A + w_B \\sigma_B)^2 - (2 + 2\\rho ) w_A w_B\\sigma_A\\sigma_B\\\\\n&=(w_{A} \\sigma_{A} + w_{B}\\sigma_{B})^{2} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{ここ重要}\n\\end{aligned}\n 0 \\leq w_{A} \\leq 1かつ 0 \\leq w_{B} \\leq 1のとき、 \n2 ( 1- \\rho ) w_A w_b \\sigma _A \\sigma _B \\geq 0\n となる(\\rho = 1のときのみ0となる)。 したがって、 \n\\begin{aligned}\n\\sigma_P^2 = (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} - \\underbrace{2(1-\\rho )w_{A}w_{B} \\sigma_{A}\\sigma_{B}}_{\\geq 0}\n\\end{aligned}\n から、 \n\\begin{aligned}\n& \\sigma _P^2 \\leq (w_A \\sigma _A + w_B \\sigma _B)^2 \\\\\n\\Longleftrightarrow & \\sigma_{P}  \\leq\n\\underbrace{w_{A}\\sigma_{A}+w_{B}\\sigma_{B}}_{リスクの加重平均}\n\\end{aligned}\n となり，ポートフォリオのリスクを表す標準偏差\\sigma_Pが銘柄AとBの標準偏差の加重平均w_{A}\\sigma_{A} + w_{B} \\sigma_{B}より少なくとも低くなることがわかる。 これを分散投資効果という。\n\n# text p.65\n# 設定\nrho = 0.2\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(0,1,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb * mu_B,\n  sigma_p = sqrt(wa^2 * sigma_A^2 + wb^2 * sigma_B^2 + 2 * rho * wa * wb * sigma_A * sigma_B),\n  label= c(\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\")\n  )\n\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n完全な負の相関(\\rho=-1)であるの場合、\\sigma^{2}_{P}=0のポートフォリオを構築できる。 確認のため、2銘柄の価格が完全な負の相関\\rho = -1をもつとき、ポートフォリオPのリスク\\sigma_Pは \n\\begin{aligned}\n\\mathbb{V}[R_P] = \\sigma ^2_P &=(w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2}-2(1- (-1))w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= (w_{A}\\sigma_{A}+w_{B}\\sigma_{B})^{2} -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 + w_B^2\\sigma _B^2 + 2w_A w_B \\sigma_A \\sigma_B -4w_{A}w_{B} \\sigma_{A}\\sigma_{B}\\\\\n&= w_A ^2 \\sigma _A^2 - 2w_{A}w_{B} \\sigma_{A}\\sigma_{B} + w_B^2\\sigma _B^2 \\\\\n&= (w_{A}\\sigma_{A} - w_{B}\\sigma_{B})^{2}\\\\\n\\sigma _P &= | w_{A}\\sigma_{A} - w_{B}\\sigma_{B}|\n\\end{aligned}\n\n以下のように，w_A \\sigma _A = w_B \\sigma_Bとなるようにw_Aとw_Bを選べば、\\sigma _P = 0となるポートフォリオを作れる。\n\n# text p.65\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n\nwa <- seq(0,1,by = 0.01)\nwb <- 1 - wa\n\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb*mu_B,\n  sigma_p = abs(wa*sigma_A - wb*sigma_B),\n  label= c(\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\")\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\nこのケースでは、\\sigma_A = 0.2、\\sigma_B = 0.3となっているため、0.2w_A = 0.3w_Bとなる保有割合を考える。 \n\\begin{aligned}\n0.2 w_A &= 0.3w_B\\\\\n0.2 w_A &= 0.3(1-w_A)\\\\\n0.2 w_A &= 0.3 - 0.3w_A\\\\\n0.5 w_A &= 0.3\\\\\nw_A &= 0.6\n\\end{aligned}\n となるため、銘柄Aに60％、銘柄Bに40%を投資することで、リスクゼロで期待リターン0.6\\times0.1 + 0.4 \\times 0.2 = 0.14を獲得することができる。\n\n\n2.2.3 空売りの効果\n空売り(short sale)とは、 1. 保有していない証券を誰か(普通は証券会社)から借りてきて売却し、 2. 一定期間後に買い戻して元の持ち主に返却する 取引をいい、値下がりから利益を得る。 空売りを行う投資家をショートセラー(short seller)という。\nいままでは、0 \\leq w_A,w_B \\geq 1＄という制約を置いていたが、この制約をはずして、 w_A + w_B = 1のみを課す。つまりw_A<0やw_B<0が空売りを表す。\n\nrho = 0.2\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = wa * mu_A + wb*mu_B,\n  sigma_p = sqrt(wa^2 * sigma_A^2 + wb^2 * sigma_B^2 + 2 * rho * wa * wb * sigma_A * sigma_B),\n  label= c(\n  rep(\"\",100),\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\" , rep(\"\",100)\n  )\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n\n\n2.2.4 安全資産の導入\n安全資産の購入についても考える。\n安全資産FのリターンをR_F、 ポートフォリオPの保有比率をw_Fとおく（安全資産のリターンは確実に実現する成果なので，確率変数を表すチルダをつけてない）。 以降は，確率変数にはなるべくチルダをつける。銘柄Aと銘柄Bと安全資産の投資割合をそれぞれw_A, w_B, w_Fで表す。\nまず銘柄Aと安全資産の2資産からなるポートフォリオを考える。 つまり各資産への投資割合をw_A + w_F = 1,\\quad w_B = 0 とする場合を考える。 この安全資産と銘柄AからなるポートフォリオPの(ネット)リターン\\tilde R_Pは， \n\\tilde R_{P} = w_{F} R_{F} + w_{A} \\tilde R_{A}\n となり，このポートフォリオの期待値は， \n\\begin{aligned}\n\\mu_{P} =\\mathbb{E}[R_P] &=\\mathbb{E}[ w_F R_{F} + w_{A} \\tilde{R_A} ]\\\\\n&=w_F R_{F}+w_{A} \\mathbb{E}[\\tilde{R_A}]\\\\\n&=w_F R_{F}+w_{A} \\mu_{A}\\\\\n&=(1-w_A) R_{F}+w_{A} \\mu_{A}\\\\\n&=R_{F} - w_{A}R_F + w_A\\mu_A\\\\\n&=R_{F} + w_A(\\underbrace{\\mu_A - R_F}_{\\tiny リスクプレミアム})\n\\end{aligned}\n\nとなる。もちろん安全資産のリターンは確率変数でないので，期待値をとってもそのままである。 \\mu_{A}-R_{F} はリスク資産である銘柄Aのリスクプレミアムを表している。通常，リスクのある資産の期待リターンは安全資産のリターンより大きいため，リスクプレミアムは正の値となる。したがって，リスク資産への投資割合w_Aを1単位増加させれば，\\mathbb{E}[R_P]はリスクプレミアム分増加する\nつぎに，ポートフォリオのリスクを表す標準偏差\\sigma _Pとリターンの関係は次式で表せる。まず安全資産のリスクはゼロであるため，リスク資産の銘柄Ａを保有する分だけリスクが生じる。\nつぎに，ポートフォリオのリスクを表す標準偏差\\sigma _Pとリターンの関係は次式で表せる。まず安全資産のリスクはゼロであるため，リスク資産の銘柄Ａを保有する分だけリスクが生じる。\n\n\\begin{aligned}\n\\sigma_P^2 = \\mathbb{V}[R_P]  &= \\mathbb{V}[w_FR_F + w_A R_A]\\\\\n&= \\mathbb{V}[w_A R_A]\\\\\n&= w_A^2 \\mathbb{V}[R_A]\\\\\n&= w_A^2 \\sigma _A^2 \\\\\n\\sigma _P & = |w_A| \\sigma_A\n\\end{aligned}\n\n空売りを想定する場合w_A < 0となるため，標準偏差を求める際に絶対値をとっている。空売りはない状況（つまり，w_A>0）を想定すると，\n\n\\begin{aligned}\n\\sigma _P = w_A \\sigma _A\\\\\nw_A = \\frac{\\sigma_P}{\\sigma _A}\n\\end{aligned}\n\nのように，リスク資産である銘柄Aへの投資割合w_Aが，ポートフォリオPとリスク資産Aのリスクの割合で決定されることがわかる。これを，ポートフォリオの期待リターン\\mu_Pに代入すると，\n\n\\begin{aligned}\n\\mu_{P} &= R_F + w_A(\\mu_A - R_F)\\\\\n& = R_F + \\frac{\\sigma_P}{\\sigma _A}(\\mu_A - R_F) \\\\\n&= R_{F}+\\frac{\\mu_{A}-R_{F}}{\\sigma_{A}}\\sigma_{P}\n\\end{aligned}\n\nとなり，期待リターン\\mu_Pは，切片がR_F，傾きが(\\mu_A - R_F)/\\sigma_Aとする\\sigma_Pの線形関数となる。\n\nR_F = 0.01\nmu_A <- 0.1\nsigma_A <- 0.2\nmu_B <- 0.2\nsigma_B <- 0.3\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = R_F + wa*(mu_A - R_F),\n  sigma_p = abs(wa)*sigma_A,\n  label= c(\n  rep(\"\",100),\n  \"0,1\", rep(\"\", 9),\n  \"0.1,0.9\",rep(\"\", 9),\n  \"0.2,0.8\",rep(\"\", 9),\n  \"0.3,0.7\",rep(\"\", 9),\n  \"0.4,0.6\",rep(\"\", 9),\n  \"0.5,0.5\",rep(\"\", 9),\n  \"0.6,0.4\",rep(\"\", 9),\n  \"0.7,0.3\",rep(\"\", 9),\n  \"0.8,0.2\",rep(\"\", 9),\n  \"0.9,0.1\",rep(\"\", 9),\n  \"1,0\" , rep(\"\",100)\n  )\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line() + geom_point(data = filter(df, label != \"\"), aes(label = label), size = 2) + coord_flip() + mystyle\n\n\n\n\n\n\n2.2.5 3資産のポートフォリオ\nリスク資産AとB，安全資産Fの3資産に投資するポートフォリオを考える。 ここで，w_A + w_B > 0を仮定し，少なくとも少しはリスク資産を保有するケースを考える。 当然だけれど，w_A = w_B =0のケースでは，安全資産のみを保有するケースとなり，リスクも無く，リターンも確定している。\n3資産A,B,Fへの投資割合をそれぞれw_A，w_B,w_Fとすると， 3資産からなるポートフォリオの期待リターンは次のように計算できる。 \n\\begin{aligned}\n\\mathbb{E}[R_{P}] &= w_FR_F + w_A \\mathbb{E} [\\tilde R_A] + w_B \\mathbb{E}[ \\tilde R_B] \\\\\n& =\nw_{F} R_{F} + (w_{A} + w_{B}) \\left(\\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E} [\\tilde R_{A}] + \\frac{w_{B}}{w_{A}+w_{B}} \\mathbb{E}[ \\tilde R_{B} ]\\right)\n\\end{aligned}\n 安全資産への投資割合w_Fとリスク資産への投資割合w_C = w_A + w_Bとまとめて，式を変形させる。 安全資産への投資以外の資金で構築したリスク資産AとBからなるポートフォリオをP_Cを考えると，P_Cの期待リターンR_Cは次のように計算できる。 \n\\begin{aligned}\nR_{C} &= \\frac{w_{A}}{w_{A}+w_{B}} \\mathbb{E}[\\tilde R_{A}] + \\frac{w_{B}}{w_{A}+w_{B}}\\mathbb{E}[ \\tilde R_{B}]\\\\\n\\end{aligned}\n\n安全資産FとポートフォリオCを保有した場合の期待リターンは次式となる。\n\n\\begin{aligned}\n\\mu_{P} & = \\mathbb{E}[w_F R_F + w_A R_A + w_B R_B]\\\\\n&= w_FR_F + w_A \\mathbb{E}[R_A] + w_B \\mathbb{E}[R_B]\\\\\n&= w_FR_F + (w_A + w_B) \\underbrace{ \\left( \\frac{w_A}{w_A + w_B} \\mathbb{E}[R_A] + \\frac{w_B}{w_A + w_B} \\mathbb{E}[R_B] \\right )}_{=w_C\\text{とおく}}\\\\\n&= w_F R_F + w_{C}\\mu_C\n\\end{aligned}\n\n安全資産と2つのリスク資産からなるポートフォリオの期待リターンは，安全資産の期待リターンとリスク資産の期待リターンの和となる。\n安全資産と2つのリスク資産に投資可能な場合，(\\mu_P, \\sigma _P)の取りうる値を図示できる。テキストの数値例を用いてRで図示してみる。\n\nリスク資産Aの期待リターン 0.1，標準偏差 0.2\nリスク資産Bの期待リターン 0.2，標準偏差 0.3\n安全資産の期待リターンを 0.01\nリスク資産AとBの間の相関係数は0.2\n安全資産，銘柄A，銘柄Bへの投資割合を0.2，0.3，0.5とするポートフォリオを考える。このポートフォリオの期待リターン\\mu_Pと標準偏差\\sigma_Pは次のようになる。"
  },
  {
    "objectID": "Chap02.html#最適ポートフォリオ問題",
    "href": "Chap02.html#最適ポートフォリオ問題",
    "title": "2  ファイナンス入門",
    "section": "2.3 最適ポートフォリオ問題",
    "text": "2.3 最適ポートフォリオ問題\n「どのようなポートフォリオが投資家にとって望ましいか」\n一般に、投資家はリスクが小さい一方でリターンが大きいポートフォリオを好む。 ここでは，リターンをポートフォリオの期待リターン\\mu_P，リスクをポートフォリオの標準偏差\\sigma _Pで表し，この2つの変数から更正される平面(\\mu_P, \\sigma_P)上で最適ポートフォリオ問題を分析する。\n\n2.3.1 効率的フロンティア\nリスク資産Aと資産Bにのみ投資可能であり，それぞれに異なる割合で投資したポートフォリオDとＥを比較する(以下の図）\n\n標準偏差はともに0.25 \\sigma _D = \\sigma _E = 0.25\nDの方がEよりも期待リターンが大きい，\\mu _D > \\mu _E\n\nつまり，同じリスク（標準偏差）ならリターン（期待リターン）が高いポートフォリオに投資したほうがよい。よってリスク・リターンのトレードオフの意味でDの方がEよりも望ましい。 以下のグラフでいうと、同じリスク(緑のライン上)なら、リターンの高いポートフォリオが望ましい。そのため赤い実線が効率的フロンティアとなり、青い点線は選択されないポートフォリオになる。\n\n#w<- seq(0, 1, by = 0.01) # 所有ウェイト\nw <- seq(-1,2,by = 0.01)\n\nmu_a    <- 0.1 # 株式Aの期待収益率\nsigma_a <- 0.2 # 株式Aの分散\nmu_b    <- 0.2 # 株式Bの期待収益率\nsigma_b <- 0.3 # 株式Bの分散\nrho     <- 0.2 # 相関係数\nmu_p    <-  w * mu_a + (1 - w) * mu_b # ポートフォリオの期待リターン\nsigma_p <- sqrt((w * sigma_a + (1 - w) * sigma_b)^2 - 2*(1 - rho)*w*(1 - w)*sigma_a*sigma_b) # ポートフォリオの分散\ndf_plot <- data.frame(mu_p, sigma_p)\ndf_plot <- df_plot %>% dplyr::mutate(plus_dummy = as.factor(ifelse(mu_p >= 0.126, 1, 0)))\nggplot(df_plot) + aes(y = sigma_p, x = mu_p, color = plus_dummy, linetype = plus_dummy) +\nscale_linetype_manual(values = c(\"dashed\", \"solid\")) + geom_path() +\ngeom_hline(yintercept = 0.25, color = \"green\") + coord_flip() + mystyle\n\n\n\n\nリスク資産AとBに加え、安全資産Fにも投資可能な場合、効率的フロンティアは直線になる。 この場合、効率的フロンティアは資本市場線(Capital Market Line; CML)とも呼ばれる。 傾きは、この金融市場におけるリスクとリターンのトレードオフを表す。\n\n#w<- seq(0, 1, by = 0.01) # 所有ウェイト\nw <- seq(-1,2,by = 0.01)\n\nmu_a    <- 0.1 # 株式Aの期待収益率\nsigma_a <- 0.2 # 株式Aの分散\nmu_b    <- 0.2 # 株式Bの期待収益率\nsigma_b <- 0.3 # 株式Bの分散\nrho     <- 0.2 # 相関係数\nR_F     <- 0.01 # 無リスク利子率\n\nmu_p    <-  w * mu_a + (1 - w) * mu_b # ポートフォリオの期待リターン\nsigma_p <- sqrt((w * sigma_a + (1 - w) * sigma_b)^2 - 2*(1 - rho)*w*(1 - w)*sigma_a*sigma_b) # ポートフォリオの分散\ndf_plot <- data.frame(mu_p, sigma_p)\ndf_plot <- df_plot %>% dplyr::mutate(plus_dummy = as.factor(ifelse(mu_p >= 0.126, 1, 0)))\n\nggplot(df_plot) + aes(y = sigma_p, x = mu_p, color = plus_dummy, linetype = plus_dummy) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) + geom_path() + ylim(0,0.6) +\n  geom_hline(yintercept = 0.25, color = \"green\") + coord_flip() + mystyle\n\n\n\n# 保有費率\nwa <- seq(-1,2,by = 0.01)\nwb <- 1 - wa\n\ndf <- tibble(\n  mu_p = R_F + wa*(mu_A - R_F),\n  sigma_p = abs(wa) * sigma_A\n)\nggplot(df) + aes(y = sigma_p, x = mu_p) + geom_line()  + coord_flip()\n\n\n\n\n\n\n2.3.2 投資家のリスク回避度と最適ポートフォリオ\n効率的フロンティアのうち、どの点が投資家の最適ポートフォリオになるのか，について考える。 そのためには投資家のリスク・リターンのトレードオフに関する選好(preference)の特徴，つまりリスクの回避度の情報が必要となる。 (\\mu_P,\\rho_p)平面上でそれを描く方法の一つが無差別曲線(indifference curve)である。 無差別曲線とは，投資家の効用(utility)が一定となるリスクとリターンの組み合わせを描いた曲線をいう。つまり同じ効用水準を達成できるリスクとリターンの組み合わせを表現した曲線である。\n\n2.3.2.1 効用関数の例\n以下では，財xとyを消費したときの効用Uを図示している。この消費者の効用関数はU(x,y) = x^{\\frac 25} \\times y^{\\frac 35}としている。\n\nlibrary(Rsolnp)\nx <- 1:50\ny <- 1:50\nu <- function(x, y) {x^(2/5) * y^(3/5)} #効用関数を定義\nU <- outer(x, y, u) #outer()はx_1,x_2に対応したf(x_1,x_2)の値を行列で返す\npersp(x, y, U,\n      theta = 30, # 横回転の角度\n      phi = 30, # 縦回転の角度\n      ticktype = \"simple\", # 線の種類\n      lwd = 0.5, # 線の太さ\n      col = F,\n      border = 8)\n\n\n\n\nこの立体図を等高線を使って表現したものが以下の図である。 青いラインは予算制約であり、予算の範囲内で購入可能な財の組み合わせを意味している。つまり、この予算制約と無差別曲線が接する点が、予算内で達成可能な最も高い効用水準を表している。\n無リスク利子率が10%で，リスクプレミアムが5％，βが1.2の場合の期待リターンは，R_F + \\beta \\times (R_M - R_F) = 0.1 + 1.2 \\times 0.05 = 0.16となる。このときの無差別曲線は，U = 0.16となるような点を結んだ曲線となる。\n\ncontour(x, y, U, method = \"edge\", labcex = 1,lwd = 2)\nabline(a = 100/6, b = -4/6, lwd = 2, col = \"blue\") #予算制約線\npoints(x = 10, y = 10, lwd = 3, col = \"darkblue\", pch = 16) #最適消費点\n\n\n\n\n無差別曲線と消費可能集合\n\n\n\n\nリスクとリターンの無差別曲線\n\n\n\n無差別曲線と効率的フロンティアに基づく最適ポート フォリオの決定\n\n\n複数ポートフォリオを比べるとき，この図の左上のものほど高リターン低リスクに対応するので、より高い効用水準が実現する。 また無差別曲線の局所的な傾きは、その投資家が追加的なリスクを引き受けるうえで要求するリスクプレミアムを表す。 リスク回避的な投資家ほど，リスクを1単位負担する際に，より大きなリスクプレミアムを要求するので、傾きは大きくなる。 つまり，1単位リスクを負担する代わりに欲しいリターンの額が大きくなるほど，傾きが大きくなる。\n無差別曲線と効率的フロンティアが接する点が、この投資家にとっての最適ポートフォリオとなる。 投資可能なポートフォリオの範囲で、最も左上の無差別曲線を実現するのが接点となる。 どの点が最適ポートフォリオとして選ばれるかは個々の投資家の無差別曲線の形状(リスク回避度)に依存する。最適ポートフォリオにおいて、無差別曲線と効率的フロンティアの局所的な傾きは一致(接線だから当然)するため、その投資家が要求するリスクプレミアムがちょうど実現されている。\n上図の場合，この投資家の最適ポートフォリオは(w_F,w_{tan})\\approx(0.29,0.71)の比率で構成される。\n接点ポートフォリオは銘柄Aに47％、銘柄Bに53％投資するポートフォリオだったので、最適保有比率は、(w_F,w_A,w_B)\\approx(0.29,0.33,0.38)と書き換えられる。\n\n\n\n2.3.3 トービンの分離定理\n安全資産が投資可能な場合の最適ポートフォリオ問題を考える。\n\n接点ポートフォリオを求め、リスク資産同士の相対的な保有比率を求める。\n投資家ごとのリスク回避度に応じて安全資産と接点ポートフォリオの最適保有比率の決定\n\n1は各投資家で共通している。 いったん接点ポートフォリオを求めてしまえば、他の投資家はその情報を用いて2を考えればよい。\n最適ポートフォリオ問題を2段階に分離できるという命題は、トービンの分離定理(又は二基金文理定理)と呼ばれている。"
  },
  {
    "objectID": "Chap02.html#capm",
    "href": "Chap02.html#capm",
    "title": "2  ファイナンス入門",
    "section": "2.4 CAPM",
    "text": "2.4 CAPM\nここでは，資産価格モデルの1つである資本資産価格モデル(Capital Asset Pricing Model)について議論する。まずは各投資家の最適ポートフォリオ問題を所与として、金融市場全体の均衡に関して議論する。\n\n2.4.1 仮定の確認\n\n選好 : 全ての投資家はポートフォリオを期待値と標準偏差の基準で評価する\n取引コスト : 取引に際して手数料や税金が存在せず、空売りが自由に可能\n流動性 : どれだけ売買しても証券の価格は変化しない\n情報集合 : 全ての投資家は同じ情報を共有している\n\n上記の仮定を満たす金融市場のことを、一般に完全資本市場(完全市場: perfect market)と呼ぶ。 これは「取引を行う上で完全に摩擦のない市場」というものであり，理論上の設定である。\n厳密にいうと、上記の仮定のうちいずれも現実には成立しない。 しかし、単純で分析が容易なモデルから出発し、その含意が仮定にどう依存するか議論を深めていくというのが経済理論の標準的なアプローチである。 実際、以降で導出するCAPMに関してこれらの仮定を緩めた理論が数多く提唱されている。\n\n\n2.4.2 CAPMの第一命題\n以上の仮定を受け入れると安全資産が投資可能なとき，全ての投資家の最適ポートフォリオ問題に対してトービンの分離定理を応用することができる。 全ての投資家は安全資産と接点ポートフォリオに投資し、危険資産に限定すれば同質的なポートフォリオを保有する。 金融市場全体の均衡を議論するうえで、市場にその資産が供給されている以上、誰かがその最適ポートフォリオの一部として保有しているという、需要と供給の一致がポイントである。\n\n\n\n\n\n\n例\n\n\n\n\n市場に参加している投資家3名\n市場に供給されている危険資産が銘柄XとYだけ\n時価総額はXが800億円、Yが200億円　\n\nこの市場には合計1000億円の危険資産が存在するとする。 全ての投資家が保有するリスク資産の合計額も1000億円に一致するはず。 リスク資産に限定すれば，全ての(合理的な)投資家は接点ポートフォリオと同じ比率でリスク資産を保有しているので，銘柄XとYの保有比率は時価総額と同じ比率8:2になっていなければならない。\n\n\n\n\n銘柄X\n銘柄Y\n合計\n\n\n\n\n\nw_X=0.8\nw_Y=0.2\nw_X+w_Y=1\n\n\n投資家A\n480\n120\n600\n\n\n投資家B\n240\n60\n300\n\n\n投資家C\n80\n20\n100\n\n\n合計\n800\n200\n1000\n\n\n\n\n\n以上の議論をよりフォーマルに述べるために、市場ポートフォリオを導入する。\n\n\n\n\n\n\n市場ポートフォリオ\n\n\n\n市場ポートフォリオ (market portfolio)とは，市場に存在する全ての危険資産を時価総額比率で保有したポートフォリオをいう。厳密には，リスク資産には株式や債券に代表される金融資産の他、不動産や貴金属などの実物資産も含まれるが、実用上はTOPIXやS&P500といった株価指数と同一視されることが多い。\n\n\n\n\n\n\n\n\nCAPMの第一命題\n\n\n\n市場ポートフォリオは接点ポートフォリオと一致し、効率的フロンティア(資本市場線)上に位置する。\n\n\n投資家は市場ポートフォリオに投資するとき、\\sigma_Mのリスクを背負う見返りとしてR_Fに加えて\\mu_M-R_Fだけ追加的な報酬を期待する。 この追加的な報酬を市場リスクプレミアム(market risk premium)という。したがってこの命題の下では、資本市場線を市場リスクプレミアム(\\mu_M-R_F)を利用して、以下のように表せる。\n\n\\mu_P = R_F + \\frac{\\mu_M - R_F}{\\sigma_M} \\sigma_P\n\n\n\n\nCAPM\n\n\n今までのパラメータをそのまま用いる。 接点ポートフォリオの保有比率は概ね47%を銘柄Aに、 53%を銘柄Bに投資するポートフォリオになった。CAPMの第一命題によると、この市場における銘柄AとBの時価総額比率は約0.47対0.53になっていなければならない。 この命題によると、各銘柄の期待リターンや分散から接点ポートフォリオを計算する必要はなく、単に時価総額加重で市場ポートフォリオを保有すればよい。\n\nパッシブ運用：幅広い銘柄に分散投資し、市場平均と同じようなパフォーマンスを目指す運用手法\nアクティブ運用：市場平均を上回るパフォーマンスを目指し、投資銘柄を絞ったり、投資比率を工夫したりする運用方法\n\n任意のポートフォリオの収益性を測る指標として、シャープ・レシオが提唱されている。シャープ・レシオは追加的なリスク・テイクによってどれだけリスクプレミアムを改善できるのかを表す指標。CAPMの第一命題によると、市場ポートフォリオはシャープ・レシオを最大化するという意味で最も効率的なポートフォリオであり、資本市場線の傾き\\frac{\\mu_M - R_P}{\\sigma_M}は市場ポートフォリオのシャープ・レシオと一致する。\n\n\\frac{\\mu_P-R_F}{\\sigma_P}\n\n\n\n2.4.3 CAPMの第二命題\n第二命題は個々の資産のリスクとリターンのトレードオフを数式で表現したもの。 ある証券に投資するときのリスクと、その証券に投資するときの期待リターンとの関係を知ることができるようになる。各投資家が証券iを追加的に保有する際、重要となるのは市場ポートフォリオとの相関。分散が大きい資産であっても、市場ポートフォリオと負に相関していれば、その資産を追加的に保有することでポートフォリオ全体のリスクは低減される。CAPMの第二命題は、この相関を以下のマーケット・ベータとして定量化する。 ※R_iは証券iのリターン、R_Mは市場ポートフォリオのリターン\nこの\\beta_iは市場ポートフォリオのリスクを1としてベンチマーク化し、その証券のリスクがベンチマークの1を上回るか下回るかを測るもの。\\beta_iが大きいほど証券iは投資家にとってリスクが大きいことを意味する。証券iのリスクはその証券のリターンの標準偏差ではなく、この\\beta_iによって測られる。 \n\\beta_i = \\frac{\\mathbb{Cov}[R_i, R_M]}{\\mathbb{Var}[R_M]}\n\n金融市場全体が均衡しているには，リスクの高い証券はその分だけ期待リターンも高くなければならない。 \\beta_iが低いにもかかわらず期待リターンが高い証券があるなら、投資家は市場ポートフォリオから離れてその証券をさらに買い増しするインセンティブを持つ。 その結果、市場価格が上がり、期待リターンが下がるため、\\beta_iに応じた期待リターンが均衡で実現される。 CAPMの第二命題はこの均衡におけるリスクとリターンのトレードオフの関係を記述した式である。\nこれまでは市場リスクプレミアムを\\mu_M - R_Fと表記していたが、以後ではより一般的な\\mathbb{E}[R_M] - R_Fと表記する。\n\n\n\n\n\n\nCAPMの第二命題\n\n\n\n各証券のリスクプレミアムは、その証券のマーケット・ベータに比例する。 この式は、証券iのリスクプレミアム\\mathbb{E}[R_i]-R_Fを、\\beta_iと市場リスクプレミアム\\mathbb{E}[R_M]-R_Fに分解している。\n\n\n第二項の\\mathbb{E}[R_M]-R_Fは個々の証券には依存しない定数である。\n\n\\begin{aligned}\n\\mathbb{E}[R_i]-R_F = \\beta_i (\\mathbb{E}[R_M] - R_F)\\\\\n\\text{ただし、 } \\beta = \\frac{Cov[R_i,R_M]}{Var[R_M]}\n\\end{aligned}\n\n通常、市場リスクプレミアムは正の値をとるので、CAPMの第二命題によると、個々の証券のリスクプレミアムは\\beta_iに関して線形に増加する。 \\beta_iはあくまで市場ポートフォリオとの相関でリスクを定量化しているのがポイント。 いくら個々の証券のリスクが大きくても、それが市場ポートフォリオと相関しない固有リスクであれば、リスクプレミアムには反映されない。 期待値をとる前のR_iを分解して確認する。\n\nR_i = R_F + \\beta_i (R_M - R_F) + \\varepsilon_i\n\nここで\\varepsilon_iは期待値ゼロでR_Mと相関しない誤差項である。\n\n\\mathbb{E}[\\varepsilon_i] = 0, \\qquad \\mathbb{Cov}[\\varepsilon_i, R_M] = 0\n\n\n\\begin{aligned}\nVar[R_i] &= \\mathbb{Var}[\\beta_i R_M + \\varepsilon_i]\\\\\n& = \\beta_i^2 \\mathbb{Var}[R_M] + \\mathbb{Var}[\\varepsilon_i] + \\underbrace{\\mathbb{Cov}[\\beta_i R_M, \\varepsilon_i]}_{\\tiny =0}\\\\\n& = \\underbrace{\\beta_i^2 \\mathbb{Var}[R_M]}_{\\tiny 市場ポートフォリオとの相関による寄与分} + \\underbrace{\\mathbb{Var}[\\varepsilon_i]}_{\\tiny 誤差項による寄与分}\n\\end{aligned}\n\nR_iの分散を計算すると、市場ポートフォリオとの相関による寄与分と誤差項による寄与分に分解できる。 誤差項の分散が大きければその分だけR_iの分散も大きくなるが、証券iのリスクプレミアムは\\mathbb{E}[R_M]-R_Fのままで変化はない。\n\n\n2.4.4 証券市場線\n安全資産と複数の危険資産が投資可能な場合、投資家の最適ポートフォリオは各人のリスク回避度に応じて図2.14の左図の資本市場線の1点となる。CAPMの第二命題が示唆するように、各証券のリスクとリターンとの関係は図2.14の右図になる。縦軸に各証券の期待リターン、横軸に各証券のリスクを表すマーケット・ベータをとると、CAPMが完全に成立する世界では全ての資産が一直線上に並ぶ。この直線を証券市場線(Securities Market Line; SML)と呼ぶ。 現実は、必ずしもCAPMの第二命題は成立しておらず、CAPMが予測するリターン(証券市場線)からの縦方向からの乖離(これをアルファと呼ぶ)が見られる。\n図2.14挿入\n定義通り\\betaを計算すると銘柄Aは約0.63，銘柄Bは約1.33となる。 両者の期待リターン、および\\betaを図示すると証券市場線に乗っており、この仮想的な市場ではCAPMが成立していることがわかる。 CAPMはアクティブ運用の賛同者から激しい批判を浴びてきたが、歴史的にみるとパッシブ運用を採用する機関投資家は増え続けており、ファイナンス理論及び投資実務の双方に多大な影響を与えてきたと言って過言ではない。\n\n\n2.4.5 N資産が投資可能な場合への拡張\n今までは，リスク資産が銘柄AとBの二つしかない場合を分析してきたが，現実は多くのリスク資産が存在し、海外株式や債券、REIT(不動産投資信託)といったその他の投資可能な金融資産を含めればその数は飛躍的に増加する。 本節での平均分散アプローチやCAPMは危険資産の数が任意のN個であっても成立する。 ただしその場合は行列での表記が必須となる(第7章やサポートサイト4.5節参照)。\n一般に，平均分散の意味で効率的なポートフォリオ(平均分散ポートフォリオ)を計算するには、目標期待リターンを所与として、それを実現するポートフォリオの中でリスクを最小化するものを求める。 得られた期待リターンとリスクのペアを一点として、目標期待リターンを動かすとリスク・リターン平面上に双曲線が描ける。 この双曲線を平均分散フロンティアと呼び、効率的フロンティアはその上半分の領域である(確認済み)。\n一般に投資可能な資産の数が増えると、平均分散フロンティアは左上に移動し、投資家はより望ましいポートフォリオが実現できるようになる。 リスク資産AとBに加えてCが投資可能な状況を考えると投資可能な資産が増えたからと言って必ずしもその資産に投資する必要はない。w_C=0とすれば、投資家は危険資産AとBのみに投資可能だった場合と同じ投資機会集合を実現できる。 新しい危険資産が既存資産の組み合わせによって完全に再現できるような極端な例を除けば分散投資のメリットが生じるため、投資家はより望ましいリスク・リターンのトレードオフを実現できる。\n統計学における分散の定義は，N個の確率変数R_1,R_2,\\cdots,R_Nの共分散行列\\Sigmaの対角成分の和である。 \n\\begin{align*}\n\\sigma^2=\\sum_{i=1}^N\\sum_{j=1}^N\\sigma_{ij}=\\sum_{i=1}^N\\sigma_{ii}\n\\end{align*}\n ここで，\\sigma_{ij}はR_iとR_jの共分散であり，\\sigma_{ii}はR_iの分散である。 共分散行列\\Sigmaは対称行列であり，対角成分は分散を表す。 また，R_iとR_jの共分散は\\sigma_{ij}=\\sigma_{ji}である。 共分散行列の対角成分以外の成分は共分散を表す。 \n\\begin{align*}\n\\Sigma=\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1N} \\\\\n\\sigma_{21} & \\sigma_{22} & \\cdots & \\sigma_{2N} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{N1} & \\sigma_{N2} & \\cdots & \\sigma_{NN} \\\\\n\\end{bmatrix}\n\\end{align*}\n\n上のは，N個の確率変数の共分散行列の定義である。Copilotで作成しました。"
  },
  {
    "objectID": "Chap02.html#数学の準備",
    "href": "Chap02.html#数学の準備",
    "title": "2  第2章 ファイナンス入門",
    "section": "2.1 数学の準備",
    "text": "2.1 数学の準備\n以下では、様々な要素(利子率とか割引率とか投資収益率とか)を記号で表現します。ここでは、それらの記号の意味を説明しておくので、分からなくなったら随時ここに戻って確認するようにしてください。\n\nキャッシュ・フロー(Cash Flow)：CF\n無リスク利子率(Risk-Free rate)：R_F\n現在価値(Present Value)：PV\n期間や時点(Time)：T\n\n次に、定数(constant)と確率変数(random variable)について説明します。\n定数とはある特定の数を意味します。例えば、1や52や0.1などです。 定数は定まった数ですので、不確実性はありません。\n確率変数(random variable)は、ある値をとる確率が定義されている変数です。 例えばサイコロの出目は確率変数です。サイコロの出目は1から6までの値をとりますが、どの値が出るかは確定していません。しかし、1から6までの値が出る確率は等しく1/6です。このように、確率変数はある値をとる確率が定義されている変数です。 確率変数であることを明示するために、確率変数には~(チルダ)をつけて表記します。\n確率変数はどの値がどの確率で出るのかは分かっていますが、実際どの値が観察されるのかは分かりません。そのため、確率変数は期待値(expectation)と分散(variance)を持ちます。 以下では、期待値を表す演算子として\\mathbb{E}[\\cdot]を、分散を表す演算子として\\mathbb{V}[\\cdot]を用います。 ファイナンスや会計学では、リスクを分散で表します。 「リスクがある」とは、結果として実現する値がばらつくことを意味します。 結果が確実に分かっている場合は、リスクがない、つまり分散が0の場合です。\n\n2.1.1 数式\nよく出てくるものをまとめておきます。\n足し算をまとめて書くときは、\\sumを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを足し合わせるときは以下のように書きます。 \nx_1 + x_2 + x_3 + \\cdots + x_n\n これを\\sumを使って書くと以下のようになります。 \n\\sum _{i = 1}^n x_i\n このほうがシンプルです。\n掛け算をまとめて書くときは、\\prodを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを掛け合わせるときは以下のように書きます。 \nx_1 \\times x_2 \\times x_3 \\times \\cdots \\times x_n\n これを\\prodを使って書くと以下のようになります。 \n\\prod _{i = 1}^n x_i\n 次に、$x = 1,2,3,4, $ といった離散的な変数xの期待値は以下のように書きます。 \n\\mathbb{E}[x] = \\sum _{i = 1}^n x_i p_i\n ここで、p_iはx_iが観測される確率です。 同様に、分散は、 \n\\mathbb{V}[x] = \\sum _{i = 1}^n (x_i - \\mathbb{E}[x])^2 p_i\n と書きます。\n\n\n2.1.2 期待値の特徴\n期待値について以下のような特徴があります。\n\n\n\n\n\n\nImportant\n\n\n\n\n\\begin{align}\n&\\mathbb{E}[a] = a \\\\\n&\\mathbb{E}[a \\tilde X] = a \\mathbb{E}[\\tilde X]\\\\\n&\\mathbb{E}[\\tilde X + a] = \\mathbb{E}[\\tilde X] + a\\\\\n&\\mathbb{E}[\\tilde X + \\tilde Y] = \\mathbb{E}[\\tilde X] + \\mathbb{E}[\\tilde Y]\n\\end{align}\n\n\n\n1つめの式は、定数aの期待値はaであることを意味します。 2つめの式は、定数aと確率変数\\tilde Xの積の期待値は、定数aと確率変数\\tilde Xの期待値の積に等しいことを意味します。 3つめの式は、確率変数\\tilde Xに定数aを足したものの期待値は、確率変数\\tilde Xの期待値に定数aを足したものに等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の期待値は、確率変数\\tilde Xの期待値と確率変数\\tilde Yの期待値の和に等しいことを意味します。\n特に4つめの公式は重要で、和の期待値は期待値の和となることを意味してます。よく使うので覚えておいてください。\n\n\n2.1.3 分散の特徴\n分散について以下のような特徴があります。\n\n\n\n\n\n\nImportant\n\n\n\n\n\\begin{align}\n&\\mathbb{V}[a] = 0\\\\\n&\\mathbb{V}[a \\tilde X] = a^2 \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + a] = \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + \\tilde Y] = \\mathbb{V}[\\tilde X] + \\mathbb{V} [\\tilde Y] + \\mathbb{Cov}(X,Y)\\\\\n&\\mathbb{V}[\\tilde X] = \\mathbb{E}[\\tilde X^2] - \\mathbb{E}[\\tilde X]^2\\\\\n\\end{align}\n\n\n\n1つめの式は、定数aの分散は0であることを意味します。自明ですね。 2つめの式は、定数aと確率変数\\tilde Xの積の分散は、定数aの2乗と確率変数\\tilde Xの分散の積に等しいことを意味します。1つめの式から明らかですね。\n3つめの式は、確率変数\\tilde Xに定数aを足したものの分散は、確率変数\\tilde Xの分散に等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の分散は、確率変数\\tilde Xの分散と確率変数\\tilde Yの分散と共分散の和に等しいことを意味します。これもよく出てくるので覚えておいてください。\n5つめの式は、確率変数\\tilde Xの分散は、確率変数\\tilde Xの2乗の期待値から確率変数\\tilde Xの期待値の2乗を引いたものに等しいことを意味します。 つまり分散の計算は、確率変数の2乗の期待値から期待値の2乗を引くことで計算できるということです。これ重要です。"
  },
  {
    "objectID": "index.html#数学算数の準備",
    "href": "index.html#数学算数の準備",
    "title": "実証会計・ファイナンスのノート",
    "section": "数学・算数の準備",
    "text": "数学・算数の準備\nこの教科書では、紛らわしい表現を避けるため、様々な要素(利子率とか割引率とか投資収益率とか)を記号で表現します。ここでは、それらの記号の意味を説明しておくので、分からなくなったら随時ここに戻って確認するようにしてください。\n\nキャッシュ・フロー(Cash Flow)：CF\n無リスク利子率(Risk-Free rate)：R_F\n現在価値(Present Value)：PV\n期間や時点(Time)：T\n\n次に、定数(constant)と確率変数(random variable)について説明します。\n定数とはある特定の数を意味します。例えば、1や52や0.1などです。 定数は定まった数ですので、不確実性はありません。\n確率変数(random variable)は、ある値をとる確率が定義されている変数です。 例えばサイコロの出目は確率変数です。サイコロの出目は1から6までの値をとりますが、どの値が出るかは確定していません。しかし、1から6までの値が出る確率は等しく1/6です。このように、確率変数はある値をとる確率が定義されている変数です。 確率変数であることを明示するために、確率変数には~(チルダ)をつけて表記します。たとえば確率変数Xは\\tilde{X}で表記します。\n確率変数は、どの値がどの確率で出るのかは分かっていますが、実際どの値が観察されるのかは分かりません。そのため、確率変数は期待値(expectation)と分散(variance)を持ちます。 以下では、期待値を表す演算子として\\mathbb{E}[\\cdot]を、分散を表す演算子として\\mathbb{V}[\\cdot]を用います。 ファイナンスや会計学では、リスクを分散で表します。 「リスクがある」とは、結果として実現する値がばらつくことを意味します。 結果が確実に分かっている場合は、リスクがない、つまり分散が0の場合です。\n\n数式\nよく出てくるものをまとめておきます。\n足し算をまとめて書くときは、\\sumを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを足し合わせるときは以下のように書きます。 \nx_1 + x_2 + x_3 + \\cdots + x_n\n これを\\sumを使って書くと以下のようになります。 \n\\sum _{i = 1}^n x_i\n このほうがシンプルです。\n掛け算をまとめて書くときは、\\prodを使います。 いま、x_1, x_2, \\dots, x_NというN個の数値があるとして、それを掛け合わせるときは以下のように書きます。 \nx_1 \\times x_2 \\times x_3 \\times \\cdots \\times x_n\n これを\\prodを使って書くと以下のようになります。 \n\\prod _{i = 1}^n x_i\n\n離散的な変数xの期待値は以下のように書きます。\n\n\\mathbb{E}[x] = \\sum _{i = 1}^n x_i p_i\n ここで、p_iはx_iが観測される確率です。 たとえばサイコロの出目Xは\\{1,2,3,4,6\\}の値を、それぞれ1/6の確率で出す確率変数です。サイコロの出目の期待値は、 \n\\begin{align*}\n\\mathbb{E}[X] &= \\frac 16 \\times 1 + \\frac 16 \\times 2 + \\frac 16 \\times 3 + \\frac 16 \\times 4 + \\frac 16 \\times 5 + \\frac 16 \\times 6\\\\\n& = 3.5\n\\end{align*}\n となります。\n次に、確率変数の分散は、 \n\\mathbb{V}[x] = \\sum _{i = 1}^n (x_i - \\mathbb{E}[x])^2 p_i\n と書きます。これもサイコロの例で考えてみましょう。 サイコロの出目の分散は、\n\n\\begin{align*}\n\\mathbb{V}[X] &= \\frac 16 \\times (1 - 3.5)^2 + \\frac 16 \\times (2 - 3.5)^2 + \\frac 16 \\times (3 - 3.5)^2 \\\\\n&+ \\frac 16 \\times (4 - 3.5)^2 + \\frac 16 \\times (5 - 3.5)^2 + \\frac 16 \\times (6 - 3.5)^2\\\\\n& = 2.916666666666666534\n\\end{align*}\n\nと計算できます。\n\n\n期待値の特徴\n期待値について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{E}[a] = a \\\\\n&\\mathbb{E}[a \\tilde X] = a \\mathbb{E}[\\tilde X]\\\\\n&\\mathbb{E}[\\tilde X + a] = \\mathbb{E}[\\tilde X] + a\\\\\n&\\mathbb{E}[\\tilde X + \\tilde Y] = \\mathbb{E}[\\tilde X] + \\mathbb{E}[\\tilde Y]\n\\end{align}\n\n\n\n1つめの式は、定数aの期待値はaであることを意味します。 2つめの式は、定数aと確率変数\\tilde Xの積の期待値は、定数aと確率変数\\tilde Xの期待値の積に等しいことを意味します。 3つめの式は、確率変数\\tilde Xに定数aを足したものの期待値は、確率変数\\tilde Xの期待値に定数aを足したものに等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の期待値は、確率変数\\tilde Xの期待値と確率変数\\tilde Yの期待値の和に等しいことを意味します。\n特に4つめの公式は重要で、和の期待値は期待値の和となることを意味してます。よく使うので覚えておいてください。\n正6面体のサイコロの出目Xと正4面体のサイコロの出目Yの和の期待値は、 \n\\begin{align*}\n\\mathbb{E}[X] &= 3.5\\\\\n\\mathbb{E}[Y] &= \\frac 14 \\times 1 + \\frac 14 \\times 2 + \\frac 14 \\times 3 + \\frac 14 \\times 4 = 2.5\\\\\n\\mathbb{E}[X + Y] &= \\mathbb{E}[X] + \\mathbb{E}[Y] = 3.5 + 2.5 = 6\n\\end{align*}\n となります。\n\n\n分散の特徴\n分散について以下のような特徴があります。\n\n\n\n\n\n\n重要\n\n\n\n\n\\begin{align}\n&\\mathbb{V}[a] = 0\\\\\n&\\mathbb{V}[a \\tilde X] = a^2 \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + a] = \\mathbb{V}[\\tilde X]\\\\\n&\\mathbb{V}[\\tilde X + \\tilde Y] = \\mathbb{V}[\\tilde X] + \\mathbb{V} [\\tilde Y] + \\mathbb{Cov}(X,Y)\\\\\n&\\mathbb{V}[\\tilde X] = \\mathbb{E}[\\tilde X^2] - \\mathbb{E}[\\tilde X]^2\\\\\n\\end{align}\n\n\n\n1つめの式は、定数aの分散は0であることを意味します。自明ですね。 2つめの式は、定数aと確率変数\\tilde Xの積の分散は、定数aの2乗と確率変数\\tilde Xの分散の積に等しいことを意味します。1つめの式から明らかですね。\n3つめの式は、確率変数\\tilde Xに定数aを足したものの分散は、確率変数\\tilde Xの分散に等しいことを意味します。 4つめの式は、確率変数\\tilde Xと確率変数\\tilde Yの和の分散は、確率変数\\tilde Xの分散と確率変数\\tilde Yの分散と共分散の和に等しいことを意味します。これもよく出てくるので覚えておいてください。\n5つめの式は、確率変数\\tilde Xの分散は、確率変数\\tilde Xの2乗の期待値から確率変数\\tilde Xの期待値の2乗を引いたものに等しいことを意味します。 つまり分散の計算は、確率変数の2乗の期待値から期待値の2乗を引くことで計算できるということです。これ重要です。 先のサイコロの例で確認してみます。 \n\\begin{align*}\n\\mathbb{V}[X] &= \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 \\\\\n&= \\frac 16 \\times 1^2 + \\frac 16 \\times 2^2 + \\frac 16 \\times 3^2 + \\frac 16 \\times 4^2 + \\frac 16 \\times 5^2 + \\frac 16 \\times 6^2 - 3.5^2 \\\\\n&= 15.16667 - 12.25 \\\\\n&= 2.916667\n\\end{align*}\n となり、上で計算した分散と一致します。"
  },
  {
    "objectID": "Chap03.html",
    "href": "Chap03.html",
    "title": "3  R言語入門",
    "section": "",
    "text": "4 for文の使い方\nプログラミングの基本要素である\nの最初の要素である「繰り返し」を行うための文法がfor文です。for文は、ある処理を繰り返し行うための文法です。たとえば、1から10までの整数を順番に表示するには、次のように書きます。\nこの文の構造は、基本的には\nとなっています。\nたとえば、教科書のように、\nという投資プロジェクトの現在価値を計算する場合、愚直に書くと次のようになります。\nこの上のコードの2行目から4行目はほぼ同じ内容なので、数字が変化しているところに注目し、for文を使って書き換えてみます。ここでは^1のところが1ずつ大きくなってます。この部分をiという変数に置き換えてみます。 ついでに、後で変化させることがあるかもしれない部分をすべて変数として定義しておきます。\n愚直に計算した場合の同じ結果となりました。 これを10年間の現在価値を計算する場合だとすると、\nと面倒くさいことこの上ないですが、for文を使えば、\nと短く書くことができます。使いこなせるように練習しておきましょう。\n次のように、print()関数の位置を変えた場合、どうなるか考えてみてください。\nこの場合、最初にNPVの中を表示し、次に1期目の現在価値を計算し、またその結果を表示し、2期目の現在価値を計算し・・・という順番で繰り返しが行われるので、計算の途中経過が表示されることになります。\nプログラミングの基本要素である\nの作り方について説明します。 Rでは自分で関数を定義することができます。関数を定義することで、同じ処理を何度も書く必要がなくなり、プログラムの見通しがよくなります。 例えば、足し算をする関数my_add()を定義してみます。\nこの関数の構造は、\nとなっています。つまり、この独自関数my_add()は、xとyという2つの引数(ひきすう)を足し合わせる関数です。数学的に書くなら、\nf(x, y) = x + y\nとなります。これはfという関数は2つの引数を足す関数であるという意味になっています。 作成した独自関数my_add()を使ってみます。\n3が出力されました。\nこのように、独自関数を作成する場合には、\nを考えておく必要があります。\nでは今までの流れで、現在価値を計算する関数を作成してみます。変化させたい値は、キャッシュフローCFと無リスク利子率Rなので、その2つを引数とする独自関数を作成します。 少し注意する必要がある点として、以下の計算例ではCFの1番目の要素は初期投資額となることに注意しましょう。\nこの関数calc_PV()を使って、現在価値を計算してみます。\nちゃんと計算されました。この関数を使って、無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値を計算してみます。\n計算されました。 関数の引数にデフォルトで値を設定することで、入力を楽にすることができます。例えば、無リスク利子率のデフォルト値を0.1に設定してみます。\nすると、無リスク利子率を指定しなくても、デフォルト値が使われるようになります。\nただ計算を間違えるもとにもなるので、なるべく省略せずに、しっかり書くことが大事です。"
  },
  {
    "objectID": "Chap03.html#rの基本的な機能",
    "href": "Chap03.html#rの基本的な機能",
    "title": "3  R言語入門",
    "section": "3.1 Rの基本的な機能",
    "text": "3.1 Rの基本的な機能\n\n3.1.1 スカラー変数の定義\nこの学習を通じて変数(variable)とは、数値や文字といったデータを格納するための箱を表し、中に何が入っているのかにより、スカラー変数、ベクトル、行列、データフレームなどに分類されます。まずは、スカラー変数の定義を学びます。\nスカラー(scalar)とは、大きさだけで決まる量のことで、つまり、1つの数値を指します。 R言語ではスカラー変数を定義するには、<-を使います。たとえば、x <- 100と書けば、xというスカラー変数に100という数値を格納できます。このとき、<-は代入演算子と呼ばれ、右辺の値を左辺の変数に代入するという意味です。また、xという変数を左辺値(left-hand side)、100という数値を右辺値(right-hand side)と呼びます。\n\nx <- 100 # 代入演算子<- の前後に半角スペースを入れるのがお作法\n\nこの中身を表示されるには、print()関数を使います。\n\nprint(x) # xの中身を表示\n\n[1] 100\n\n\nあるいは\n\nx\n\n[1] 100\n\n\nでも表示されます。\n\nRでは#の後ろの文章はコメントとして扱われ、実行されません。コメントはプログラムの内容を説明するためにたくさん書いて残しておきましょう。\n\n\n\n3.1.2 ベクトル変数の定義\nベクトル(vector)とは、大きさと向きで決まる量のことで、つまり、複数の数値を指します。R言語ではベクトル変数を定義するには、c()を使います。たとえば、x <- c(1, 2, 3)と書けば、xというベクトル変数に1, 2, 3という数値を格納できます。このとき、c()はベクトルを作る関数と呼ばれ、1, 2, 3という数値を引数として与えています。\n\nx <- c(1, 5, 9) # xに1と5と9を要素とするベクトルを代入\nprint(x)\n\n[1] 1 5 9\n\n\n等差数列を作る関数にseq()関数があります。seq()は3つの引数をとり、\n\nfrom : 始点\nto : 終点\nby : 差分\n\nを指定します。たとえば、2000年から2020年を表す年度の変数をyearとして定義するには、\n\nyear <- seq(from = 2000, to = 2020, by = 1)\nprint(year)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nと書けば、2000から2020までの公差1の等差数列を作ります。 seq()変数の引数には、fromとtoとbyの3つの引数を指定することができますが、fromとtoのみを指定することもできます。このとき、byの値は1となります。次のように書いても、上と同じ結果を得ることができます。\n\nseq(2000,2020)\n\n [1] 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014\n[16] 2015 2016 2017 2018 2019 2020\n\n\nベクトルの要素数を知るには、length()関数を使います。\n\nlength(year) # yearの要素数を表示\n\n[1] 21\n\n\nベクトル変数yearの中には21個の要素があることがわかります。\n\n3.1.2.1 ベクトルの要素の取り出し\n複数の要素をもつベクトルから、一部の要素を取り出すには、[]を使います。たとえば、xの2番目の要素を取り出すには、x[2]と書きます。このとき、[]は添字演算子と呼ばれ、2という添字を引数として与えています。添字は1から始まります。\n上のyearから2000を取り出すには、year[1]、2020を取り出すにはyear[20]と書きます。 次のような書き方で、好きな要素を指定して取り出すことができます。\n\nyear[1] # 1番目のデータを取り出す\n\n[1] 2000\n\nyear[20] # 20番目のデータを取り出す\n\n[1] 2019\n\nyear[2:5] # 2番目から5番目のデータを取り出す\n\n[1] 2001 2002 2003 2004\n\nyear[c(5,10)] # 1番目と20番目のデータを取り出す\n\n[1] 2004 2009\n\nyear[6:length(year)] # 6番目から最後のデータを取り出す\n\n [1] 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n[16] 2020\n\n\n\n\n3.1.2.2 現在価値の計算\n今の時点をt=0として、T年後に確実に得られるキャッシュ・フローCF_Tの現在価値PV_0は、 \nPV_0 = \\frac{CF_T}{(1+r)^T}\n と書けます。たとえば1年後に確実に受け取れる100万円の現在価値PV_0を計算してみます。いま、無リスク利子率rは10%とします。\n\n100 / (1 + 0.1)^1\n\n[1] 90.90909\n\n\n次に、この無リスク利子率rが変化した場合の現在価値の計算を考えます。まず、無リスク利子率のベクトルを定義します。\n\n# 下の２つは同じ結果\nR <- seq(from = 0.1, to = 0.2, by = 0.01)　# 省略せずに書いた場合\nR <- seq(0.1, 0.2, 0.01) # 略した場合\n\n次に、無リスク利子率が変化した場合の現在価値を計算します。\n\nPV <- 100 / (1 + R)^1\nprint(PV)\n\n [1] 90.90909 90.09009 89.28571 88.49558 87.71930 86.95652 86.20690 85.47009\n [9] 84.74576 84.03361 83.33333\n\n\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値が計算されました。この結果をグラフにしてみます。\n\n\n\n3.1.3 基本パッケージplotによる作図\nとりあえずサクッと作図してデータをチェックしたいとき、もとからR言語に組み込まれている基本関数plot()が便利です。先ほど作成したベクトル変数PVをグラフにしてみます。\n\nplot(PV)\n\n\n\n\nいま、PVは11個の要素をもつベクトル変数なので、データを左から順番に並べた散布図(scatter diagram)が作成されています。これだと何のグラフか分かりづらいので、いろいろとオプションを指定してみます。\n\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\",\n    ylab = \"現在価値\",\n    main = \"無リスク利子率と現在価値の関係\",\n    type = \"l\" # 線グラフ\n)\n\n\n\n\nMacだと文字化けしてしまいました。そこで文字コードを指定します。Windowsだとこの作業は不要です。\n\npar(family = \"HiraKakuProN-W3\") # Macの場合のみ\nplot(\n    x = R, # x軸のデータ\n    y = PV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"無リスク利子率と現在価値の関係\", # グラフのタイトル\n    type = \"l\" # 折れ線グラフ\n)"
  },
  {
    "objectID": "Chap03.html#npvと割引率の関係の可視化",
    "href": "Chap03.html#npvと割引率の関係の可視化",
    "title": "3  R言語入門",
    "section": "4.1 NPVと割引率の関係の可視化",
    "text": "4.1 NPVと割引率の関係の可視化\n無リスク利子率が0.1から0.2まで0.01ずつ変化した場合の現在価値NPVの値を計算してみます。\n\nR <- seq(0.1, 0.2, 0.01) # 無リスク利子率\nN <- length(R) # 無リスク利子率の要素数 11個\nNPV <- rep(NA, N) # ベクトル変数にN個のNAを代入\n\nfor (i in 1:N) { # iは1からNまで\n    NPV[i] <- -100 # 初期投資\n    for (j in 1:3) { # jは1から3まで\n        NPV[i] <- NPV[i] + 50 / (1 + R[i])^j # 現在価値\n    }\n}\nprint(NPV) # 11個の現在価値を表示\n\n [1] 24.342600 22.185736 20.091563 18.057630 16.081601 14.161256 12.294477\n [8] 10.479248  8.713646  6.995838  5.324074\n\n\n少し複雑な構造しているので、順番に説明します。\n\n1行目は、無リスク利子率のベクトル変数Rを定義しています。ここでは、0.1から0.2まで0.01刻みのデータを作成しています。\n2行目は、ベクトル変数Rの要素数をNとして定義しています。ここでは、Nは11となります。\n3行目は、ベクトル変数NPVにN個のNAを代入しています。NAはNot Availableの略で、欠損値を表します。NAを代入することで、空っぽの箱が11個入ったベクトル変数NPVを用意します。\n4行目から9行目は、for文を使って、NPVの中身を計算しています。 forが2回出てきているので、二重に繰り返しの処理を行っています。これをネストと呼びます。 1つのめforはiが1からN(ここでは11)まで変化し、2つめのforはjが1から3まで変化します。1つめのfor文のiが1のとき、次のfor文のjが1から3までの処理を繰り返し、次に1つめのfor文のiが2のとき、次のfor文のjが1から3までの処理を繰り返し・・・という順番で処理が行われます。\n10行目は、NPVの中身を表示しています。\n\n\nTABキーを使って、インデントを行い、ソースコードのまとまりをわかりやすくしています。インデントは、プログラムの構造をわかりやすくするために行います。インデントを行うときは、半角スペース2つか4つを使います。どちらを使っても構いませんが、どちらかに統一することが大切です。\n\nこの結果をグラフにしてみます。\n\npar(family = \"HiraKakuProN-W3\") # 日本語フォントの設定\nplot(\n    x = R, # x軸のデータ\n    y = NPV, # y軸のデータ\n    xlab = \"無リスク利子率\", # x軸のラベル\n    ylab = \"現在価値\", # y軸のラベル\n    main = \"図：無リスク利子率と現在価値\", # グラフのタイトル\n    type = \"l\" # 線グラフ\n)\n\n\n\n\n\nベクトル化\n上のコードは、for文を使って、NPVの中身を計算しています。しかし、R言語では、for文を使わずに、ベクトルを使って、同じことを行うことができます。このように、for文を使わずに、ベクトルを使って処理を行うことをベクトル化と呼びます。ベクトル化を行うと、処理が高速化されることがあります。\n\nR <- 0.1 # 無リスク利子率 10%\nCF <- c(-100, 50, 50, 50) # キャッシュ・フローのベクトル\nyear <- 0:3 # 年度のベクトル\nPV_CF <- CF / (1 + R)^year # 各期の現在価値を計算\nNPV <- sum(PV_CF) # 現在価値の合計\nprint(NPV)\n\n[1] 24.3426"
  },
  {
    "objectID": "Chap04.html#ディスクロージャー制度の概要とデータの入手先",
    "href": "Chap04.html#ディスクロージャー制度の概要とデータの入手先",
    "title": "4  財務データの取得と可視化",
    "section": "4.1 ディスクロージャー制度の概要とデータの入手先",
    "text": "4.1 ディスクロージャー制度の概要とデータの入手先\n\n4.1.1 法定開示と適時開示\n\n\n\n\n年次開示\n四半期開示\n重要事実\n\n\n\n\n法定開示\n有価証券報告書\n四半期報告書\n臨時報告書\n\n\n適時開示\n決算短信\n四半期決算短信\n適時開示\n\n\n\n\n\n4.1.2 財務データの入手先\n\nEDINET：金融庁が運営する電子開示システムで，全上場企業の法定開示資料をデータベースとして提供\nTDnet：東京証券取引所が運営する電子開示システムで，上場企業の決算短信をデータベースとして提供\n\nXBRL(eXtensible Business Reporting Language)形式で財務諸表などの主要情報を公開しています。XBRLからデータを読み込むスキルは本書の枠を超えるため，ここでは練習用データで分析しますが、立命館大学では日経NEEDSを利用して財務データを収集します。"
  },
  {
    "objectID": "Chap04.html#rを利用した財務データの分析",
    "href": "Chap04.html#rを利用した財務データの分析",
    "title": "4  財務データの取得と可視化",
    "section": "4.2 Rを利用した財務データの分析",
    "text": "4.2 Rを利用した財務データの分析\n\n4.2.1 tidyverseパッケージの概要\ntidyverseとは，R神Wickham氏が基本コンセプトを設定し，整然データ(tidy data)に対して一貫した記法でデータを扱えるパッケージ群です。 インストールと読み込みは以下の通りです。\n\n#install.packages(\"tidyverse\") # 初回だけ\nlibrary(tidyverse) # 毎回読み込み。\n\ntidyverseパッケージを読み込むことで，次の代表的なパッケージが利用できるようになります。 よく使うものは以下のものになります。\n\nggplot2 データの可視化　めっちゃ使う\ndplyr データハンドリング　めっちゃ使う\nreadr データを読み込む めっちゃ使う\ntidyr tidyデータにもっていく　そこそこ使う\npurrr 関数型プログラミングで使う　慣れてくると使う\ntibble data.frameではなくtibbleにする　あまり使わない\nstringr 文字列の加工・操作　ちょいちょい使う\nforcats ファクター型変数の操作　そんなに使わない\n\n\n\n4.2.2 財務データの読み込み\n「実証会計・ファイナンス」のサポートサイトにある練習用のデータセットch04_financial_data.csvをダウンロードして，自分のPCの作業ディレクトリに置きます。 いまRが作業ディレクトリとしてどこの場所を読み込んでいるのかを確認するにはgetwd()を使います。 作業ディレクトリを変更するときはsetwd()で作業ディレクトリを絶対パスで指定するとよいでしょう。\nいままではcsvデータを読み込むために，基本関数のread.csv()を使ってきましたが、ここからはより高速かつオプション指定が柔軟なtidyverse関数群の1つであるreadrパッケージのread_csv()関数を使います。readとcsvの間がピリオド.からアンダースコア_に変わっているので注意してください。 readrパッケージのread_csv()関数は，\n\nデータの読み込みが高速かつ型の推論が柔軟\n基本のdata.frameではなく，その拡張版であるtibbleで返す\n列名を勝手に変換しない。\n文字列を勝手にファクター型にしない（ read.csv()だと勝手にファクターになる )。\n\nという利点があります。 松浦は、作業ディレクトリであるフォルダの中にdataフォルダを作成し、そこにcsvファイルを入れています。 そのため、以下のコードではdata/ch04_financial_data.csvのように相対パスでファイルを指定しています。\n\nfinancial_data <- read_csv(\"data/ch04_financial_data.csv\") # readrを使用\nnrow(financial_data) # 行数\n\n[1] 7920\n\nncol(financial_data) # 列数\n\n[1] 11\n\nhead(financial_data,5) # 最初の5行\n\n# A tibble: 5 × 11\n   year firm_ID industry_ID sales    OX   NFE     X     OA    FA    OL     FO\n  <dbl>   <dbl>       <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl>\n1  2015       1           1 5261.  437.  NA    287. 13006. 3543. 4373.  2481.\n2  2016       1           1 5949.  564.  50.7  513. 13866. 4642. 4534.  3960.\n3  2017       1           1 6505.  691.  29.5  662. 13953. 7744. 5111.  6159.\n4  2018       1           1 6846.  751.  86.5  665. 18818. 7285. 5137. 10124.\n5  2019       1           1 7572.  959. 298.   660. 18190  9735. 5488. 11362.\n\n\nこのfinancial_dataには、11個の変数に観測値が7920個あることがわかります。\n\nyear : 年度\nfirm_ID : 企業ID\nindustry_ID : 産業ID\nsales : 売上高\nOX : 事業利益(operating income)\nNFE : 純金融費用(net financial expenses)\nX : 当期純利益(net income)\nOA : 事業資産(operating assets)\nOL : 事業負債(operating liabilities)\nFE : 金融資産(financial assets)\nFO : 金融負債(financial obligations)\n\nこのデータフレームの構造を確認します。\n\nglimpse(financial_data)\n\nRows: 7,920\nColumns: 11\n$ year        <dbl> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ industry_ID <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sales       <dbl> 5261.40, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505…\n$ OX          <dbl> 437.49, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.…\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> 286.64, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.…\n$ OA          <dbl> 13005.55, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86…\n$ FA          <dbl> 3543.43, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 225…\n$ OL          <dbl> 4372.96, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840…\n$ FO          <dbl> 2480.72, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2…\n\n\n変数はすべて数値型doubleになっていますが、firm_IDとindustry_IDはカテゴリーを表す変数ですので、数値型ではなくファクター型に変換します。ついでにyearは年度という時間を尺度なので、数値型ではなくfactor型に変換します。ここで重要なのは、yearはただのファクター型ではなく、順序のあるファクター型とすることです。\nここではas.factor()を使います。\n\n# firm_IDとindustry_IDをfactor型に変換\nfinancial_data$year <- factor(financial_data$year, \n                            ordered = TRUE, \n                            levels = c(2015:2020)\n                            )\nfinancial_data$firm_ID <- as.factor(financial_data$firm_ID)\nfinancial_data$industry_ID <- as.factor(financial_data$industry_ID)\n\n# 確認\nglimpse(financial_data)\n\nRows: 7,920\nColumns: 11\n$ year        <ord> 2015, 2016, 2017, 2018, 2019, 2020, 2015, 2016, 2017, 2018…\n$ firm_ID     <fct> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4…\n$ industry_ID <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ sales       <dbl> 5261.40, 5948.96, 6505.06, 6846.38, 7572.24, 7537.63, 3505…\n$ OX          <dbl> 437.49, 564.14, 691.18, 751.29, 958.53, 778.37, 45.82, 51.…\n$ NFE         <dbl> NA, 50.667498, 29.543157, 86.486500, 298.049774, -65.45877…\n$ X           <dbl> 286.64, 513.48, 661.64, 664.80, 660.48, 843.83, 40.07, 49.…\n$ OA          <dbl> 13005.55, 13865.58, 13952.58, 18818.48, 18190.00, 20462.86…\n$ FA          <dbl> 3543.43, 4642.16, 7743.99, 7284.72, 9735.13, 10274.25, 225…\n$ OL          <dbl> 4372.96, 4534.22, 5111.22, 5137.28, 5487.96, 5371.38, 1840…\n$ FO          <dbl> 2480.72, 3959.70, 6159.02, 10123.91, 11362.22, 13772.15, 2…"
  },
  {
    "objectID": "Chap04.html#探索的データ分析",
    "href": "Chap04.html#探索的データ分析",
    "title": "4  財務データの取得と可視化",
    "section": "4.3 探索的データ分析",
    "text": "4.3 探索的データ分析\n\n4.3.1 データセットの概要確認\nデータセットを操作するまえに，データの概要を大まかにつかむ必要があり，この作業を探索的データ分析(exploratory data analysis)といいます。 仮説などを持たず，とりあえず特徴や構造を理解するための方法です。\n\n\n\n\n\n\nノート\n\n\n\n引数の型に応じて自動的に最適な結果を返す機能を多態性 (polymorphism)といい，多態性をもつ関数を総称関数(generic function)という。\n\n\n\nsummary(financial_data)\n\n   year         firm_ID      industry_ID       sales        \n 2015:1266   1      :   6   3      :1760   Min.   :    205  \n 2016:1293   2      :   6   10     :1702   1st Qu.:  16103  \n 2017:1319   3      :   6   7      :1334   Median :  40431  \n 2018:1323   4      :   6   1      :1143   Mean   : 166007  \n 2019:1356   5      :   6   9      : 667   3rd Qu.: 118314  \n 2020:1363   7      :   6   8      : 429   Max.   :3496433  \n             (Other):7884   (Other): 885                    \n       OX                 NFE                  X                   OA         \n Min.   :-353606.7   Min.   :-285383.9   Min.   :-357624.8   Min.   :    217  \n 1st Qu.:    399.3   1st Qu.:    -66.4   1st Qu.:    383.3   1st Qu.:  12560  \n Median :   1602.9   Median :     -1.2   Median :   1586.1   Median :  30799  \n Mean   :   7968.9   Mean   :     64.0   Mean   :   7904.9   Mean   : 152273  \n 3rd Qu.:   5260.5   3rd Qu.:     41.4   3rd Qu.:   5204.6   3rd Qu.:  93469  \n Max.   : 398034.5   Max.   : 331035.3   Max.   : 572588.7   Max.   :7987936  \n                     NA's   :1                                                \n       FA                 OL                FO         \n Min.   :     288   Min.   :     35   Min.   :     44  \n 1st Qu.:    6835   1st Qu.:   3965   1st Qu.:   3757  \n Median :   19095   Median :  10868   Median :  11125  \n Mean   :   80185   Mean   :  50261   Mean   :  70681  \n 3rd Qu.:   52118   3rd Qu.:  33111   3rd Qu.:  35446  \n Max.   :29250611   Max.   :2817975   Max.   :7026924  \n                                                       \n\n\nさらに，データセットのある変数に含まれる固有な要素を抽出するには，unique()関数を用います。\n\nunique(financial_data$year) # financial_dataのyear変数に含まれる固有要素\n\n[1] 2015 2016 2017 2018 2019 2020\nLevels: 2015 < 2016 < 2017 < 2018 < 2019 < 2020\n\n# 2015, 2016, 2017, 2018, 2019, 2020\n\n固有要素の数を確認するには，unique()関数で取り出した要素の数をlength()関数で返します。 企業-年の企業数と年度数を確認するには次のようにします。\n\nlength(unique(financial_data$firm_ID)) # 1515を返す\n\n[1] 1515\n\nlength(unique(financial_data$industry_ID)) # 10\n\n[1] 10\n\n\nよってこのデータには10の産業、1515の企業があることが分かります。\n\n\n4.3.2 欠損データの処理\nほとんどのデータセットには，欠損値(NA)が含まれているため，この欠損値の処理は非常に重要になります。 欠損値の有無を確認するためには，complete.cases()関数を用いるのが便利です。 欠損値が含まれているとFALSEを返し，欠損値がないとTRUEを返します。\n\nhead(complete.cases(financial_data)) # 最初の６行の結果を表示\n\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nsum()関数で，TRUEの個数を数え上げることもできます。\n\nsum(complete.cases(financial_data)) # TRUE/FALSEを1/0に置き換えて合計\n\n[1] 7919\n\n\n欠損値の出現に何らかの傾向がある場合，欠損値の削除が生存者バイアス(survivorship bias)をもたらす可能性があります。 たとえば，過去20年間にわたって連結財務諸表データに欠損値が含まれていない上場企業ばかりを分析すると，途中で倒産したり上場したりした企業は削除され，20年間経営し続けている優良企業しかデータに残らない生存者バイアスが発生します。\nこのようなバイアスを考慮しなくても良いなら，欠損値をもつ個体(unit)のデータ(行)を削除するのが単純な処理となります。 このとき，tidyrパッケージに含まれるdrop_na()関数を用いると簡単に欠損値を含む行を削除できます。 基本関数のna.omit()でもよいですが，tidyr::drop_na()の方がオプションが豊富なのでおすすめです。\n\nnrow(financial_data) # 欠損行を削除する前の行数\n\n[1] 7920\n\nnrow(drop_na(financial_data)) # 欠損行を削除した場合の行数\n\n[1] 7919\n\nfinancial_data <- drop_na(financial_data) # 欠損行を削除した上でデータを上書き\n# この作業には注意が必要である。オリジナルデータはそのまま残しておいたほうが良い\n\n欠損値を含む行を削除するのではなく，欠損値に適切な推定値を代入することでサンプルサイズを減らさない方法も開発されていますが，欠損値の出現を説明する確率モデルを仮定し，その推定値を求める必要があります。\n\n\n\n\n\n\nノート\n\n\n\n詳しくは髙橋・渡辺 (2019) 欠損データ処理：Rによる単一代入法と多重代入法 を参照してください。\nさらに欠損値についての議論では，星野・岡田 (2016)「欠測データの統計科学―医学と社会科学への応用」岩波書店がめちゃめちゃ有用です。"
  },
  {
    "objectID": "Chap04.html#データの抽出とヒストグラムによる可視化",
    "href": "Chap04.html#データの抽出とヒストグラムによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.4 データの抽出とヒストグラムによる可視化",
    "text": "4.4 データの抽出とヒストグラムによる可視化\n\n4.4.1 条件にあうデータの抽出方法\n教科書では複数の方法が紹介されているが，このメモではtidyverseパッケージを用いた方法だけ取り上げます。具体的には，データベース操作のパッケージであるdplyrの中のfilter()関数について説明します。 さらにmagrittrを用いたパイプ演算子%>%を用いたデータの受け渡しの記法を活用して，可読性の高いソースコードを書くことも紹介します。 ここではdplyrパッケージのfilter()関数であることを明示的に示すため、dplyr::filter()と書いていますが、dplyrパッケージを読み込んでいる場合はfilter()と書いても同じです。\n\nfinancial_data_2015 <- financial_data %>%\n    dplyr::filter(year == 2015) # year変数が2015のデータを抽出\n\nfilter()で条件を満たすデータのみを取り出し，それをfinancial_data_2015に代入している。\nパイプ演算子%>%は左のオブジェクトを右の関数の第1引数に代入する，という処理を行います。 つまり，x %>% filter(year == 2015)は，filter(x, year == 2015)と同じ意味になります。 パイプ演算子を使うことで，データが次の処理に受け渡されていくプロセスが読みやすくなります。たとえば、\n\n欠損値を除去して，\n2015年のデータを抽出し，\nROEを計算して，\n産業ごとに平均値を出す\n\nというよく使いそうな処理を行いたい場合，tidyverseなら次のように書きます。\n\nfinancial_data %>%\n    drop_na() %>% # 欠損値を除去し，\n    filter(year == 2015) %>% # 2015年のデータを抽出し，\n    mutate(ROE = earnings / equity) %>% # ROEを変数を作り，\n    group_by(industry) %>% # 業種コードごとに\n    summarise(mean_ROE = mean(ROE)) # mean()でROE平均を計算\n\n基本関数の場合は、\n\nfinancial_data <- na.omit(financial_data)\nfinancial_data_2015 <- financial_data[financial_data$year == 2015, ]\nfinancial_data_2015$ROE <- financial_data_2015$earnings / financial_data_2015$equity\nmean_ROE_by_industry <- aggregate(financial_data_2015$ROE, \n        by = list(financial_data_2015$industry), \n        FUN = mean)\n\nとなりますので、上の方が読みやすいことがわかります。\n\n\n4.4.2 ヒストグラムによる売上高の可視化\n\n4.4.2.1 ヒストグラム\nヒストグラム(histogram)は，データの分布を可視化するためのグラフです。 ヒストグラムは，連続データを区間に分けて，区間ごとのデータの個数を棒グラフで表現したものです。したがってヒストグラムの棒の高さは、その区間に含まれるデータの個数を表します。\nたとえば、例として生徒100人の身長データがあるとします。 この身長データをRで生成するには，rnorm()関数を使います。\n\n# 平均170cm，標準偏差5cmの正規分布から100個のデータを生成\nheight <- rnorm(100, mean = 170, sd = 5)\nprint(height)\n\n  [1] 169.6924 174.5469 176.3546 171.0446 175.6103 170.4743 164.5788 166.0442\n  [9] 161.9346 163.7407 157.3900 179.8433 168.5600 172.7645 172.0916 162.9906\n [17] 164.9894 176.5034 174.0555 176.4578 164.5827 165.0025 168.9452 172.8089\n [25] 174.2949 171.0870 175.8524 180.7838 164.3101 178.1985 164.9176 176.0124\n [33] 170.4831 171.7323 170.9961 177.1232 169.7548 168.2287 169.0044 175.0003\n [41] 169.3694 172.1525 167.8356 171.3804 170.3527 168.2850 170.3796 162.3475\n [49] 164.0759 162.8132 168.2428 172.1306 173.8485 172.2481 167.0463 177.1396\n [57] 175.6116 170.5064 162.7817 162.8524 169.9775 171.3020 169.9325 171.4664\n [65] 180.8614 161.3915 168.1194 176.5041 177.4252 162.1188 171.4196 175.6819\n [73] 167.0647 169.8203 169.9235 167.6972 164.7486 168.0285 172.3546 173.3254\n [81] 169.8629 164.4961 174.7364 166.4179 177.7701 175.6074 179.5678 167.9054\n [89] 161.5347 166.5031 171.4887 173.6740 173.6661 168.2252 164.6050 168.9659\n [97] 166.2311 165.0904 170.7562 177.4817\n\n\n100個のデータを眺めていても、なかなか特徴をつかめませんよね。そこでこの身長という連続データを5センチごとの区間に分けます。 たとえば、165cm以上、170cm未満の区間には何人の生徒がいるのか、170cm以上、175cm未満の区間には何人の生徒がいるのか、というように区間ごとのデータの個数を数えます。 このとき、区間の幅を5cmにするか、10cmにするか、20cmにするか、ということは、データの特徴をつかむ上で重要なことです。 区間の幅を大きくすると、データの特徴がざっくりとしかつかめません。 一方、区間の幅を小さくすると、データの特徴が細かくつかめますが、データの個数が少ない区間が多くなり、データの特徴をつかむのに時間がかかります。 やってみましょう。\n\nhist(height, breaks = seq(150, 190,by = 1)) # 区間の幅を1cmにする\n\n\n\nhist(height, breaks = seq(150, 190,by = 5)) # 区間の幅を5cmにする\n\n\n\nhist(height, breaks = seq(150, 190,by = 10)) # 区間の幅を10cmにする\n\n\n\n\nどのヒストグラムがデータの特徴を最も良く表しているのか、を考えて区間幅を設定しましょう。\n\n\n4.4.2.2 ggplotでヒストグラム\nヒストグラムを書くためには，基本関数のhist()が最も簡単ですが，より高性能なggplot2を用いたヒストグラムの書き方を説明します。 ここでは、上で作成した2015年のデータfinancial_data_2015を使って、売上高のヒストグラムを書きます。\nggplot2の書き方は少し特殊ですが、慣れてくると非常に便利です。 ggplot2ではレイヤー(階層)を上から重ねていくようにグラフを作っていきます。 まずggplot()関数でグラフの土台を作ります。ggplot()に入れるデータの型はdata.frameでなければならないので注意しましょう。\nggplot()の中で読み込むデータを指定して、gというオブジェクトに代入し、それを表示させます。\n\ng <- ggplot(data = financial_data_2015) # グラフにしたいデータを指定\nprint(g) # 出力\n\n\n\n\n真っ白で何も出力されていませんが、financial_data_2015というデータフレームを指定して、グラフの土台を作りました。\n次に軸の設定をします。ヒストグラムは1変数のグラフなのでx軸のみを設定します。aes()関数で変数を指定します。先ほど作成したgにaes()関数を+で追加していきます。\n\ng <- g + aes(x = sales) # x軸を売上高にする\nprint(g) # 出力\n\n\n\n\n横軸が表示されました。 この上に、ヒストグラムを書くためにgeom_histogram()関数を追加します。 ggplot2パッケージでは、geom_***の形でグラフを指定します。例えば、\n\ngeom_bar 棒グラフ\ngeom_point 散布図\ngeom_line 折れ線グラフ\ngeom_boxplot 箱ひげ図\ngeom_histogram ヒストグラム\n\nあたりがよく使われるグラフです。\n\ng <- g + geom_histogram() # グラフはヒストグラム\nprint(g)\n\n\n\n\nここでコンソールに，\n\nstat_bin() using bins = 30. Pick better value with binwidth.\n\nというメッセージが出ますが、これは「何も指定されなかったので，ヒストグラムのビンの数を30にして作図したけど，オプションのstat_bin()で適切な区間幅をbinwidthで設定してね」ということです。無視しても大丈夫です。\nx軸が指数表記となっていて見づらいので，scales()関数を使って表記を変更します。\n\ng <- g + scale_x_continuous(label = scales::label_comma()) # 3桁ごとにコンマで区切った数値で表示\nprint(g)\n\n\n\n\n横軸の数値が変化したことが分かります。\nまた、小数ながら非常に大きな売上高をもつ企業があるため，ヒストグラムの形が左側に集まるように歪んでいます。 そこで売上高を自然対数に変換して，分布の歪みを修整したヒストグラムを書いてみます。 データを変更するので、最初から全部書きます。\n\ng <- ggplot(financial_data_2015) + # データの読み込み\n  aes(x = log(sales)) + # x軸を売上の自然対数に\n  geom_histogram() # ヒストグラム\nprint(g) # 出力\n\n\n\n\nうまくいきました。 ついでにいろいろなオプションをつけてみます。\n\nlibrary(ggthemes)\nmystyle <- list (#  ggplotのテーマ\n  theme_calc(), # ggthemesパッケージ\n  scale_colour_calc(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n\ng <- g + xlab(\"売上高の自然対数\") + ylab(\"度数\") + mystyle # 先ほどのスタイルを適用\nprint(g)"
  },
  {
    "objectID": "Chap04.html#データの集計と折れ線グラフによる可視化",
    "href": "Chap04.html#データの集計と折れ線グラフによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.5 データの集計と折れ線グラフによる可視化",
    "text": "4.5 データの集計と折れ線グラフによる可視化\n\n4.5.1 dplyrを用いた集計\nもっとデータを加工して、データの特徴をつかむグラフを作成してみます。 データを加工するために、非常に便利なパッケージであるtidyverseのdplyrを用いたデータ加工を説明します。dplyrでよく使う関数に、\n\ngroup_by() ：グループ化\nsummarise() ： 集計\nmutate() ： 変数の追加\nfilter()： データの抽出\n\nがあります。これらの関数を組み合わせることで、データの加工が非常に簡単にできます。たとえば、financial_dataに含まれる売上高を年度ごとに集計してみましょう。dplyrのgroup_by()関数を使うと、変数を指定してデータをグループ化することができます。たとえば、yearを指定すると、年度ごとにデータをグループ化します。 group_by()でグループ化したあとに、summarise()関数を使って平均や分散などの統計量を計算します。\n\nN_firms_by_year <- financial_data %>%\n    group_by(year) %>% # 年度ごとにグループ化\n    summarize( # 以下の統計量を計算\n        N_firms = n(), # データ個数 n()\n        mean_sales = mean(sales) # 売上高の年度平均 mean()\n)\n\nこれでN_firms_by_yearというオブジェクトに、financial_dataを年度ごとにグループ化して、年度ごとの企業数N_firmsと平均売上高mean_saleを計算したデータが入っています。 2015年から2020年の6年間のデータがあるので、6行のデータが入っているはずです。 中身を確認しておきましょう。\n\nglimpse(N_firms_by_year)\n\nRows: 6\nColumns: 3\n$ year       <ord> 2015, 2016, 2017, 2018, 2019, 2020\n$ N_firms    <int> 1265, 1293, 1319, 1323, 1356, 1363\n$ mean_sales <dbl> 173614.9, 173359.5, 170010.9, 157995.4, 160928.2, 161043.7\n\n\n以下の変数について6個のデータが入っていることがわかります。\n\nyear : 年度 (ord)\nN_firms : 企業数 (int)\nmean_sales : 平均売上高 (dbl)\n\n\n\n\n\n\n\nノート\n\n\n\n関数型プログラミング(functional programming)は，現代的なプログラミング・パラダイムの1種であり，定義された関数を用いて各データに対して行いたい処理を切り分ける。Rではapply系関数として，様々な関数が用意されている。tidyverse群では，purrrがある。ちょっと難しいですがpurrr超便利\n\n\n\n\n4.5.2 折れ線グラフによる上場企業数の可視化\nデータの成形が終わったので，折れ線グラフを作っていきます。 ここではx軸(横軸)を年度year，y軸(縦軸)を上場企業数N_firmsとする折れ線グラフを作ってみます。 折れ線グラフを作るにはgeom_line()関数を使います。\n\ng <- ggplot(N_firms_by_year) +\n    aes(x = year, y = N_firms, group=1) +\n    geom_line()\ng <- g + labs(x = \"Year\", y = \"Number of Firms\") + mystyle# 軸ラベル\nprint(g)\n\n\n\n\nここで突然現れたgroup = 1というaes()のオプションですが、これはすべてのデータが同じグループに属していることを指定しています。 x軸にファクター型を指定する場合、group = 1を指定しないと、x軸の値ごとに別のグループとして認識されてしまい、折れ線グラフがうまく描けません。"
  },
  {
    "objectID": "Chap04.html#変数の作成とヒストグラムによる可視化",
    "href": "Chap04.html#変数の作成とヒストグラムによる可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.6 変数の作成とヒストグラムによる可視化",
    "text": "4.6 変数の作成とヒストグラムによる可視化\ntidyverseのdplyrパッケージのmutate()関数を用いれば，パイプ演算子%>%を用いて可読性の高いシンプルな書き方で、新しい変数を作成することができます。\n\n\n\n\n\n\nキーボードショートカット\n\n\n\nMacならcommand + shift + mでパイプ演算子が入力できます。 Windowsならctrl + shift + mです。\n\n\nここでは，ROE(Return on Equity)を計算してみます。 ROEの定義は，\n\nROE_t = \\frac{X_t}{BE_{t-1}}\n\nとなります。 分子のX_tはt期の当期純利益，分母のBE_{t-1}はt期首の株主資本です。 練習用データであるfinancial_date.csvには，当期純利益はXという列名で収録されていますが、株主資本の列はありません。 よってデータから株主資本は次のように計算します。\n\nBE_t = \\underbrace{(OA_t - OL_t)}_{NOA_t} - \\underbrace{(FO_t - FA_t)}_{NFO_t}\n\nこの計算を行い，新しい変数BEをデータフレームに加えるには，dplyr::mutate()を使います。\n\nfinancial_data <- financial_data %>%\n    mutate(\n        BE = (OA - OL) - (FO - FA) # 新たなBE変数が加わる\n    )\n\n分母の株主資本は期首，つまり前期末の数値を用いる必要があります。 1期前の値を参照するには，lab()関数を用います。 ただ，クロスセクションのデータで普通にlag()関数を用いると，次のように別の企業のデータを参照してしまいます。\n\nfinancial_data <- financial_data %>%\n    mutate(\n        lag_BE = lag(BE),\n        ROE = X / lag_BE # これはダメ\n    )\n\nhead(financial_data, 10)[,c(\"firm_ID\", \"year\", \"BE\",\"lag_BE\",\"ROE\")]\n\n# A tibble: 10 × 5\n   firm_ID year      BE lag_BE      ROE\n   <fct>   <ord>  <dbl>  <dbl>    <dbl>\n 1 1       2016  10014.    NA  NA      \n 2 1       2017  10426. 10014.  0.0661 \n 3 1       2018  10842. 10426.  0.0638 \n 4 1       2019  11075. 10842.  0.0609 \n 5 1       2020  11594. 11075.  0.0762 \n 6 2       2015   1055. 11594.  0.00346\n 7 2       2016   1082.  1055.  0.0468 \n 8 2       2017   1135.  1082.  0.0702 \n 9 2       2018   1184.  1135.  0.0763 \n10 2       2019   1237.  1184.  0.0770 \n\n\n結果のfirm_IDが2の企業の2015年のROEを計算するには，1期前の企業1の2014年の株主資本を参照する必要があるけれど，2014年のデータは存在しないため、企業2の2015年度のROEは欠損値NAになっている必要があるのに、lag()関数が1つ前の企業1の2020年の株主資本を参照してしまっています。 ROEを企業ごとに計算するために，dplyr::group_by()を使って，計算を企業群ごとに行うことで、この問題を解決できます。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # firm_IDごとに以下の処理を繰り返す\n    mutate(\n        lagged_BE = lag(BE), # lag関数で前期の値を取り出す\n        ROE = X / lagged_BE # これはOK\n    ) %>%\n    ungroup() # group化を解除\nhead(financial_data, 10)[,c(\"firm_ID\", \"year\", \"BE\",\"lagged_BE\",\"ROE\")]\n\n# A tibble: 10 × 5\n   firm_ID year      BE lagged_BE     ROE\n   <fct>   <ord>  <dbl>     <dbl>   <dbl>\n 1 1       2016  10014.       NA  NA     \n 2 1       2017  10426.    10014.  0.0661\n 3 1       2018  10842.    10426.  0.0638\n 4 1       2019  11075.    10842.  0.0609\n 5 1       2020  11594.    11075.  0.0762\n 6 2       2015   1055.       NA  NA     \n 7 2       2016   1082.     1055.  0.0468\n 8 2       2017   1135.     1082.  0.0702\n 9 2       2018   1184.     1135.  0.0763\n10 2       2019   1237.     1184.  0.0770\n\n\n2015年のROEが欠損値になっており、正しい計算ができています。 クロスセクション分析におけるlag()関数の問題点を分かりやすくするために、上のようにlagged_BE変数とROE変数を別々に作成しましたが、通常は次のように書きます。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # firm_IDごとに以下の処理を繰り返す\n    mutate(\n        ROE = X / lag(BE) # これで一気に計算する方がOK\n    ) %>%\n    ungroup() # group化を解除\n\nこれでROEの計算ができので、次にROEのヒストグラムを作ってみます。\n\ng <- ggplot(financial_data) + # データの選択\n    aes(x = ROE) + geom_histogram()\ng <- g + scale_x_continuous(limits = c(-0.3, 0.5)) # x軸の範囲を調整\nprint(g)\n\n\n\n\nROEの分布が分かりました。赤字企業が分かりやすいように、ROEがゼロのところに縦線を引いてみます。 縦線を引くにはgeom_vline()を使い、横線を引くにはgeom_hline()を使います。\n\ng <- g + geom_vline(xintercept = 0, color = \"red\") # x軸に縦線を引く\nprint(g)"
  },
  {
    "objectID": "Chap04.html#グループごとの集計とランク付け",
    "href": "Chap04.html#グループごとの集計とランク付け",
    "title": "4  財務データの取得と可視化",
    "section": "4.7 グループごとの集計とランク付け",
    "text": "4.7 グループごとの集計とランク付け\n\n4.7.1 産業ごとのROE平均値と棒グラフによる可視化\nグループごとに平均値を出すといった処理は，dplyrのgroup_by()とsummarise()を用いることで簡単にできます。\nここでは、産業ごとにROEの平均値と標準偏差を求めてみます。ROEには欠損値が含まれているため、mean()関数を使うとNAが返ってきます。NAを無視して平均値を計算するには、mean()関数のオプションna.rm = TRUEを指定します。\n\ndf_ind <- financial_data %>%\n    group_by(industry_ID) %>% # 集計したいグループを指定\n    summarize(\n        mean_ROE = mean(ROE, na.rm = TRUE), # 産業平均\n        sd_ROE = sd(ROE, na.rm = TRUE)　# 産業標準偏差\n    )\nglimpse(df_ind)\n\nRows: 10\nColumns: 3\n$ industry_ID <fct> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ mean_ROE    <dbl> 0.07731106, 0.10761577, 0.07548896, 0.07371925, 0.08570296…\n$ sd_ROE      <dbl> 0.09264764, 0.09530125, 0.05569899, 0.04676826, 0.04859797…\n\n\n10の産業ごとに統計量を計算したので、10行のデータが返ってきました。 このデータを用いて産業ごとのROE平均の棒グラフを作成してみます。\n\n# 作図\nggplot(df_ind) + # データフレームを指定\n    aes(x = industry_ID, y = mean_ROE) + # 変数を2つ指定\n    geom_col() + # 棒グラフ geom_bar()もあるけどこっち\n    labs(x = \"産業ID\", y = \"産業平均ROE\") + # ラベル設定\n    scale_y_continuous(expand = c(0,0)) + mystyle # グラフの原点0,0に設定\n\n\n\n\n教科書では，パイプ処理%>%で直接ggplot()にデータフレームを渡していますが，個人的に可読性が低くなりオススメできないので，上の例ではデータ操作と作図を分けて書きました。 好みの問題なので、どちらでも構いません。\n次に、2020年度の産業別ROEランキングを作ってみます。 ROEを大きい順にならべて、一番大きい企業に1、2番目の企業に2、という風にランキングを表す変数を作成するには、rank(desc())を使います。desc()は降順に並べ替える関数です。\n下のソースコードでは、前半のまとまりで、以下の処理を行ったデータを新しいデータフレームROE_rank_dataに代入しています。\n\nfinancial_dataの中から2020年度のデータを抽出し、\n必要な変数としてfirm_ID、industry_ID、ROEの3つを選択し、\nindustry_IDごとにグループ化して、\nmutate()関数でROE_rank変数を作成し,\nungroup()関数でグループ化を解除しています。\n\n後半のまとまりでは、上で作成したROE_rank_dataに対して、\n\n産業ごとのROEランキング第1位の企業を抽出し、\nROEが大きい順に並べ替えて、\nそれをknitr::kable()関数で表として出力\n\nという処理をしています。\n\n# 2020年度の産業内のROEランキングの変数を作成\nROE_rank_data <- financial_data %>%\n    filter(year == 2020) %>% # 2020年度データを抽出\n    select(firm_ID, industry_ID, ROE) %>% # 必要な変数を選択\n    group_by(industry_ID) %>% # 産業コードごとに以下の処理を実行\n    mutate(\n        ROE_rank = rank(desc(ROE)) # ROE_rank変数を降順で作成\n    ) %>%\n    ungroup()# グループ化を解除\nprint(ROE_rank_data)\n\n# A tibble: 1,363 × 4\n   firm_ID industry_ID     ROE ROE_rank\n   <fct>   <fct>         <dbl>    <dbl>\n 1 1       1           0.0762        85\n 2 2       1           0.0728        90\n 3 3       1           0.119         36\n 4 4       1           0.0216       154\n 5 5       1           0.113         39\n 6 7       1           0.00379      167\n 7 8       1           0.388          1\n 8 9       1           0.0913        68\n 9 10      1           0.111         44\n10 11      1           0.130         28\n# ℹ 1,353 more rows\n\n\n上の処理により、financial_dataのデータフレームにROE_rankという変数が追加して、ROE_rank_dataという新しいオブジェクトに代入しました。\n\nROE_rank_data %>%\n    filter(ROE_rank == 1) %>% # 各産業のランク1のものを抽出\n    arrange(desc(ROE)) %>%  # ROEが大きい順\n    knitr::kable(booktabs = TRUE, # ここから下は表の装飾\n        caption = \"2020年度産業別ROEランキング第1位企業\",\n        position = \"h!\" # 表示場所はここに\n        )\n\n\n2020年度産業別ROEランキング第1位企業\n\n\nfirm_ID\nindustry_ID\nROE\nROE_rank\n\n\n\n\n929\n7\n0.5641813\n1\n\n\n475\n3\n0.4975356\n1\n\n\n8\n1\n0.3882552\n1\n\n\n242\n2\n0.3749986\n1\n\n\n661\n5\n0.2673141\n1\n\n\n1042\n8\n0.2559963\n1\n\n\n1380\n10\n0.2497929\n1\n\n\n1167\n9\n0.2346232\n1\n\n\n619\n4\n0.1491307\n1\n\n\n719\n6\n0.1422026\n1\n\n\n\n\n\nindustry_IDが7の産業の中のfirm_IDが929の企業のROEが0.5641813ということがわかりました。 この企業は、financial_dataの中でどのような企業なのかを調べてみましょう。\n\nfinancial_data %>%\n    filter(firm_ID == 929) %>% # firm_IDが929の企業を抽出\n    select(firm_ID, industry_ID,sales,OX,BE, ROE) %>% # 必要な変数を選択\n    knitr::kable(booktabs = TRUE, # ここから下は表の装飾\n        caption = \"企業929のROE\",\n        position = \"h!\" # 表示場所はここに\n        )\n\n\n企業929のROE\n\n\nfirm_ID\nindustry_ID\nsales\nOX\nBE\nROE\n\n\n\n\n929\n7\n10696.59\n-3.23\n1134.92\nNA\n\n\n929\n7\n12423.11\n17.16\n971.44\n0.0297113\n\n\n929\n7\n8148.15\n-48.69\n980.28\n-0.0437907\n\n\n929\n7\n8173.33\n-687.52\n668.91\n-0.7019219\n\n\n929\n7\n1562.78\n132.68\n804.05\n0.2020302\n\n\n929\n7\n5832.03\n490.84\n1257.68\n0.5641813\n\n\n\n\n\n業績のばらつきが大きく、ROEも乱高下する企業であることが分かりました。"
  },
  {
    "objectID": "Chap04.html#上級デュポンモデルによるroeの分析とその可視化",
    "href": "Chap04.html#上級デュポンモデルによるroeの分析とその可視化",
    "title": "4  財務データの取得と可視化",
    "section": "4.8 上級デュポン・モデルによるROEの分析とその可視化",
    "text": "4.8 上級デュポン・モデルによるROEの分析とその可視化\n上級デュポン・モデルとは，次式で表されるROEの分解式です。\n\n\\begin{aligned}\nROE_t := \\frac{X_t}{BE_{t-1}} &= \\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} + \\underbrace{\\frac{NFO_{t-1}}{BE_{t-1}}}_{FLEV_{t-1}} \\times \\left[ \\frac{OX_t}{NOA_{t-1}} - \\frac{NFE_t}{NFO_{t-1}} \\right]\n\\end{aligned}\n\n各変数の意味は以下の通りです。 - X : 当期純利益(net income) - BE : 株主資本(book of equity) - OX : 事業利益(operating income) - NOA : 純事業資産(net operating assets) - NFO : 純金融負債(net financial obligations) - NFE : 純金融費用(net financial expenses)\nRNOA_tは，ATO_tとPM_tとに分割できます。\n\n\\underbrace{\\frac{OX_t}{NOA_{t-1}}}_{RNOA_t} = \\underbrace{\\frac{sales_t}{NOA_{t-1}}}_{ATO_t} \\times \\underbrace{\\frac{OX_t}{sales_t}}_{PM_t}\n\nいくつかの変数は，元のデータには含まれていないので，与えられたデータから計算する必要があります。 dplyr::mutate()関数を用いて新しい変数を作成し，データフレームに追加します。 lag()で前期末(つまり当期首)の値を取得するため，group_by()関数で企業ごとにグループ化しています。\n\nfinancial_data <- financial_data %>%\n    group_by(firm_ID) %>% # 企業IDごとに以下の計算を行う。\n    mutate(\n        NOA = OA - OL, # 純事業資産 = 事業資産 - 事業負債\n        RNOA = OX / lag(NOA), # 会計上の事業リターン\n        PM = OX / sales, # 利ざや profit margin\n        ATO = sales / lag(NOA), # 純事業資産回転率\n        NFO = FO - FA, # 純金融負債 = 金融負債 - 金融資産\n        lagged_FLEV = lag(NFO) / lagged_BE, #期首財務レバレッジ\n        NBC = NFE / lag(NFO), # 債権者のリターン net borrowing cost\n        ROE_DuPont = RNOA + lagged_FLEV * (RNOA - NBC) # 上級デュポン・モデルによるROE\n    ) %>%\n    ungroup()\n\nROEの分解式が合っているかどうかを確認するため，all.equal()関数を使って，第1引数と第2引数が等しいかどうかを判定してみます。 普通に計算したROEと上級デュポン・モデルの分解したものから計算したROE_DuPointとの比較しています。\n\nall.equal(financial_data$ROE, financial_data$ROE_DuPont)\n\n[1] \"Mean relative difference: 4.396878e-06\"\n\n\nとなり，差の平均は4.396878 \\times 10^{-6}となり，ほぼ0となっていることから，上級デュポン・モデルの分解式が正しいことが確認できます。 完全にゼロにならない理由は計算の過程で生じる丸め誤差によるものです。\n\n4.8.1 箱ひげ図による産業別比較\n産業別で利ざやPMがどのように分布しているのかを調べるために，箱ひげ図(box plot)を作ってみます。 箱ひげ図は，データの分布を可視化するためのグラフで，第1四分位点，中央値，第3四分位点，(異常値をのぞく)最大値，(異常値をのぞく)最小値を表現できる，非常に情報量の多いグラフです。\nggplot2パッケージのgeom_boxplot()関数を用いることで，データフレームから箱ひげ図を作図できます。\n先に作成したデータフレームfinancial_dataを用いて，PMの箱ひげ図を作成してみましょう。 あまり多くの箱ひげ図を作っても見づらくなるので，最終年度のデータ で，産業IDが2〜6までの企業に限定します。\n\ndf_2020 <- financial_data %>%\n    filter(\n        year == 2020, # 最終年度\n        industry_ID %in% 2:6 # 産業コードが2から6\n    )\ng <- ggplot(df_2020) +\n  aes(x = industry_ID, y = PM, fill = industry_ID) + \n  geom_boxplot() # 箱ひげ図\ng <- g + labs(x = \"Industry ID\") + mystyle\nprint(g)\n\n\n\n\n箱ひげ図から，産業ごとに利ざやの分布が異なることがわかります。とりわけ産業3は利ざやの散らばりが大きく，産業4は非常に散らばりが小さいことが分かります。\n\n\n4.8.2 散布図による産業別比較\n次に産業ごとに ATO(純事業資産回転率)と PM(売上高事業利益率)がどう分布しているか散布図を書いてみます。 ここでは異常値の影響を受けにくい統計量である中央値(median)を計算し，散布図を作成してみます。\n\ndf_ind_median <- financial_data %>%\n    group_by(industry_ID) %>%\n    summarise(\n        median_ATO = median(ATO, na.rm = TRUE), # ATOの中央値\n        median_PM = median(PM, na.rm = TRUE) # PMの中央値\n    )\n\ng <- ggplot(df_ind_median) + \n    aes(x = median_ATO, y = median_PM, label = industry_ID) + # 散布図\n    geom_point() + # 散布図\n    geom_text(vjust=-1) + \n    xlab(\"純事業資産回転率(ATO)の中央値\") + ylab(\"売上高事業利益率(PM)の中央値\") + mystyle# ラベル\nprint(g)\n\n\n\n\nこの産業ごとに計算された中央値のデータを用いて，線形回帰直線を引いて，ATOとPMの関係を見てみます。\n\ng <- g + geom_smooth(method = \"lm\", se = FALSE) # 線形回帰直線を追加\nprint(g)\n\n\n\n\nいい感じですが，会計学入門(1.3.4節)で学習したATO \\times RM = RNOAという関係のとおり，データからもATOとPMとの間にトレードオフの関係があることが予想されています。 もし理論どおりの関係であればデータはATO = RNOA / PMといった反比例の関係になるはずです。これを示すため，RNOAを一定としたときのATOとPMの関係，つまりを図に書き込んでみます。 関数をグラフとして図に追加するためにstat_function()関数を用います。\n\n\n\n\n\n\nTips\n\n\n\nstat_function()関数の引数は，fun = function(x) xの関数系, linetype = “スタイル”とします。 ここでは，function(x)でxの関数であることを指定し，median_RNOA / xとしてます。\n\n\n\nmedian_RNOA <- median(financial_data$RNOA, na.rm = TRUE) # 全データから計算したRNOAの中央値\n\ng <- g + stat_function(\n    fun = function(x) median_RNOA / x, \n    linetype = \"longdash\", \n    color = \"red\") # 反比例の関数を追加\nprint(g)\n\n\n\n\nかなりあてはまりが良さそうな線が引けました。 このように，データを可視化することで，理論とデータの整合性を確認することができます。"
  },
  {
    "objectID": "Chap05.html",
    "href": "Chap05.html",
    "title": "5  株式データの取得と可視化",
    "section": "",
    "text": "6 リターンの累積\nここでは，株式データと財務データを組み合わせて分析を行います。\n年次財務データannual_dataを使って線形回帰(linear regression)について学習します。 線形(linear)とは，Xと\\betaの積が線形であることを意味します。回帰(regression)とは，Xと\\betaの積がYを説明することを意味します。 回帰は，2変数間の間で、一方の変数が他方の変数に対して影響を与えるという関係を想定できる場合に用いられます。 しかし因果関係を直接調べているのではないことに注意しましょう。\n影響を与える変数を説明変数(explanatory variable)や独立変数(independent variable)といい、 影響を与えられる変数を目的変数(response variable)や従属変数(dependent variable)といいます。 分野などでどっちを使うのかは異なりますが、ここでは説明変数と目的変数を使います。\n線形関係を仮定した関係を式にすると，次のようになります。 \nY = \\alpha + \\beta X\n ここで， \\alphaは定数項(constant term)と呼ばれ，切片(intercept)とも呼ばれます。 \\betaは回帰係数(regression coefficient)と呼ばれ，傾き(slope)とも呼ばれます。\n実際のデータが上のモデルを満たす、つまりすべてのデータが直線上に並んでいるわけではないのです。 実際のデータとモデルとの間にはずれがあることを考慮して、上のモデルを次のように書き換えます。\nY = \\alpha + \\beta X + u\n ここでuは誤差項(error term)とか観察不可能項(unobservable term)と呼ばれます。\n線形回帰の目的は，XとYの関係を表す\\alphaと\\betaを推定することです。 推定するために，観測できるデータを使います。 観測できるデータはXとYのペアで(X_i, Y_i)と表記します。 このペアを観測値(observed value)と呼びます。 この観測値は，XとYの関係を表す\\alphaと\\betaを推定するために使われます。 推定するために使われる\\alphaと\\betaを推定値(estimated value)と呼びます。 推定値は，\\hat{\\alpha}と\\hat{\\beta}と表記して，観察値と区別します。"
  },
  {
    "objectID": "Chap05.html#時価総額とリターンの計算",
    "href": "Chap05.html#時価総額とリターンの計算",
    "title": "5  株式データの取得と可視化",
    "section": "5.1 時価総額とリターンの計算",
    "text": "5.1 時価総額とリターンの計算\n時価総額(market capitalization)を計算するためには、株式数に株価を掛けて計算します。 新しい変数を作成するときはdplyrパッケージのmutate()関数を使います。 mutate()で時価総額を表す新しい変数MEを作成します。\n\nstock_data <- stock_data %>%\n  mutate(ME = stock_price * n_shares) # 時価総額MEを作成\n\n次に時価総額のヒストグラムを作成してみます。 前節で学習した内容に加えて、いろいろ見た目の指定を増やしてみます。 グラフの体裁を整えるため、ggplot2の機能を拡張するggthemesパッケージを追加します。\n\nlibrary(ggthemes) # グラフの体裁を整えるパッケージを追加\nlibrary(scales) # 軸の表記を変えるパッケージを追加\nmystyle <- list (#  ggplotのテーマ\n  theme_few(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=12,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\n\ng <- ggplot(stock_data) + aes(x = ME)\ng <- g + geom_histogram() #基本設定\ng <- g + xlab(\"Market Equity\") + ylab(\"Count\") #軸ラベル\ng <- g + scale_x_continuous(\n  limits = c(0, quantile(stock_data$ME, 0.95)), # x軸の範囲\n  labels = label_comma(scale = 1e-6) # x軸の表記を百万円単位に\n  ) + xlab(\"時価総額\") + ylab(\"度数\") +  mystyle\nprint(g) # グラフを出力\n\n\n\n\n\n5.1.1 トータル・リターンと超過リターンの計算\nある株式のt期のトータル・リターンR_tは、次式で定義されます。\n\nR_t = \\frac{(\\text{株価}_t + \\text{1株当り配当}_t) \\times \\text{調整係数}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\nたいていの場合，1株当り配当DPS_tはゼロで，調整係数adjustment\\_coefficient_tは1となるため，次式のように簡略化できます。\n\nR_t = \\frac{\\text{株価}_t - \\text{株価}_{t-1}}{\\text{株価}_{t-1}}\n\n銘柄ごとにリターンを計算するので，group_by()とmutate()を使って計算します。ここでは，firm_IDごとにトータルリターンRと， トータルリターンから無リスク利子率を除いた超過リターンReを計算しています。\n\nstock_data <- stock_data %>%\n  group_by(firm_ID) %>% # 企業ごとに\n  mutate( # 新しい変数を作成\n    # トータルリターン\n    R = ( (stock_price + DPS) * adj_coef - lag(stock_price)) / lag(stock_price),\n    Re = R - R_F # 月次超過リターン\n  ) %>%\n  ungroup() # グループ化を解除\n\nここまでの処理でstock_dataに時価総額ME，トータルリターンR，超過リターンReが追加されました。 以下では，このデータを使って探索的データ分析を行います。\n\n\n5.1.2 株式データの探索的データ分析\n探索的データ分析という名の，とりあえず何も考えずに目の前のデータから何が分かるのかを調べ倒してみる，という分析を行います。\nとりあえず，summary()で基本統計量を確認します。\n\nsummary(stock_data)\n\n      year          month          month_ID        firm_ID      \n Min.   :2015   Min.   : 1.00   Min.   : 1.00   Min.   :   1.0  \n 1st Qu.:2016   1st Qu.: 3.75   1st Qu.:19.00   1st Qu.: 384.0  \n Median :2018   Median : 6.50   Median :37.00   Median : 760.0  \n Mean   :2018   Mean   : 6.50   Mean   :37.01   Mean   : 761.2  \n 3rd Qu.:2019   3rd Qu.: 9.25   3rd Qu.:55.00   3rd Qu.:1147.0  \n Max.   :2020   Max.   :12.00   Max.   :72.00   Max.   :1515.0  \n                                                                \n  stock_price          DPS              n_shares            adj_coef     \n Min.   :   112   Min.   :   0.000   Min.   :3.700e+04   Min.   :0.1000  \n 1st Qu.:  1417   1st Qu.:   0.000   1st Qu.:3.151e+06   1st Qu.:1.0000  \n Median :  2445   Median :   0.000   Median :1.014e+07   Median :1.0000  \n Mean   :  4685   Mean   :   6.802   Mean   :6.973e+07   Mean   :0.9999  \n 3rd Qu.:  4558   3rd Qu.:   0.000   3rd Qu.:3.564e+07   3rd Qu.:1.0000  \n Max.   :622796   Max.   :1913.000   Max.   :2.111e+10   Max.   :2.0000  \n                                                                         \n      R_F                   ME                  R                 Re         \n Min.   :-2.329e-04   Min.   :1.459e+08   Min.   :-0.3803   Min.   :-0.3802  \n 1st Qu.: 8.233e-06   1st Qu.:9.648e+09   1st Qu.:-0.0406   1st Qu.:-0.0408  \n Median : 8.203e-05   Median :2.563e+10   Median : 0.0103   Median : 0.0101  \n Mean   : 2.041e-04   Mean   :1.365e+11   Mean   : 0.0159   Mean   : 0.0157  \n 3rd Qu.: 4.626e-04   3rd Qu.:7.987e+10   3rd Qu.: 0.0648   3rd Qu.: 0.0646  \n Max.   : 7.368e-04   Max.   :3.293e+13   Max.   : 0.5150   Max.   : 0.5145  \n                                          NA's   :1515      NA's   :1515     \n\n\nさらに，分散と標準偏差も計算します。データには欠損値が含まれているため，na.rm = TRUEオプションをつけています。 教科書とは違いますが，dplyr::summarize()関数を使って一気に複数の統計量を計算します。 ここでは，stock_data <- stock_dataとしていないため，stock_dataには新しい変数は追加されず，結果を表示するだけです。\n\nstock_data %>%\n  summarise(\n    var_R = var(R, na.rm = TRUE), # 総リターンの分散\n    sd_R  = sd(R, na.rm = TRUE), # 総リターンの標準偏差\n    var_Re = var(Re, na.rm = TRUE), # 超過リターンの分散\n    sd_Re = sd(Re, na.rm = TRUE) # 超過リターンの標準偏差\n  )\n\n# A tibble: 1 × 4\n    var_R   sd_R  var_Re  sd_Re\n    <dbl>  <dbl>   <dbl>  <dbl>\n1 0.00830 0.0911 0.00830 0.0911\n\n\nデータの分布の形を表す統計量である，3次のモーメントである歪度(skewness)と4次のモーメントである尖度(kurtosis)も計算してみます。 たとえば確率変数xの歪度は \n\\text{歪度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^3\n で表され，正の値をとるとき分布が右に歪んでいる(裾が右に長い)ことを示している。 尖度は， \n\\text{尖度} = \\frac 1n \\sum _{i = 1}^n \\left( \\frac{x_i - \\bar x}{\\hat \\sigma_x} \\right) ^4\n で定義され，尖度が3のとき，正規分布と同じ尖度を持つことを示し，3より小さいとき，正規分布よりとがった分布をしていることを示します。\n歪度と尖度を計算するには，e1071パッケージのskewness()関数を使います。\n\nlibrary(\"e1071\")\nstock_data %>%\n  summarise(\n    skewness_R = skewness(R, na.rm = TRUE), # 総リターンの歪度\n    kurtosis_R = kurtosis(R, na.rm = TRUE), # 総リターンの尖度\n    skewness_Re = skewness(Re, na.rm = TRUE), # 超過リターンの歪度\n    kurtosis_Re = kurtosis(Re, na.rm = TRUE) # 超過リターンの尖度\n  )\n\n# A tibble: 1 × 4\n  skewness_R kurtosis_R skewness_Re kurtosis_Re\n       <dbl>      <dbl>       <dbl>       <dbl>\n1      0.507       1.27       0.507        1.27\n\n\nトータルリターンの歪度が0.507 >0なので，右に裾の広い分布となっており，尖度が1.27 < 3なので正規分布よりもとがった形となっていることがわかります。\n図でも確認するために，トータルリターンRのヒストグラムを書いてみます。\n\nggplot(stock_data) +\n  aes(x = R) + geom_histogram() + # トータルリターンのヒストグラム\n  xlab(\"Monthly Stock Return\") + ylab(\"Count\") + mystyle # 軸ラベル\n\n\n\n\nトータルリターンのヒストグラムに正規分布のグラフを重ねてみると，次のようになります。\n\n# トータルリターン\nR <- stock_data$R\n\n# 正規分布データ作成\nm <- mean(stock_data$R, na.rm = TRUE)\nsd <- sd(stock_data$R, na.rm = TRUE)\nx <- rnorm(95040, mean = m, sd = sd)\n\ndf <- data.frame(R,x) %>% drop_na() # 欠損値削除\ndf <- df %>% pivot_longer(everything())\n\nトータルリターンと正規分布のヒストグラムを書いてみる。\n\ng <- ggplot(df) + aes(x = value, fill = name, group = name) +\n  geom_histogram(bins = 100, alpha = 0.4, position=\"identity\") +\n  xlab(\"Monthly Stock Return\") + ylab(\"Count\")\ng <- g + annotate( # 位置を指定して文字列を追加\n  geom = \"text\", x = 0.3, y = 900, label = \"fat tail\") +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 0.3, xend = 0.3,\n  y = 800, yend = 300,\n  color = \"black\",  size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng <- g + annotate( # 位置を指定して文字列を追加\n  geom = \"text\", x = 0.3, y = 4200,\n  label = \"Sharp shape\"\n  ) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 0.2, xend = 0.1,\n  y = 4200, yend = 4200,\n  color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng <- g + mystyle\nprint(g)\n\n\n\n\n歪度と尖度の結果と整合的に、赤色で表されているトータルリターンのヒストグラムは正規分布よりも右に裾が長く，尖度も正規分布よりもとがった形となっています。"
  },
  {
    "objectID": "Chap05.html#バイアンドホールドリターンの考え方",
    "href": "Chap05.html#バイアンドホールドリターンの考え方",
    "title": "5  株式データの取得と可視化",
    "section": "6.1 バイ・アンド・ホールド・リターンの考え方",
    "text": "6.1 バイ・アンド・ホールド・リターンの考え方\nバイ・アンド・ホールド・リターン(buy-and-hold-return)は，ある時点で株式を購入し，そのまま保有し続けたときのリターンのことを指します。 たとえば，12月末に株式を購入し，3月末に売却したときの、バイ・アンド・ホールド・リターンの累積は，次式で計算できます。ただし配当は無視します。 \n\\begin{aligned}\n\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{12月}}} \\right) =\n\\underbrace{\\left ( \\frac{W_{\\text{1月}}}{W_{\\text{12月}}} \\right)}_{1 + R_{\\text{1月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{2月}}}{W_{\\text{1月}}} \\right)}_{1 + R_{\\text{2月}}} \\times\n\\underbrace{\\left ( \\frac{W_{\\text{3月}}}{W_{\\text{2月}}} \\right)}_{1 + R_{\\text{3月}}} \\times\n\\end{aligned}\n\n一般的に、月次でt時点からT時点までの年次リターンは、\n\n\\left ( \\frac{W_{\\text{翌年12月末}}}{W_{\\text{12月末}}} \\right) = \\prod_{t = \\text{1月}}^{\\text{12月}} (1 + R_t)\n\nと計算できます。"
  },
  {
    "objectID": "Chap05.html#年次リターンの計算",
    "href": "Chap05.html#年次リターンの計算",
    "title": "5  株式データの取得と可視化",
    "section": "6.2 年次リターンの計算",
    "text": "6.2 年次リターンの計算\nでは、stock_dataをもとに年次リターンを計算してみましょう。\n\nannual_stock_data <- stock_data %>%\n  group_by(firm_ID, year) %>% # firm_IDとyearごとにグループ化\n  summarise(\n    annual_R = prod(1 + R) - 1, # B&H年次リターン\n    annual_R_F = prod(1 + R_F) - 1 # 年次超過リターン\n  ) %>%\n  mutate(annual_Re = annual_R - annual_R_F) %>% # 年次超過リターン\n  ungroup()\nhead(annual_stock_data)\n\n# A tibble: 6 × 5\n  firm_ID  year annual_R annual_R_F annual_Re\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>\n1       1  2015   NA      0.00743      NA    \n2       1  2016    0.997  0.000565      0.997\n3       1  2017    0.688  0.0000488     0.688\n4       1  2018   -0.214  0.00579      -0.219\n5       1  2019    0.647 -0.000770      0.648\n6       1  2020   -0.284  0.000380     -0.285"
  },
  {
    "objectID": "Chap05.html#データの結合",
    "href": "Chap05.html#データの結合",
    "title": "5  株式データの取得と可視化",
    "section": "7.1 データの結合",
    "text": "7.1 データの結合\n複数のデータフレームを結合する際に重要なところは、\n\nデータの頻度の違い\nタイミングの一致\n\nとなる。 今まで使ってきた財務データは年次データであるのに対して，株式データは月次データであるため，データの頻度が異なります。 確認してみましょう。\n\nfinancial_data <- read_csv(\"data/ch04_output.csv\")\nnrow(financial_data) # 年次財務データの行数\n\n[1] 7919\n\nnrow(annual_stock_data) # 年次リターン・データの行数\n\n[1] 7920\n\nnrow(stock_data) # 月次リターン・データの行数\n\n[1] 95040\n\n\n月次リターンの行数が上の年次データとは大きく異なっていることが分かります。\n\n\n\n\n\n\n先読みバイアス(look-ahead bias)とは、ある時点での情報を使って、その時点よりも未来の情報を使っていることを指します。12月末決算の会社のディスクロジャージャーは、最速で決算日後45日以内に出される決算短信か、3ヶ月以内に出される有価証券報告書があります。 このため、年次データを使って同時期の年次リターンを計算すると、年次データの発表後に出される有価証券報告書の情報を使っていることになります。これを先読みバイアスといいます。\n\n\n\n\nannual_data <- annual_stock_data %>%\n  full_join(financial_data, by = c(\"firm_ID\", \"year\")) # firm_IDとyearのペアをキーとして設定\n\n\nannual_data <- annual_stock_data %>%\n  full_join(financial_data) # キーを省略した場合，列名が同じ変数がキーになる\nhead(annual_data)\n\n# A tibble: 6 × 17\n  firm_ID  year annual_R annual_R_F annual_Re industry_ID sales    OX   NFE\n    <dbl> <dbl>    <dbl>      <dbl>     <dbl>       <dbl> <dbl> <dbl> <dbl>\n1       1  2015   NA      0.00743      NA              NA   NA    NA   NA  \n2       1  2016    0.997  0.000565      0.997           1 5949.  564.  50.7\n3       1  2017    0.688  0.0000488     0.688           1 6505.  691.  29.5\n4       1  2018   -0.214  0.00579      -0.219           1 6846.  751.  86.5\n5       1  2019    0.647 -0.000770      0.648           1 7572.  959. 298. \n6       1  2020   -0.284  0.000380     -0.285           1 7538.  778. -65.5\n# ℹ 8 more variables: X <dbl>, OA <dbl>, FA <dbl>, OL <dbl>, FO <dbl>,\n#   BE <dbl>, lagged_BE <dbl>, ROE <dbl>\n\n\n\nmonthly_data <- stock_data %>%\n  full_join(financial_data, by = c(\"firm_ID\", \"year\")) # firm_IDとyearのペアをキーとして設定"
  },
  {
    "objectID": "Chap05.html#バブルチャート",
    "href": "Chap05.html#バブルチャート",
    "title": "5  株式データの取得と可視化",
    "section": "7.2 バブルチャート",
    "text": "7.2 バブルチャート\n\nannual_data <- stock_data %>%\n  filter(month == 12) %>% # 12月のみ\n  select(year, firm_ID, ME) %>% # 変数を選択\n  full_join(annual_data, ., by = c(\"year\", \"firm_ID\")) %>% # 年次データと結合\n  mutate(ME = ME / 1e6) # MEを百万円単位に変換\n\n\nyear2015 <- annual_data %>%\n   filter(\n      year == 2015, # 2015年のみ\n      firm_ID %in% 2:20, # firm_IDが2から20のデータを抽出\n      X > 0 # 対数を取るため当期純利益が正のデータのみ抽出\n      )\n\nggplot(year2015) +\n  aes(x = log(sales), y = log(X), size = ME, alpha = 0.4) +\n  geom_point() + # バブルチャートを描くにはsize引数を指定\n  scale_size(range = c(1, 20), name = \"Market Equity\") + # rangeでバブルの最小最大面積を指定\n  scale_x_continuous(limits = c(8, 14)) + # 両軸の範囲を指定\n  scale_y_continuous(limits = c(2, 11)) + mystyle"
  },
  {
    "objectID": "Chap05.html#リターンデータに関する仮定",
    "href": "Chap05.html#リターンデータに関する仮定",
    "title": "5  株式データの取得と可視化",
    "section": "8.1 リターン・データに関する仮定",
    "text": "8.1 リターン・データに関する仮定\n統計的推論の内容に入る前に、firm_IDが1の企業の超過リターンReのデータを眺めてみます。\n\nstock_data_1_month <- stock_data %>%\n  filter(firm_ID == 1) %>%\n  select(month_ID, Re, R)\nggplot(stock_data_1_month) +\n  aes(x = month_ID, y = Re) + # 軸の設定\n  geom_line() + mystyle # 折れ線グラフ\n\n\n\n\nこのようなデータは時系列データと呼ばれ、ある個体(ここではfirm_IDが1の企業)の一定期間にわたって観測したデータのことを指します。\n\n\n\n\n\n\n重要\n\n\n\n月次超過リターンの時系列データは、何らかの確率分布(モデル)から独立に生成されている。\n\n\n\n株価そのものでは無く変化率であるリターンをモデル化する理由\n\n株価それ自体は株式分割などの要因でも変化するし、会社の成長に応じて上昇するため、その成長率をモデル化する方が、投資のリスクに対するリターンをより明確に評価することができるからである。\n\n月次リターンではなく月次超過リターンをモデルかする理由\n\n投資リスクを取って得られる追加的なリターンであるリスクプレミアムを明確に評価するために、無リスク金利を差し引いた超過リターンをモデル化します。\n\n月次超過リターンが独立であるとする理由\n\n半強度の効率的市場であれば、過去の情報はすでに株価に織り込まれているので、過去の超過リターンは将来の超過リターンと無関係である、とし、超過リターンに系列相関はない、と仮定します。 しかし、アノマリーの存在などにより、現実には系列相関があると考えられますが、モデルが複雑になるので、ここでは独立の仮定をおいて、モデルを単純化します。\n\n月次超過リターンが正規分布に従うとする理由\n\n正規分布を仮定するといろいろ計算が楽になる、という理由とともに、 株価の動きは多くの独立した事象の結果であると考えられ、中心極限定理により、超過リターンは正規分布に従うと考えられます。\nこれらの仮定を受け入れると、超過リターンの確率分布は次式で表されます。\n\nRe_t \\sim N(\\mu, \\sigma^2)\n\nこれにより、母集団分布に対して統計的推論が可能になります。 firm 1の超過リターンのヒストグラムを書いてみます。\n\nggplot(stock_data_1_month) + aes(x = Re) + # データと変数\n  geom_histogram() + scale_y_continuous(expand = c(0,0))+ mystyle \n\n\n\n\nサンプルサイズが小さいため凸凹しているけれど、もっとサンプルを増やせば、正規分布に近い形をとるはずです。"
  },
  {
    "objectID": "Chap05.html#推定量と推定値の違い",
    "href": "Chap05.html#推定量と推定値の違い",
    "title": "5  株式データの取得と可視化",
    "section": "8.2 推定量と推定値の違い",
    "text": "8.2 推定量と推定値の違い\n推定量(estimator)とは、母集団分布の母数(パラメータ)を推定するために使われる統計量のことです。 推定値(estimates)とは、推定量に実際のデータを代入して計算した値のことです。 たとえば母集団分布が正規分布N(\\mu, \\sigma^2)に従うと仮定すると、母数は\\muと\\sigma^2の2つです。この母数を推定するために使われる統計量が、それぞれ標本平均\\bar xと標本分散s^2です。 このときの推定値とは、実際に観察された標本から計算された標本平均\\bar xと標本分散s^2のことを指します。\n次の問題を考えます。\n\n\n\n\n\n\n重要\n\n\n\nfirm_IDが1の銘柄の月次リターンR_{i,t}^eは、期待値の意味で、ゼロより大きいのだろうか？\n\n\nここで「期待値の意味で」というのは平均的に、と言い換えても問題ないです。 企業1の月次超過リターンの平均は0より大きい、ということは、企業1の月次リターンは平均的に無リスク利子率よりも大きいかどうか、を比べるということです。\nこの問題を解くために、まずは母集団分布の母数である期待値\\muを推定する必要があります。 期待値\\muを推定するために使われる推定量は標本平均\\bar xなので、ここで標本平均を計算します。\n\nstock_data_1_month %>%\n  summarise(\n    mean_Re = mean(Re, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 1\n  mean_Re\n    <dbl>\n1  0.0291\n\n\n企業1の平均月次超過リターンmean_Reが0.0291となりました。 これだけみるとゼロより大きい値ですが、これは母集団から抽出された1つのサンプルの平均ですので、他のサンプルの平均がゼロを超えるかどうかは分かりません。\n\n8.2.1 大数の法則\n母集団から無限個の標本(sample)を抽出して、それぞれの標本平均(sample mean)を計算すると、その標本平均の平均は母集団の期待値\\muに一致することが知られています。これを対数の法則(law of large number)といいます。\n数式よりも前にシミュレーションで確認してみましょう。 まずは、母集団分布を平均が10、標準偏差が2の正規分布N(10, 4)として、母集団から100のデータを抽出して標本を1つ作ります。そしてその標本の平均を計算します。\n\nset.seed(123) # 乱数の種を固定\nsize <- 100 # 標本サイズ\n# 母集団のパラメータの設定\nmu <- 10 # 平均\nsigma <- 4 # 標準偏差\npopulation <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 10.36162\n\n\n平均は10.3616236となりました。 母集団の平均10とは異なる数値になっています。 もう一度別の標本でやってみると、\n\npopulation <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\nmean(population) # 標本平均\n\n[1] 9.569813\n\n\nまた違う平均が計算されました。 この作業を何度も何度も繰り返し、標本平均をたくさん計算します。 ここでは、100個のデータをもつ標本を100個作って、それぞれの標本平均を計算します。\n\nn_sample <- 100 # サンプル数\nsample_mean <- rep(NA, n_sample) # 標本平均を格納するベクトル\nsample_sd <- rep(NA, n_sample) # 標本分散を格納するベクトル\nfor(i in 1:n_sample){\n  population <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\n  sample_mean[i] <- mean(population) # 標本平均を計算\n  sample_sd[i] <- sd(population)\n}\n\nサンプルの平均が100個計算できたので、ヒストグラムを書いてみます。\n\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\nあまり正規分布のようには見えません。 ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 9.99003\n\n\n母集団の平均10に近い値になっていることが分かります。もっとサンプルの数を増やしてみます。 データの数が100のサンプルを1,000,000個(100万個)抽出して、それぞれのサンプルの平均値を計算します。\n\nn_sample <- 10^6 # サンプル数\nsample_mean <- rep(NA, n_sample) # 標本平均を格納するベクトル\nsample_sd <- rep(NA, n_sample) # 標本分散を格納するベクトル\nfor(i in 1:n_sample){\n  population <- rnorm(size, mu, sigma) # 母集団からサンプルを抽出\n  sample_mean[i] <- mean(population) # 標本平均を計算\n  sample_sd[i] <- sd(population)\n}\n\nggplot() + aes(x = sample_mean) + geom_histogram() + mystyle\n\n\n\n\nほぼ正規分布のような形をしていることが分かります。ではサンプルの平均の平均を計算してみます。\n\nmean(sample_mean) # 標本平均の平均\n\n[1] 10.00063\n\nmean(sample_sd) # 標本分散の平均\n\n[1] 3.990079\n\n\nこのように標本の数を無限に大きくしたとき、サンプルの平均の平均は母集団の平均10に一致するし，標本標準偏差は母集団の標準偏差4に一致する，というのが大数の法則です。"
  },
  {
    "objectID": "Chap05.html#t値の計算",
    "href": "Chap05.html#t値の計算",
    "title": "5  株式データの取得と可視化",
    "section": "8.3 t値の計算",
    "text": "8.3 t値の計算\n先ほど計算したfirm_IDが1の企業の超過リターンの平均値はNAでした。 これがゼロより大きいかどうかはすぐ分かりますが，この値はたまたま今手元にある1つのサンプルから計算された平均値なので，他の標本ではどうなるか分かりません。 このように推定量にばらつきがある場合には，その推定量の分布を考える必要があります。 ここでは，その分布をt分布(t distribution)と仮定して，t値(t-value)を計算してみます。 t値は次のように定義されます。\n\nt = \\frac{\\bar{X} - \\mu_0}{\\sqrt{s^2 / n} } \\stackrel{d}{\\approx} N(0,1)\n\nここで，\\bar Xは標本平均，\\mu_0は帰無仮説(null hypothesis)の値で，ここでは\\mu_0 = 0とします。s^2は標本分散，nは標本サイズです。 分子に注目すると，標本平均と帰無仮説の値の差となっており，もし標本平均が0に近いなら，t値は0に近い値になります。\n\nRe_firm_ID_1 <- stock_data %>%\n  filter(firm_ID == 1) %>% # firm_IDが1の企業のデータを抽出\n  select(Re) %>% #超過リターンのみ選択\n  drop_na() %>% # 欠損値を除去\n  unlist() # データフレームをベクトルに変換\n\nmu0 <- 0 # 帰無仮説の値\nn <- length(Re_firm_ID_1) # 標本サイズ\n\nt_value <- (mean(Re_firm_ID_1) - mu0) / sqrt(var(Re_firm_ID_1) / n) # $t$値の計算\nprint(t_value)\n\n[1] 2.121296\n\n\n\n8.3.1 統計的検定の考え方\nあなたがサイコロを投げるゲームをしていて、あるプレイヤーが非常に幸運だと主張しています。彼は6回サイコロを投げて、5回も「6」が出たとします。これはただの偶然なのか、それとも何か他の要因（例えば、サイコロがいかさまであるとか）が関与しているのでしょうか？\nこの問いに答えるために、我々は統計的検定(statistical test)を用いることができます。 まず帰無仮説(null hypothesis)を設定します。 この例では、帰無仮説は「サイコロは公正であり、すべての出目が等確率（1/6）で出る」とすることが適切です。\n次に、この帰無仮説が真(true)である場合に、我々が観察した結果（5回の「6」）がどれほどあり得ないかを計算します。これがp値(p value)です。この場合、6回投げて5回「6」が出る確率を計算します。\nこれを計算すると、p値は非常に小さいことが分かり（つまり、この結果は帰無仮説の下ではほぼあり得ない），帰無仮説が棄却されます。 帰無仮説が棄却されるとは，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいことを意味します。 したがって、我々はこの結果が偶然生じたとは考えにくく、その代わりにサイコロがいかさまである、または何か他の非ランダムな要因が作用している可能性を強く疑うことになります。これがp値を用いて統計的検定の考え方です。\np値が0.05より小さい場合，帰無仮説は棄却され，対立仮説が採択される，というケースが多いです。 この場合，有意水準5%で帰無仮説は棄却されます。 有意水準は，帰無仮説が正しいと仮定したときに，観測されたデータが得られる確率が小さいと判断する基準値です。 有意水準は，5%や1%がよく使われます。\nRでは，t.test()関数を使って，t値とp値を計算することができます。 ここでは，t.test()関数を使って，firm_IDが1の企業の超過リターンがゼロなのかどうなのか，を検定するために，t値とp値を計算してみましょう。\n\nt.test(Re_firm_ID_1)\n\n\n    One Sample t-test\n\ndata:  Re_firm_ID_1\nt = 2.1213, df = 70, p-value = 0.03744\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.001737894 0.056383256\nsample estimates:\n mean of x \n0.02906058"
  },
  {
    "objectID": "Chap05.html#ols推定",
    "href": "Chap05.html#ols推定",
    "title": "5  株式データの取得と可視化",
    "section": "9.1 OLS推定",
    "text": "9.1 OLS推定\n推定方法として最も有名なものが最小二乗法(ordinary least squares; OLS)です。 最小二乗法では，観測値と推定値の差の二乗の和が最小になるように\\alphaと\\betaを推定します。 このとき，観測値と推定値の差を残差(residual)と呼びます。 最小二乗法では，残差の二乗の和である残差平方和(sum of squared residuals; SSR)が最小になるように\\alphaと\\betaを推定します。\n\n\\min _{\\alpha, \\beta} \\sum _{i=1}^n (Y_i - \\alpha - \\beta X_i)^2\n\n\nlm_sample_data <- annual_data %>%\n  group_by(firm_ID) %>% # 企業IDごとに\n  mutate(\n    lagged_BEME = lag(BE) / lag(ME), # 期首簿価時価比率\n  ) %>%\n  ungroup() %>%\n  filter(year == 2016, firm_ID <= 10) %>%\n  select(firm_ID, year, annual_Re, lagged_BEME) %>%\n  drop_na() # 欠損値を除去\n\nggplot(lm_sample_data) +\n  geom_point(aes(x = lagged_BEME, y = annual_Re)) + # 散布図\n  xlab(\"簿価時価比率\") + ylab(\"超過リターン\") + mystyle\n\n\n\n\n簿価時価比率と株式リターンの散布図に回帰直線を追加します。 回帰直線を追加するには、geom_smooth()を使います。 geom_smooth()の引数には、\n\nmethod = \"lm\": 線形回帰\nse = FALSE: 標準誤差を表示しない\ncolor = \"black\": 線の色を黒にする\n\nを追加しています。\n\ng <- ggplot(lm_sample_data) + aes(x = lagged_BEME, y = annual_Re) # x軸とy軸を指定\ng <- g + geom_point() # 散布図を追加\ng <- g + geom_smooth(method = \"lm\", se = FALSE, color = \"black\") # 回帰直線を追加\ng <- g + xlab(\"t期末時価簿価費率\") + ylab(\"t+1期超過リターン\") + mystyle\nprint(g)\n\n\n\n\n\n# ch05_33: lm()関数を用いた線形回帰\nlm_results <- lm(annual_Re ~ lagged_BEME, data = lm_sample_data) # 従属変数 ~ 独立変数\nnames(lm_results)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\n\nprint(lm_results$coefficients)\n\n(Intercept) lagged_BEME \n 0.05513385  0.07552921 \n\n\nこれが目的変数を超過リターン、説明変数を時価簿価費率とする回帰モデルを最小二乗法で推定した結果である。 termは変数名、estimateが回帰係数、std.errorが標準誤差、statisticがt統計量、p.valueがp値である。 termの1つめの(intercept)は切片で、説明変数がlagged_BEMEです。 ここでの統計的検定の帰無仮説は\\beta = 0、つまりlagged_BEMEのestimateが0である、というものです。\n\n# ch05_35: broomパッケージのtidy()関数で係数の推定値に関する結果を確認\n#install.packages(\"broom\")\nlibrary(broom)\ntidy(lm_results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)   0.0551    0.156      0.354   0.736\n2 lagged_BEME   0.0755    0.0844     0.895   0.405\n\n\nlagged_BEMEの回帰係数0.0755292は有意水準5%で統計的に有意ではなく、傾きがゼロかどうかは分からない、という結果となった。\ngrance()関数を使って、回帰分析の結果をまとめて表示することもできる。\n\nglance(lm_results)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.118       -0.0294 0.223     0.800   0.405     1   1.81  2.37  2.61\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n\n\n\nr.squaredは決定係数R^2\nadj.r.squaredは自由度調整済み決定係数\\bar{R}^2\nsigmaは標準誤差\nstatisticはF統計量\np.valueはF検定のp値\ndfは自由度\nlogLikは対数尤度\naicは赤池情報量基準(AIC)\nbicはベイズ情報量基準(BIC)\ndevianceは逸脱度\ndf.residualは残差の自由度\nnobsは観測値の数\n\nとなっています。回帰分析の結果でよく利用されるのは、決定係数R^2です。 決定係数の数字が大きければ大きいほど、モデルの説明力が高いことを意味します。 しかし決定係数は検定統計量ではないため、どれだけ高いと良いのかは一概には言えません。\nそこでF統計量を使います。 F統計量は、帰無仮説が「説明変数の係数が全てゼロである」という仮説のもとで計算される統計量です。 この統計量が有意に正であれば、説明変数の少なくとも1つは有意にゼロではないということになり、モデルは有効であると判断できます。 ちなみにこのモデルではF統計量は有意ではなく、モデルが有効かどうかは分かりません。"
  },
  {
    "objectID": "Chap05.html#対数回帰モデル",
    "href": "Chap05.html#対数回帰モデル",
    "title": "5  株式データの取得と可視化",
    "section": "9.2 対数回帰モデル",
    "text": "9.2 対数回帰モデル\n独立変数Xが変化したときの従属変数Yへの影響は一定(つまり傾きが一定)と仮定してきましたが、 実際には傾きが一定でない場合もあります。 回帰式が非線形であることが想定される場合、対処法として\n\n多項式回帰(polynomial regression) ：独立変数にX^2とかX^3を加える\n対数回帰(logarithmic regression) ：独立変数や従属変数の対数をとる\n\nたとえば、独立変数を対数変換した場合は、次のようなモデルになります。\n\nY_i = \\beta_0 + \\beta_1 \\log (X_i) + \\varepsilon_i\n\nこのモデルを対数回帰モデルと呼びます。 Rで分析する場合は、log()関数を使って対数変換を行います。 ついでにlm()の結果をtidy()関数で整形します。\n\n# ch05_37: 線形・対数モデルによる推定\ntidy(lm(annual_Re ~ log(lagged_BEME), data = lm_sample_data)) # 右辺のみlog()関数で自然対数を取る\n\n# A tibble: 2 × 5\n  term             estimate std.error statistic p.value\n  <chr>               <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)        0.167     0.0868     1.93    0.102\n2 log(lagged_BEME)   0.0355    0.109      0.326   0.756\n\n\nlog(lagged_BEME)のp.valueの値が0.756となり、有意水準5%で帰無仮説を棄却できませんでした。 つまり、簿価時価比率の対数と株式リターンの間には統計的に関係があるかどうかについて、何も言えない、ということが分かりました。\n間違っても、帰無仮説を棄却できなかったので、簿価時価比率の対数と株式リターンの間には関係がないとは言っていはいけません。注意しましょう。\n\n9.2.1 データの保存\n作成したデータフレームをcsvファイルとして保存するには，write_csv()関数を用います。 前処理が終わった後や新しい変数を作った後に、データを保存しておくと便利です。 6章以降では、以下のデータを継続して使うので、csvファイルとして保存しておきます。\n\n# ch05_38: データの保存\nwrite_csv(monthly_data, \"data/ch05_output1.csv\")\nwrite_csv(annual_data, \"data/ch05_output2.csv\")"
  },
  {
    "objectID": "Chap01.html#企業活動とお金の流れ",
    "href": "Chap01.html#企業活動とお金の流れ",
    "title": "1  会計入門",
    "section": "1.1 企業活動とお金の流れ",
    "text": "1.1 企業活動とお金の流れ"
  },
  {
    "objectID": "Chap01.html#株主目線の価値創造企業",
    "href": "Chap01.html#株主目線の価値創造企業",
    "title": "1  会計入門",
    "section": "1.2 株主目線の価値創造企業",
    "text": "1.2 株主目線の価値創造企業"
  },
  {
    "objectID": "Chap01.html#企業分析の視点",
    "href": "Chap01.html#企業分析の視点",
    "title": "1  会計入門",
    "section": "1.3 企業分析の視点",
    "text": "1.3 企業分析の視点"
  },
  {
    "objectID": "Chap01.html#練習問題",
    "href": "Chap01.html#練習問題",
    "title": "1  会計入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap02.html#練習問題",
    "href": "Chap02.html#練習問題",
    "title": "2  ファイナンス入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap03.html#練習問題",
    "href": "Chap03.html#練習問題",
    "title": "3  R言語入門",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap04.html#練習問題",
    "href": "Chap04.html#練習問題",
    "title": "4  財務データの取得と可視化",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "Chap05.html#練習問題",
    "href": "Chap05.html#練習問題",
    "title": "5  株式データの取得と可視化",
    "section": "練習問題",
    "text": "練習問題"
  }
]